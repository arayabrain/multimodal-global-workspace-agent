{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rousslan/anaconda3/envs/ss-hab-headless-py39/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Notebook support or argpase\n",
    "import sys; sys.argv=['']; del sys\n",
    "\n",
    "# Prototyping datsaet reading for the BC experimetns\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import uuid\n",
    "import datetime\n",
    "import pickle as pkl\n",
    "import compress_pickle as cpkl\n",
    "\n",
    "import torch\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "\n",
    "# General config related\n",
    "from configurator import get_arg_dict, generate_args\n",
    "\n",
    "# Env config related\n",
    "from ss_baselines.av_nav.config import get_config\n",
    "from ss_baselines.savi.config.default import get_config as get_savi_config\n",
    "from ss_baselines.common.env_utils import construct_envs\n",
    "from ss_baselines.common.environments import get_env_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region: Generating additional hyparams\n",
    "CUSTOM_ARGS = [\n",
    "    # General hyper parameters\n",
    "    get_arg_dict(\"seed\", int, 111),\n",
    "    get_arg_dict(\"total-steps\", int, 1_000_000),\n",
    "\n",
    "    # SS env config\n",
    "    get_arg_dict(\"config-path\", str, \"env_configs/audiogoal_rgb_nocont.yaml\"),\n",
    "\n",
    "    # PPO Hyper parameters\n",
    "    get_arg_dict(\"num-envs\", int, 128), # Number of parallel envs. 10 by default\n",
    "    get_arg_dict(\"num-steps\", int, 80), # For each env, how many steps are collected to form PPO Agent rollout.\n",
    "    get_arg_dict(\"num-minibatches\", int, 1), # Number of mini-batches the rollout data is split into to make the updates\n",
    "    get_arg_dict(\"update-epochs\", int, 4), # Number of gradient step for the policy and value networks\n",
    "    get_arg_dict(\"gamma\", float, 0.99),\n",
    "    get_arg_dict(\"gae-lambda\", float, 0.95),\n",
    "    get_arg_dict(\"norm-adv\", bool, True, metatype=\"bool\"),\n",
    "    get_arg_dict(\"clip-coef\", float, 0.1), # Surrogate loss clipping coefficient\n",
    "    get_arg_dict(\"clip-vloss\", bool, True, metatype=\"bool\"),\n",
    "    get_arg_dict(\"ent-coef\", float, 0.2), # Entropy loss coef; 0.2 in SS baselines\n",
    "    get_arg_dict(\"vf-coef\", float, 0.5), # Value loss coefficient\n",
    "    get_arg_dict(\"max-grad-norm\", float, 0.5),\n",
    "    get_arg_dict(\"target-kl\", float, None),\n",
    "    get_arg_dict(\"lr\", float, 2.5e-4), # Learning rate\n",
    "    get_arg_dict(\"optim-wd\", float, 0), # weight decay for adam optim\n",
    "    ## Agent network params\n",
    "    get_arg_dict(\"agent-type\", str, \"ss-default\", metatype=\"choice\",\n",
    "        choices=[\"ss-default\", \"deep-etho\",\n",
    "                    \"perceiver-gwt-gwwm\", \"perceiver-gwt-attgru\"]),\n",
    "    get_arg_dict(\"hidden-size\", int, 512), # Size of the visual / audio features and RNN hidden states \n",
    "    ## Perceiver / PerceiverIO params: TODO: num_latnets, latent_dim, etc...\n",
    "    get_arg_dict(\"pgwt-latent-type\", str, \"randn\", metatype=\"choice\",\n",
    "        choices=[\"randn\", \"zeros\"]), # Depth of the Perceiver\n",
    "    get_arg_dict(\"pgwt-latent-learned\", bool, True, metatype=\"bool\"),\n",
    "    get_arg_dict(\"pgwt-depth\", int, 1), # Depth of the Perceiver\n",
    "    get_arg_dict(\"pgwt-num-latents\", int, 8),\n",
    "    get_arg_dict(\"pgwt-latent-dim\", int, 64),\n",
    "    get_arg_dict(\"pgwt-cross-heads\", int, 1),\n",
    "    get_arg_dict(\"pgwt-latent-heads\", int, 4),\n",
    "    get_arg_dict(\"pgwt-cross-dim-head\", int, 64),\n",
    "    get_arg_dict(\"pgwt-latent-dim-head\", int, 64),\n",
    "    get_arg_dict(\"pgwt-weight-tie-layers\", bool, False, metatype=\"bool\"),\n",
    "    get_arg_dict(\"pgwt-ff\", bool, False, metatype=\"bool\"),\n",
    "    get_arg_dict(\"pgwt-num-freq-bands\", int, 6),\n",
    "    get_arg_dict(\"pgwt-max-freq\", int, 10.),\n",
    "    get_arg_dict(\"pgwt-use-sa\", bool, False, metatype=\"bool\"),\n",
    "    ## Peceiver Modality Embedding related\n",
    "    get_arg_dict(\"pgwt-mod-embed\", int, 0), # Learnable modality embeddings\n",
    "    ## Additional modalities\n",
    "    get_arg_dict(\"pgwt-ca-prev-latents\", bool, True, metatype=\"bool\"), # if True, passes the prev latent to CA as KV input data\n",
    "\n",
    "    # Logging params\n",
    "    # NOTE: While supported, video logging is expensive because the RGB generation in the\n",
    "    # envs hogs a lot of GPU, especially with multiple envs \n",
    "    get_arg_dict(\"save-videos\", bool, False, metatype=\"bool\"),\n",
    "    get_arg_dict(\"save-model\", bool, True, metatype=\"bool\"),\n",
    "    get_arg_dict(\"log-sampling-stats-every\", int, int(1.5e3)), # Every X frames || steps sampled\n",
    "    get_arg_dict(\"log-training-stats-every\", int, int(10)), # Every X model update\n",
    "    get_arg_dict(\"logdir-prefix\", str, \"./logs/\") # Overrides the default one\n",
    "]\n",
    "args = generate_args(CUSTOM_ARGS)\n",
    "\n",
    "# Additional PPO overrides\n",
    "args.batch_size = int(args.num_envs * args.num_steps)\n",
    "args.minibatch_size = int(args.batch_size // args.num_minibatches)\n",
    "\n",
    "# Load environment config\n",
    "is_SAVi = str.__contains__(args.config_path, \"savi\")\n",
    "if is_SAVi:\n",
    "    env_config = get_savi_config(config_paths=args.config_path)\n",
    "else:\n",
    "    env_config = get_config(config_paths=args.config_path)\n",
    "# endregion: Generating additional hyparams\n",
    "\n",
    "# TODO: make it not require the environemtn instantiation\n",
    "\n",
    "# Overriding some envs parametes from the .yaml env config\n",
    "env_config.defrost()\n",
    "env_config.NUM_PROCESSES = args.num_envs # Corresponds to number of envs, makes script startup faster for debugs\n",
    "# env_config.USE_SYNC_VECENV = True\n",
    "# env_config.USE_VECENV = False\n",
    "# env_config.CONTINUOUS = args.env_continuous\n",
    "## In caes video saving is enabled, make sure there is also the rgb videos\n",
    "env_config.freeze()\n",
    "# print(env_config)\n",
    "\n",
    "# Environment instantiation\n",
    "# envs = construct_envs(env_config, get_env_class(env_config.ENV_NAME))\n",
    "# single_observation_space = envs.observation_spaces[0]\n",
    "# single_action_space = envs.action_spaces[0]\n",
    "\n",
    "# single_observation_space, single_action_space\n",
    "\n",
    "# # Loading pretrained agent\n",
    "# import models\n",
    "# from models import ActorCritic, Perceiver_GWT_GWWM_ActorCritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR_PATH = f\"ppo_gru_dset_2022_09_21__750000_STEPS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs_list dict:\n",
      "\t rgb -> (30, 128, 128, 3); type: <class 'list'>\n",
      "\t audiogoal -> (30, 2, 16000); type: <class 'list'>\n",
      "\t spectrogram -> (30, 65, 26, 2); type: <class 'list'>\n",
      "action_list -> (30, 1); type: list\n",
      "done_list -> (30,); type: list\n",
      "reward_list -> (30,); type: list\n",
      "info_list -> (30,); type: list\n",
      "ep_length -> 30; type: int\n"
     ]
    }
   ],
   "source": [
    "ep_filenames = os.listdir(DATASET_DIR_PATH)\n",
    "len(ep_filenames)\n",
    "ep_filename = np.random.choice(ep_filenames)\n",
    "\n",
    "ep_filepath = os.path.join(DATASET_DIR_PATH, ep_filename)\n",
    "with open(ep_filepath, \"rb\") as f:\n",
    "    ep_data_dict = cpkl.load(f)\n",
    "ep_data_dict.keys()\n",
    "\n",
    "for k, v in ep_data_dict.items():\n",
    "    if isinstance(v, dict):\n",
    "        print(f\"{k} dict:\")\n",
    "        for kk, vv in v.items():\n",
    "            print(f\"\\t {kk} -> {np.shape(vv)}; type: {type(vv)}\")\n",
    "    elif isinstance(v, list):\n",
    "        print(f\"{k} -> {np.shape(v)}; type: list\")\n",
    "    elif isinstance(v, int):\n",
    "        print(f\"{k} -> {v}; type: int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import IterableDataset, DataLoader\n",
    "\n",
    "# ## Shape of the dave ep_data_dict:, for reference\n",
    "# # obs_list dict:\n",
    "# # \t rgb -> (94, 128, 128, 3)\n",
    "# # \t audiogoal -> (94, 2, 16000)\n",
    "# # \t spectrogram -> (94, 65, 26, 2)\n",
    "# # action_list -> (94, 1)\n",
    "# # done_list -> (94,)\n",
    "# # reward_list -> (94,)\n",
    "# # info_list -> (94,)\n",
    "# # ep_length -> 94\n",
    "\n",
    "# class BCIterableDataset(IterableDataset):\n",
    "#     def __init__(self, dataset_path, batch_length, seed=111):\n",
    "#         self.seed = seed\n",
    "#         self.batch_length = batch_length\n",
    "#         self.dataset_path = dataset_path\n",
    "\n",
    "#         # Read episode filenames in the dataset path\n",
    "#         self.ep_filenames = os.listdir(dataset_path)\n",
    "#         print(f\"Initialized IterDset with {len(self.ep_filenames)} episodes.\")\n",
    "    \n",
    "#     def __iter__(self):\n",
    "#         batch_length = self.batch_length\n",
    "#         while True:\n",
    "#             # Sample epsiode data until there is enough for one trajectory\n",
    "#             # Hardcoded for now, make flexible later\n",
    "#             # Done later to recover the \n",
    "#             obs_list = {\n",
    "#                 \"rgb\": np.zeros([batch_length, 128, 128, 3]),\n",
    "#                 \"audiogoal\": np.zeros([batch_length, 2, 16000]),\n",
    "#                 \"spectrogram\": np.zeros([batch_length, 65, 26, 2])\n",
    "#             }\n",
    "#             action_list, reward_list, done_list = \\\n",
    "#                 np.zeros([batch_length, 1]), \\\n",
    "#                 np.zeros([batch_length, 1]), \\\n",
    "#                 np.zeros([batch_length, 1])\n",
    "            \n",
    "#             ssf = 0 # Step affected so far\n",
    "#             while ssf < batch_length:\n",
    "#                 idx = th.randint(len(self.ep_filenames), ())\n",
    "#                 print(f\"Sampled traj idx: {idx}\")\n",
    "#                 ep_filename = self.ep_filenames[idx]\n",
    "#                 ep_filepath = os.path.join(DATASET_DIR_PATH, ep_filename)\n",
    "#                 with open(ep_filepath, \"rb\") as f:\n",
    "#                     edd = cpkl.load(f)\n",
    "\n",
    "#                 # Append the data to the bathc trjectory\n",
    "#                 rs = batch_length - ssf # Reamining steps\n",
    "#                 horizon = ssf + min(rs, edd[\"ep_length\"])\n",
    "\n",
    "#                 for k, v in edd[\"obs_list\"].items():\n",
    "#                     obs_list[k][ssf:horizon] = v[:rs]\n",
    "#                 action_list[ssf:horizon] = edd[\"action_list\"][:rs]\n",
    "#                 reward_list[ssf:horizon] = np.array(edd[\"reward_list\"][:rs])[:, None]\n",
    "#                 done_list[ssf:horizon] = np.array(edd[\"done_list\"][:rs])[:, None]\n",
    "\n",
    "#                 ssf += edd[\"ep_length\"]\n",
    "\n",
    "#                 if ssf >= self.batch_length:\n",
    "#                     break\n",
    "\n",
    "#             yield obs_list, action_list, reward_list, done_list\n",
    "    \n",
    "# def make_dataloader(dataset_path, batch_size, batch_length, seed=111, num_workers=4):\n",
    "#     def worker_init_fn(worker_id):\n",
    "#         # worker_seed = th.initial_seed() % (2 ** 32)\n",
    "#         worker_seed = 133754134 + worker_id\n",
    "\n",
    "#         random.seed(worker_seed)\n",
    "#         np.random.seed(worker_seed)\n",
    "\n",
    "#     th_seed_gen = th.Generator()\n",
    "#     th_seed_gen.manual_seed(133754134 + seed)\n",
    "\n",
    "#     dloader = iter(\n",
    "#         DataLoader(\n",
    "#             BCIterableDataset(\n",
    "#                 dataset_path=dataset_path, batch_length=batch_length),\n",
    "#                 batch_size=batch_size, num_workers=num_workers,\n",
    "#                 worker_init_fn=worker_init_fn, generator=th_seed_gen\n",
    "#             )\n",
    "#     )\n",
    "\n",
    "#     return dloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dloader = make_dataloader(DATASET_DIR_PATH, batch_size=1, batch_length=30)\n",
    "# for _ in range(2):\n",
    "#     obs_batch, action_batch, reward_batch, done_batch = next(dloader)\n",
    "\n",
    "# # obs_batch[\"rgb\"].shape, obs_batch[\"spectrogram\"].shape\n",
    "# # done_batch[0][..., 0].tolist()\n",
    "# # reward_batch[0][..., 0].tolist()\n",
    "# # obs_batch[\"rgb\"][0][0, 0, 0]\n",
    "# # action_batch[0][..., 0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized IterDset with 4677 episodes.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/rousslan/random/rl/ss-hab/ppo/ppo_bcdset_read_proto.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 83>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmusashi/home/rousslan/random/rl/ss-hab/ppo/ppo_bcdset_read_proto.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=81'>82</a>\u001b[0m dloader \u001b[39m=\u001b[39m make_dataloader2(DATASET_DIR_PATH, batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, batch_length\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmusashi/home/rousslan/random/rl/ss-hab/ppo/ppo_bcdset_read_proto.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=82'>83</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bmusashi/home/rousslan/random/rl/ss-hab/ppo/ppo_bcdset_read_proto.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=83'>84</a>\u001b[0m     obs_batch, action_batch, reward_batch, done_batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(dloader)\n",
      "File \u001b[0;32m~/anaconda3/envs/ss-hab-headless-py39/lib/python3.9/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/ss-hab-headless-py39/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1330\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1327\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1329\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1330\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1331\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1332\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1333\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ss-hab-headless-py39/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1296\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1294\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1295\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1296\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1297\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1298\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/ss-hab-headless-py39/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1134\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1122\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1135\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1136\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1137\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ss-hab-headless-py39/lib/python3.9/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    114\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/anaconda3/envs/ss-hab-headless-py39/lib/python3.9/multiprocessing/connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 262\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m~/anaconda3/envs/ss-hab-headless-py39/lib/python3.9/multiprocessing/connection.py:429\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 429\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    430\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/anaconda3/envs/ss-hab-headless-py39/lib/python3.9/multiprocessing/connection.py:936\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    933\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    935\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    937\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    938\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/anaconda3/envs/ss-hab-headless-py39/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "\n",
    "# This variant will sample \n",
    "class BCIterableDataset2(IterableDataset):\n",
    "    def __init__(self, dataset_path, batch_length, seed=111):\n",
    "        self.seed = seed\n",
    "        self.batch_length = batch_length\n",
    "        self.dataset_path = dataset_path\n",
    "\n",
    "        # Read episode filenames in the dataset path\n",
    "        self.ep_filenames = os.listdir(dataset_path)\n",
    "        print(f\"Initialized IterDset with {len(self.ep_filenames)} episodes.\")\n",
    "    \n",
    "    def __iter__(self):\n",
    "        batch_length = self.batch_length\n",
    "        while True:\n",
    "            # Sample epsiode data until there is enough for one trajectory\n",
    "            # Hardcoded for now, make flexible later\n",
    "            # Done later to recover the \n",
    "            obs_list = {\n",
    "                \"rgb\": np.zeros([batch_length, 128, 128, 3]),\n",
    "                \"audiogoal\": np.zeros([batch_length, 2, 16000]),\n",
    "                \"spectrogram\": np.zeros([batch_length, 65, 26, 2])\n",
    "            }\n",
    "            action_list, reward_list, done_list = \\\n",
    "                np.zeros([batch_length, 1]), \\\n",
    "                np.zeros([batch_length, 1]), \\\n",
    "                np.zeros([batch_length, 1])\n",
    "            \n",
    "            ssf = 0 # Step affected so far\n",
    "            while ssf < batch_length:\n",
    "                idx = th.randint(len(self.ep_filenames), ())\n",
    "                print(f\"Sampled traj idx: {idx}\")\n",
    "                ep_filename = self.ep_filenames[idx]\n",
    "                ep_filepath = os.path.join(self.dataset_path, ep_filename)\n",
    "                with open(ep_filepath, \"rb\") as f:\n",
    "                    edd = cpkl.load(f)\n",
    "\n",
    "                # Append the data to the bathc trjectory\n",
    "                rs = batch_length - ssf # Reamining steps\n",
    "                edd_start = th.randint(0, edd[\"ep_length\"]-20) # Sample start of sub-squence for this episode\n",
    "                edd_end = min(edd_start + rs, edd[\"ep_length\"])\n",
    "                subseq_len = edd_end - edd_start # + 1 ?\n",
    "\n",
    "                horizon = ssf + subseq_len\n",
    "\n",
    "                for k, v in edd[\"obs_list\"].items():\n",
    "                    obs_list[k][ssf:horizon] = v[edd_start:edd_end]\n",
    "                action_list[ssf:horizon] = edd[\"action_list\"][edd_start:edd_end]\n",
    "                reward_list[ssf:horizon] = np.array(edd[\"reward_list\"][edd_start:edd_end])[:, None]\n",
    "                done_list[ssf:horizon] = np.array(edd[\"done_list\"][edd_start:edd_end])[:, None]\n",
    "\n",
    "                ssf += subseq_len\n",
    "\n",
    "                if ssf >= self.batch_length:\n",
    "                    break\n",
    "\n",
    "            yield obs_list, action_list, reward_list, done_list\n",
    "    \n",
    "def make_dataloader2(dataset_path, batch_size, batch_length, seed=111, num_workers=4):\n",
    "    def worker_init_fn(worker_id):\n",
    "        # worker_seed = th.initial_seed() % (2 ** 32)\n",
    "        worker_seed = 133754134 + worker_id\n",
    "\n",
    "        random.seed(worker_seed)\n",
    "        np.random.seed(worker_seed)\n",
    "\n",
    "    th_seed_gen = th.Generator()\n",
    "    th_seed_gen.manual_seed(133754134 + seed)\n",
    "\n",
    "    dloader = iter(\n",
    "        DataLoader(\n",
    "            BCIterableDataset2(\n",
    "                dataset_path=dataset_path, batch_length=batch_length),\n",
    "                batch_size=batch_size, num_workers=num_workers,\n",
    "                worker_init_fn=worker_init_fn, generator=th_seed_gen\n",
    "            )\n",
    "    )\n",
    "\n",
    "    return dloader\n",
    "\n",
    "dloader = make_dataloader2(DATASET_DIR_PATH, batch_size=1, batch_length=30)\n",
    "for _ in range(2):\n",
    "    obs_batch, action_batch, reward_batch, done_batch = next(dloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ss-hab-headless-py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8606c1569764bc263c51958f68bba938f45460ba430fa08f16cdd64c0c2e55c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
