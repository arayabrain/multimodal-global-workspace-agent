{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook support or argpase\n",
    "import sys; sys.argv=['']; del sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rousslan/anaconda3/envs/ss-hab-headless-py39/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import apex\n",
    "\n",
    "from collections import deque\n",
    "from torchinfo import summary\n",
    "\n",
    "import tools\n",
    "from configurator import generate_args, get_arg_dict\n",
    "from th_logger import TBXLogger as TBLogger\n",
    "\n",
    "# Env deps: Soundspaces and Habitat\n",
    "from habitat.datasets import make_dataset\n",
    "from ss_baselines.av_nav.config import get_config\n",
    "from ss_baselines.savi.config.default import get_config as get_savi_config\n",
    "from ss_baselines.common.env_utils import construct_envs\n",
    "from ss_baselines.common.environments import get_env_class\n",
    "from ss_baselines.common.utils import images_to_video_with_audio\n",
    "\n",
    "# Custom ActorCritic agent for PPO\n",
    "from models import ActorCritic, ActorCritic_DeepEthologyVirtualRodent, \\\n",
    "    Perceiver_GWT_GWWM_ActorCritic, Perceiver_GWT_AttGRU_ActorCritic\n",
    "\n",
    "# Dataset utils\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "import compress_pickle as cpkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This variant will sample one single (sub) seuqence of an episode as a trajectoyr\n",
    "# and add zero paddign to the rest\n",
    "class BCIterableDataset3(IterableDataset):\n",
    "    def __init__(self, dataset_path, batch_length, seed=111):\n",
    "        self.seed = seed\n",
    "        self.batch_length = batch_length\n",
    "        self.dataset_path = dataset_path\n",
    "\n",
    "        # Read episode filenames in the dataset path\n",
    "        self.ep_filenames = os.listdir(dataset_path)\n",
    "        if \"dataset_statistics.bz2\" in self.ep_filenames:\n",
    "            self.ep_filenames.remove(\"dataset_statistics.bz2\")\n",
    "        \n",
    "        print(f\"Initialized IterDset with {len(self.ep_filenames)} episodes.\")\n",
    "    \n",
    "    def __iter__(self):\n",
    "        batch_length = self.batch_length\n",
    "        while True:\n",
    "            # Sample one episode file\n",
    "            idx = th.randint(len(self.ep_filenames), ())\n",
    "            ep_filename = self.ep_filenames[idx]\n",
    "            ep_filepath = os.path.join(self.dataset_path, ep_filename)\n",
    "            with open(ep_filepath, \"rb\") as f:\n",
    "                edd = cpkl.load(f)\n",
    "            is_success = edd[\"info_list\"][-1][\"success\"]\n",
    "            last_action = edd[\"action_list\"][-1]\n",
    "            print(f\"Sampled traj idx: {idx}; Length: {edd['ep_length']}; Success: {is_success}; Last act: {last_action}\")\n",
    "            \n",
    "            # edd_start = th.randint(0, edd[\"ep_length\"]-20, ()).item() # Sample start of sub-squence for this episode\n",
    "            # NOTE: the following sampling might not leverage long-term trajectories well.\n",
    "            edd_start = 0 # Given that we have short trajectories, just start at the beginning anyway\n",
    "            edd_end = min(edd_start + batch_length, edd[\"ep_length\"])\n",
    "            subseq_len = edd_end - edd_start\n",
    "            \n",
    "            horizon = subseq_len\n",
    "\n",
    "            obs_list = {\n",
    "                k: np.zeros([batch_length, *np.shape(v)[1:]]) for k,v in edd[\"obs_list\"].items()\n",
    "            }\n",
    "            action_list, reward_list, done_list, depad_mask_list = \\\n",
    "                np.zeros([batch_length, 1]), \\\n",
    "                np.zeros([batch_length, 1]), \\\n",
    "                np.zeros([batch_length, 1]), \\\n",
    "                np.zeros((batch_length, 1)).astype(np.bool8)\n",
    "\n",
    "            for k, v in edd[\"obs_list\"].items():\n",
    "                obs_list[k][:horizon] = v[edd_start:edd_end]\n",
    "                # Adjust the shape of obs_list[\"depth\"] from (128,128 -> (128, 128, 1))\n",
    "            obs_list[\"depth\"] = obs_list[\"depth\"][:, :, None]\n",
    "            action_list[:horizon] = np.array(edd[\"action_list\"][edd_start:edd_end])[:, None]\n",
    "            reward_list[:horizon] = np.array(edd[\"reward_list\"][edd_start:edd_end])[:, None]\n",
    "            done_list[:horizon] = np.array(edd[\"done_list\"][edd_start:edd_end])[:, None]\n",
    "            depad_mask_list[:horizon] = True\n",
    "\n",
    "            yield obs_list, action_list, reward_list, done_list, depad_mask_list\n",
    "    \n",
    "def make_dataloader3(dataset_path, batch_size, batch_length, seed=111, num_workers=2):\n",
    "    def worker_init_fn(worker_id):\n",
    "        # worker_seed = th.initial_seed() % (2 ** 32)\n",
    "        worker_seed = 133754134 + worker_id\n",
    "\n",
    "        random.seed(worker_seed)\n",
    "        np.random.seed(worker_seed)\n",
    "\n",
    "    th_seed_gen = th.Generator()\n",
    "    th_seed_gen.manual_seed(133754134 + seed)\n",
    "\n",
    "    dloader = iter(\n",
    "        DataLoader(\n",
    "            BCIterableDataset3(\n",
    "                dataset_path=dataset_path, batch_length=batch_length),\n",
    "                batch_size=batch_size, num_workers=num_workers,\n",
    "                worker_init_fn=worker_init_fn, generator=th_seed_gen\n",
    "            )\n",
    "    )\n",
    "\n",
    "    return dloader\n",
    "\n",
    "# Tensorize current observation, store to rollout data\n",
    "def tensorize_obs_dict(obs, device, observations=None, rollout_step=None):\n",
    "    obs_th = {}\n",
    "    for obs_field, _ in obs[0].items():\n",
    "        v_th = th.Tensor(np.array([step_obs[obs_field] for step_obs in obs], dtype=np.float32)).to(device)\n",
    "        # in SS1.0, the dcepth observations comes as [B, 128, 128, 1, 1], so fix that\n",
    "        if obs_field == \"depth\" and v_th.dim() == 5:\n",
    "            v_th = v_th.squeeze(-1)\n",
    "        obs_th[obs_field] = v_th\n",
    "        # Special case when doing the rollout, also stores the \n",
    "        if observations is not None:\n",
    "            observations[obs_field][rollout_step] = v_th\n",
    "    \n",
    "    return obs_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 18:23:02.207129: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-18 18:23:04,295 Initializing dataset SemanticAudioNav\n",
      "2023-05-18 18:23:04,313 Initializing dataset SemanticAudioNav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Logdir: ./logs/_seed_111__2023_05_18_18_23_01_823608.musashi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 18:23:23,560 initializing sim SoundSpacesSim\n",
      "2023-05-18 18:23:23,944 Initializing task SemanticAudioNav\n",
      "2023-05-18 18:23:24,025 Initializing dataset SemanticAudioNav\n",
      "2023-05-18 18:23:49,643 initializing sim SoundSpacesSim\n",
      "2023-05-18 18:23:50,052 Initializing task SemanticAudioNav\n"
     ]
    }
   ],
   "source": [
    "# region: Generating additional hyparams\n",
    "CUSTOM_ARGS = [\n",
    "    # General hyper parameters\n",
    "    get_arg_dict(\"seed\", int, 111),\n",
    "    get_arg_dict(\"total-steps\", int, 1_000_000),\n",
    "    \n",
    "    # Behavior cloning gexperiment config\n",
    "    get_arg_dict(\"dataset-path\", str, \"SAVI_Oracle_Dataset_v0\"),\n",
    "\n",
    "    # SS env config\n",
    "    get_arg_dict(\"config-path\", str, \"env_configs/savi/savi_ss1.yaml\"),\n",
    "\n",
    "    # PPO Hyper parameters\n",
    "    get_arg_dict(\"num-envs\", int, 10), # Number of parallel envs. 10 by default\n",
    "    get_arg_dict(\"num-steps\", int, 150), # For each env, how many steps are collected to form PPO Agent rollout.\n",
    "    get_arg_dict(\"num-minibatches\", int, 1), # Number of mini-batches the rollout data is split into to make the updates\n",
    "    get_arg_dict(\"update-epochs\", int, 4), # Number of gradient step for the policy and value networks\n",
    "    get_arg_dict(\"gamma\", float, 0.99),\n",
    "    get_arg_dict(\"gae-lambda\", float, 0.95),\n",
    "    get_arg_dict(\"norm-adv\", bool, True, metatype=\"bool\"),\n",
    "    get_arg_dict(\"clip-coef\", float, 0.1), # Surrogate loss clipping coefficient\n",
    "    get_arg_dict(\"clip-vloss\", bool, True, metatype=\"bool\"),\n",
    "    get_arg_dict(\"ent-coef\", float, 0.0), # Entropy loss coef; 0.2 in SS baselines\n",
    "    get_arg_dict(\"vf-coef\", float, 0.5), # Value loss coefficient\n",
    "    get_arg_dict(\"max-grad-norm\", float, 0.5),\n",
    "    get_arg_dict(\"target-kl\", float, None),\n",
    "    get_arg_dict(\"lr\", float, 2.5e-4), # Learning rate\n",
    "    get_arg_dict(\"optim-wd\", float, 0), # weight decay for adam optim\n",
    "    ## Agent network params\n",
    "    get_arg_dict(\"agent-type\", str, \"ss-default\", metatype=\"choice\",\n",
    "        choices=[\"ss-default\", \"deep-etho\",\n",
    "                    \"perceiver-gwt-gwwm\", \"perceiver-gwt-attgru\"]),\n",
    "    get_arg_dict(\"hidden-size\", int, 512), # Size of the visual / audio features and RNN hidden states \n",
    "    ## Perceiver / PerceiverIO params: TODO: num_latnets, latent_dim, etc...\n",
    "    get_arg_dict(\"pgwt-latent-type\", str, \"randn\", metatype=\"choice\",\n",
    "        choices=[\"randn\", \"zeros\"]), # Depth of the Perceiver\n",
    "    get_arg_dict(\"pgwt-latent-learned\", bool, True, metatype=\"bool\"),\n",
    "    get_arg_dict(\"pgwt-depth\", int, 1), # Depth of the Perceiver\n",
    "    get_arg_dict(\"pgwt-num-latents\", int, 8),\n",
    "    get_arg_dict(\"pgwt-latent-dim\", int, 64),\n",
    "    get_arg_dict(\"pgwt-cross-heads\", int, 1),\n",
    "    get_arg_dict(\"pgwt-latent-heads\", int, 4),\n",
    "    get_arg_dict(\"pgwt-cross-dim-head\", int, 64),\n",
    "    get_arg_dict(\"pgwt-latent-dim-head\", int, 64),\n",
    "    get_arg_dict(\"pgwt-weight-tie-layers\", bool, False, metatype=\"bool\"),\n",
    "    get_arg_dict(\"pgwt-ff\", bool, False, metatype=\"bool\"),\n",
    "    get_arg_dict(\"pgwt-num-freq-bands\", int, 6),\n",
    "    get_arg_dict(\"pgwt-max-freq\", int, 10.),\n",
    "    get_arg_dict(\"pgwt-use-sa\", bool, False, metatype=\"bool\"),\n",
    "    ## Peceiver Modality Embedding related\n",
    "    get_arg_dict(\"pgwt-mod-embed\", int, 0), # Learnable modality embeddings\n",
    "    ## Additional modalities\n",
    "    get_arg_dict(\"pgwt-ca-prev-latents\", bool, False, metatype=\"bool\"), # if True, passes the prev latent to CA as KV input data\n",
    "\n",
    "    ## Special BC\n",
    "    get_arg_dict(\"prev-actions\", bool, False, metatype=\"bool\"),\n",
    "    get_arg_dict(\"burn-in\", int, 0), # Steps used to init the latent state for RNN component\n",
    "    get_arg_dict(\"batch-chunk-length\", int, 0), # For gradient accumulation\n",
    "    get_arg_dict(\"ce-weights\", float, None, metatype=\"list\"), # Weights for the Cross Entropy loss\n",
    "    get_arg_dict(\"dataset-ce-weights\", bool, True, metatype=\"bool\"),\n",
    "\n",
    "    # Eval protocol\n",
    "    get_arg_dict(\"eval\", bool, True, metatype=\"bool\"),\n",
    "    get_arg_dict(\"eval-every\", int, int(1.5e4)), # Every X frames || steps sampled\n",
    "    get_arg_dict(\"eval-n-episodes\", int, 5),\n",
    "\n",
    "    # Logging params\n",
    "    # NOTE: While supported, video logging is expensive because the RGB generation in the\n",
    "    # envs hogs a lot of GPU, especially with multiple envs \n",
    "    get_arg_dict(\"save-videos\", bool, False, metatype=\"bool\"),\n",
    "    get_arg_dict(\"save-model\", bool, True, metatype=\"bool\"),\n",
    "    get_arg_dict(\"log-sampling-stats-every\", int, int(1.5e3)), # Every X frames || steps sampled\n",
    "    get_arg_dict(\"log-training-stats-every\", int, int(10)), # Every X model update\n",
    "    get_arg_dict(\"logdir-prefix\", str, \"./logs/\") # Overrides the default one\n",
    "]\n",
    "args = generate_args(CUSTOM_ARGS)\n",
    "# endregion: Generating additional hyparams\n",
    "\n",
    "# Load environment config\n",
    "is_SAVi = str.__contains__(args.config_path, \"savi\")\n",
    "if is_SAVi:\n",
    "    env_config = get_savi_config(config_paths=args.config_path)\n",
    "else:\n",
    "    env_config = get_config(config_paths=args.config_path)\n",
    "\n",
    "# Additional PPO overrides\n",
    "args.batch_size = int(args.num_envs * args.num_steps)\n",
    "args.minibatch_size = int(args.batch_size // args.num_minibatches)\n",
    "\n",
    "# Gradient accumulation support\n",
    "if args.batch_chunk_length == 0:\n",
    "    args.batch_chunk_length = args.num_envs\n",
    "\n",
    "# Experiment logger\n",
    "tblogger = TBLogger(exp_name=args.exp_name, args=args)\n",
    "print(f\"# Logdir: {tblogger.logdir}\")\n",
    "should_log_training_stats = tools.Every(args.log_training_stats_every)\n",
    "should_eval = tools.Every(args.eval_every)\n",
    "\n",
    "# Seeding\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "th.manual_seed(args.seed)\n",
    "th.cuda.manual_seed_all(args.seed)\n",
    "th.backends.cudnn.deterministic = args.torch_deterministic\n",
    "# th.backends.cudnn.benchmark = args.cudnn_benchmark\n",
    "\n",
    "# Set device as GPU\n",
    "device = tools.get_device(args) if (not args.cpu and th.cuda.is_available()) else th.device(\"cpu\")\n",
    "\n",
    "# Overriding some envs parametes from the .yaml env config\n",
    "env_config.defrost()\n",
    "# NOTE: using less environments for eval to save up system memory -> run more experiment at thte same time\n",
    "env_config.NUM_PROCESSES = 2 # Corresponds to number of envs, makes script startup faster for debugs\n",
    "# env_config.CONTINUOUS = args.env_continuous\n",
    "## In caes video saving is enabled, make sure there is also the rgb videos\n",
    "agent_extra_rgb = False\n",
    "if args.save_videos:\n",
    "    # For RGB video sensors\n",
    "    if \"RGB_SENSOR\" not in env_config.SENSORS:\n",
    "        env_config.SENSORS.append(\"RGB_SENSOR\")\n",
    "        # Indicates to the agent that RGB obs should not be used as observational inputs\n",
    "        agent_extra_rgb = True\n",
    "    # For Waveform to generate audio over the videos\n",
    "    if \"AUDIOGOAL_SENSOR\" not in env_config.TASK_CONFIG.TASK.SENSORS:\n",
    "        env_config.TASK_CONFIG.TASK.SENSORS.append(\"AUDIOGOAL_SENSOR\")\n",
    "env_config.freeze()\n",
    "# print(env_config)\n",
    "\n",
    "# Environment instantiation\n",
    "envs = construct_envs(env_config, get_env_class(env_config.ENV_NAME))\n",
    "single_observation_space = envs.observation_spaces[0]\n",
    "single_action_space = envs.action_spaces[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized IterDset with 2357 episodes.\n",
      "Sampled traj idx: 786; Length: 14; Success: 1.0; Last act: 0\n",
      "Sampled traj idx: 1740; Length: 15; Success: 1.0; Last act: 0\n",
      "\n",
      "ActorCritic(\n",
      "  (visual_encoder): VisualCNN(\n",
      "    (cnn): Sequential(\n",
      "      (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (5): Flatten()\n",
      "      (6): Linear(in_features=2304, out_features=512, bias=True)\n",
      "      (7): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (audio_encoder): AudioCNN(\n",
      "    (cnn): Sequential(\n",
      "      (0): Conv2d(2, 32, kernel_size=(5, 5), stride=(2, 2))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (5): Flatten()\n",
      "      (6): Linear(in_features=2496, out_features=512, bias=True)\n",
      "      (7): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (state_encoder): RNNStateEncoder(\n",
      "    (rnn): GRU(1024, 512)\n",
      "  )\n",
      "  (action_distribution): CategoricalNet(\n",
      "    (linear): Linear(in_features=512, out_features=4, bias=True)\n",
      "  )\n",
      "  (critic): CriticHead(\n",
      "    (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled traj idx: 2273; Length: 12; Success: 1.0; Last act: 0\n",
      "Sampled traj idx: 153; Length: 18; Success: 1.0; Last act: 0\n",
      "Sampled traj idx: 532; Length: 8; Success: 1.0; Last act: 0\n",
      "Sampled traj idx: 725; Length: 21; Success: 1.0; Last act: 0\n",
      "Sampled traj idx: 2309; Length: 11; Success: 1.0; Last act: 0\n",
      "Sampled traj idx: 1671; Length: 13; Success: 1.0; Last act: 0\n",
      "Sampled traj idx: 636; Length: 12; Success: 1.0; Last act: 0\n",
      "Sampled traj idx: 104; Length: 15; Success: 1.0; Last act: 0\n",
      "Sampled traj idx: 506; Length: 35; Success: 1.0; Last act: 0\n",
      "Sampled traj idx: 2002; Length: 15; Success: 1.0; Last act: 0\n",
      "Sampled traj idx: 1598; Length: 25; Success: 1.0; Last act: 0\n",
      "Sampled traj idx: 76; Length: 11; Success: 1.0; Last act: 0\n",
      "Sampled traj idx: 725; Length: 21; Success: 1.0; Last act: 0\n",
      "Sampled traj idx: 291; Length: 37; Success: 1.0; Last act: 0\n",
      "Sampled traj idx: 808; Length: 19; Success: 1.0; Last act: 0\n",
      "Sampled traj idx: 1474; Length: 17; Success: 1.0; Last act: 0\n",
      "Sampled traj idx: 1714; Length: 7; Success: 1.0; Last act: 0\n",
      "Sampled traj idx: 888; Length: 25; Success: 1.0; Last act: 0\n",
      "Sampled traj idx: 770; Length: 10; Success: 1.0; Last act: 0\n",
      "Sampled traj idx: 1688; Length: 10; Success: 1.0; Last act: 0\n",
      "Sampled traj idx: 692; Length: 8; Success: 1.0; Last act: 0\n",
      "Sampled traj idx: 1967; Length: 50; Success: 1.0; Last act: 0\n",
      "Sampled traj idx: 1047; Length: 27; Success: 1.0; Last act: 0\n",
      "Sampled traj idx: 1087; Length: 8; Success: 1.0; Last act: 0\n",
      "Sampled traj idx: 1589; Length: 10; Success: 1.0; Last act: 0\n",
      "Sampled traj idx: 28; Length: 6; Success: 1.0; Last act: 0\n",
      "Sampled traj idx: 2264; Length: 15; Success: 1.0; Last act: 0\n",
      "Sampled traj idx: 1308; Length: 15; Success: 1.0; Last act: 0\n"
     ]
    }
   ],
   "source": [
    "# TODO: delete the envrionemtsn / find a more efficient method to do this\n",
    "\n",
    "# TODO: make the ActorCritic components parameterizable through comand line ?\n",
    "if args.agent_type == \"ss-default\":\n",
    "    agent = ActorCritic(single_observation_space, single_action_space,\n",
    "        args.hidden_size, extra_rgb=agent_extra_rgb, prev_actions=args.prev_actions).to(device)\n",
    "elif args.agent_type == \"perceiver-gwt-gwwm\":\n",
    "    agent = Perceiver_GWT_GWWM_ActorCritic(single_observation_space, single_action_space,\n",
    "        args, extra_rgb=agent_extra_rgb).to(device)\n",
    "elif args.agent_type == \"perceiver-gwt-attgru\":\n",
    "    agent = Perceiver_GWT_AttGRU_ActorCritic(single_observation_space, single_action_space,\n",
    "        args, extra_rgb=agent_extra_rgb).to(device)\n",
    "elif args.agent_type == \"deep-etho\":\n",
    "    raise NotImplementedError(f\"Unsupported agent-type:{args.agent_type}\")\n",
    "    # TODO: support for storing the rnn_hidden_statse, so that the policy \n",
    "    # that takes in the 'core_modules' 's rnn hidden output can also work.\n",
    "    agent = ActorCritic_DeepEthologyVirtualRodent(single_observation_space,\n",
    "            single_action_space, 512).to(device)\n",
    "else:\n",
    "    raise NotImplementedError(f\"Unsupported agent-type:{args.agent_type}\")\n",
    "\n",
    "if not args.cpu and th.cuda.is_available():\n",
    "    # TODO: GPU only. But what if we still want to use the default pytorch one ?\n",
    "    optimizer = apex.optimizers.FusedAdam(agent.parameters(), lr=args.lr, eps=1e-5, weight_decay=args.optim_wd)\n",
    "else:\n",
    "    optimizer = th.optim.Adam(agent.parameters(), lr=args.lr, eps=1e-5, weight_decay=args.optim_wd)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Dataset loading\n",
    "dloader = make_dataloader3(args.dataset_path, batch_size=args.num_envs,\n",
    "                            batch_length=args.num_steps, seed=args.seed)\n",
    "\n",
    "## Compute action coefficient for CEL of BC\n",
    "dataset_stats_filepath = f\"{args.dataset_path}/dataset_statistics.bz2\"\n",
    "# Override dataset statistics if the file already exists\n",
    "if os.path.exists(dataset_stats_filepath):\n",
    "    with open(dataset_stats_filepath, \"rb\") as f:\n",
    "        dataset_statistics = cpkl.load(f)\n",
    "\n",
    "# Reads args.ce_weights if passed\n",
    "ce_weights = args.ce_weights\n",
    "\n",
    "# In case args.dataset_ce_weights is True,\n",
    "# override the args.ce_weigths manual setting\n",
    "if args.dataset_ce_weights:\n",
    "    # TODO: make some assert on 1) the existence of the \"dataset_statistics.bz2\" file\n",
    "    # and 2) that it contains the \"action_cel_coefs\" of proper dimension\n",
    "    ce_weights = [dataset_statistics[\"action_cel_coefs\"][a] for a in range(4)]\n",
    "\n",
    "if ce_weights is not None:\n",
    "    # TODO: assert it has same shape as action space.\n",
    "    ce_weights = th.Tensor(ce_weights).to(device)\n",
    "\n",
    "# Info logging\n",
    "summary(agent)\n",
    "print(\"\")\n",
    "print(agent)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.6824, 0.3606, 2.1973, 1.7908], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_list, action_list, _, done_list, depad_mask_list = \\\n",
    "    [ {k: th.Tensor(v).float().to(device) for k,v in b.items()} if isinstance(b, dict) else \n",
    "        b.float().to(device) for b in next(dloader)] # NOTE this will not suport \"audiogoal\" waveform audio, only rgb / depth / spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_list.shape, done_list.shape, depad_mask_list.shape, obs_list[\"rgb\"].shape, obs_list[\"depth\"].shape, obs_list[\"spectrogram\"].shape, obs_list[\"audiogoal\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(dataset_statistics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ss-hab-headless-py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
