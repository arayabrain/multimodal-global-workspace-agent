{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook support or argpase\n",
    "import sys; sys.argv=['']; del sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rousslan/anaconda3/envs/ss-hab-headless-py39/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import apex\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import compress_pickle as cpkl\n",
    "\n",
    "import rsatoolbox\n",
    "from torchinfo import summary\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.gridspec import GridSpec\n",
    "# plt.style.use(\"seaborn-darkgrid\")\n",
    "\n",
    "import models\n",
    "from models import GW_Actor, GRU_Actor\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "%matplotlib inline\n",
    "\n",
    "from ss_baselines.common.utils import plot_top_down_map\n",
    "\n",
    "\n",
    "mpl.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "mpl.rcParams[\"axes.facecolor\"] = \"white\"\n",
    "mpl.rcParams[\"savefig.facecolor\"] = \"white\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General config related\n",
    "from configurator import get_arg_dict, generate_args\n",
    "\n",
    "# Env config related\n",
    "from ss_baselines.av_nav.config import get_config\n",
    "from ss_baselines.savi.config.default import get_config as get_savi_config\n",
    "from ss_baselines.common.env_utils import construct_envs\n",
    "from ss_baselines.common.environments import get_env_class\n",
    "\n",
    "# region: Generating additional hyparams\n",
    "CUSTOM_ARGS = [\n",
    "\t# General hyper parameters\n",
    "\tget_arg_dict(\"seed\", int, 111),\n",
    "\tget_arg_dict(\"total-steps\", int, 1_000_000),\n",
    "\n",
    "\t# Behavior cloning gexperiment config\n",
    "\tget_arg_dict(\"dataset-path\", str, \"SAVI_Oracle_Dataset_v0\"),\n",
    "\n",
    "\t# SS env config\n",
    "\tget_arg_dict(\"config-path\", str, \"env_configs/savi/savi_ss1_rgb_spectro.yaml\"),\n",
    "\n",
    "\t# PPO Hyper parameters\n",
    "\tget_arg_dict(\"num-envs\", int, 10), # Number of parallel envs. 10 by default\n",
    "\tget_arg_dict(\"num-steps\", int, 150), # For each env, how many steps are collected to form PPO Agent rollout.\n",
    "\tget_arg_dict(\"num-minibatches\", int, 1), # Number of mini-batches the rollout data is split into to make the updates\n",
    "\tget_arg_dict(\"update-epochs\", int, 4), # Number of gradient step for the policy and value networks\n",
    "\tget_arg_dict(\"gamma\", float, 0.99),\n",
    "\tget_arg_dict(\"gae-lambda\", float, 0.95),\n",
    "\tget_arg_dict(\"norm-adv\", bool, True, metatype=\"bool\"),\n",
    "\tget_arg_dict(\"clip-coef\", float, 0.1), # Surrogate loss clipping coefficient\n",
    "\tget_arg_dict(\"clip-vloss\", bool, True, metatype=\"bool\"),\n",
    "\tget_arg_dict(\"ent-coef\", float, 0.2), # Entropy loss coef; 0.2 in SS baselines\n",
    "\tget_arg_dict(\"vf-coef\", float, 0.5), # Value loss coefficient\n",
    "\tget_arg_dict(\"max-grad-norm\", float, 0.5),\n",
    "\tget_arg_dict(\"target-kl\", float, None),\n",
    "\tget_arg_dict(\"lr\", float, 2.5e-4), # Learning rate\n",
    "\tget_arg_dict(\"optim-wd\", float, 0), # weight decay for adam optim\n",
    "\t## Agent network params\n",
    "\tget_arg_dict(\"agent-type\", str, \"gw\", metatype=\"choice\",\n",
    "\t\tchoices=[\"gw\", \"gru\"]),\n",
    "\tget_arg_dict(\"gru-type\", str, \"layernorm\", metatype=\"choice\",\n",
    "\t\t\t\t\tchoices=[\"default\", \"layernorm\"]),\n",
    "\tget_arg_dict(\"hidden-size\", int, 512), # Size of the visual / audio features\n",
    "\n",
    "\t## BC related hyper parameters\n",
    "\tget_arg_dict(\"batch-chunk-length\", int, 0), # For gradient accumulation\n",
    "\tget_arg_dict(\"dataset-ce-weights\", bool, False, metatype=\"bool\"), # If True, will read CEL weights based on action dist. from the 'dataset_statistics.bz2' file.\n",
    "\tget_arg_dict(\"ce-weights\", float, None, metatype=\"list\"), # Weights for the Cross Entropy loss\n",
    "\n",
    "\t## GW Agent with custom attention, recurrent encoder and null inputs\n",
    "\tget_arg_dict(\"gw-size\", int, 512), # Dim of the GW vector\n",
    "\tget_arg_dict(\"recenc-use-gw\", bool, True, metatype=\"bool\"), # Use GW at Recur. Enc. level\n",
    "\tget_arg_dict(\"recenc-gw-detach\", bool, True, metatype=\"bool\"), # When using GW at Recurrent Encoder level, whether to detach the grads or not\n",
    "\tget_arg_dict(\"gw-use-null\", bool, True, metatype=\"bool\"), # Use Null at CrossAtt level\n",
    "\tget_arg_dict(\"gw-cross-heads\", int, 1), # num_heads of the CrossAttn\n",
    "\n",
    "\t# Eval protocol\n",
    "\tget_arg_dict(\"eval\", bool, True, metatype=\"bool\"),\n",
    "\tget_arg_dict(\"eval-every\", int, int(1.5e4)), # Every X frames || steps sampled\n",
    "\tget_arg_dict(\"eval-n-episodes\", int, 5),\n",
    "\n",
    "\t# Logging params\n",
    "\t# NOTE: Video logging expensive\n",
    "\tget_arg_dict(\"save-videos\", bool, False, metatype=\"bool\"),\n",
    "\tget_arg_dict(\"save-model\", bool, True, metatype=\"bool\"),\n",
    "\tget_arg_dict(\"save-model-every\", int, int(5e5)), # Every X frames || steps sampled\n",
    "\tget_arg_dict(\"log-sampling-stats-every\", int, int(1.5e3)), # Every X frames || steps sampled\n",
    "\tget_arg_dict(\"log-training-stats-every\", int, int(10)), # Every X model update\n",
    "\tget_arg_dict(\"logdir-prefix\", str, \"./logs/\") # Overrides the default one\n",
    "]\n",
    "args = generate_args(CUSTOM_ARGS)\n",
    "# endregion: Generating additional hyparams\n",
    "\n",
    "# Load environment config\n",
    "is_SAVi = str.__contains__(args.config_path, \"savi\")\n",
    "if is_SAVi:\n",
    "\tenv_config = get_savi_config(config_paths=args.config_path)\n",
    "else:\n",
    "\tenv_config = get_config(config_paths=args.config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate obs / act space based on args and env_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dict(audiogoal:Box(-3.4028235e+38, 3.4028235e+38, (2, 16000), float32), rgb:Box(0, 255, (128, 128, 3), uint8), spectrogram:Box(-3.4028235e+38, 3.4028235e+38, (65, 26, 2), float32)),\n",
       " Discrete(4))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overriding some envs parametes from the .yaml env config\n",
    "env_config.defrost()\n",
    "env_config.NUM_PROCESSES = 1 # Corresponds to number of envs, makes script startup faster for debugs\n",
    "env_config.USE_SYNC_VECENV = True\n",
    "# env_config.USE_VECENV = False\n",
    "# env_config.CONTINUOUS = args.env_continuous\n",
    "## In caes video saving is enabled, make sure there is also the rgb videos\n",
    "env_config.freeze()\n",
    "# print(env_config)\n",
    "\n",
    "# Environment instantiation\n",
    "# envs = construct_envs(env_config, get_env_class(env_config.ENV_NAME))\n",
    "# Dummy environment spaces\n",
    "\n",
    "# TODO: add dyanmicallly set single_observation_space so that RGB and RGBD based variants\n",
    "# can be evaluated at thet same time\n",
    "from gym import spaces\n",
    "single_action_space = spaces.Discrete(4)\n",
    "single_observation_space = spaces.Dict({\n",
    "    \"rgb\": spaces.Box(shape=[128,128,3], low=0, high=255, dtype=np.uint8),\n",
    "    # \"depth\": spaces.Box(shape=[128,128,1], low=0, high=255, dtype=np.uint8),\n",
    "    \"audiogoal\": spaces.Box(shape=[2,16000], low=-3.4028235e+38, high=3.4028235e+38, dtype=np.float32),\n",
    "    \"spectrogram\": spaces.Box(shape=[65,26,2], low=-3.4028235e+38, high=3.4028235e+38, dtype=np.float32)\n",
    "})\n",
    "# single_observation_space = envs.observation_spaces[0]\n",
    "# single_action_space = envs.action_spaces[0]\n",
    "\n",
    "single_observation_space, single_action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Category-Scene-Trajs, Scene-Category-Trajs, and Dataset's metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loads data for analysis, as well as dataset's metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Read the filtred trajectories data\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m## Default format is {cat -> { scenes -> traj: []}}\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(analysis_trajs_filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 7\u001b[0m     cats_scenes_trajs_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcpkl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m## Compute the equivalent scenes cat trajs format\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m## {scenes -> { cat -> trajs: []}}\u001b[39;00m\n\u001b[1;32m     11\u001b[0m scenes_cats_trajs_dict \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/anaconda3/envs/ss-hab-headless-py39/lib/python3.9/site-packages/compress_pickle/compress_pickle.py:272\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, compression, pickler_method, pickler_kwargs, mode, set_default_extension, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m     pickler_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 272\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43muncompress_and_unpickle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompresser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpickler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickler_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    278\u001b[0m     compresser\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/ss-hab-headless-py39/lib/python3.9/functools.py:888\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    886\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 888\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ss-hab-headless-py39/lib/python3.9/site-packages/compress_pickle/io/base.py:99\u001b[0m, in \u001b[0;36mdefault_uncompress_and_unpickle\u001b[0;34m(compresser, pickler, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;129m@uncompress_and_unpickle\u001b[39m\u001b[38;5;241m.\u001b[39mregister(BaseCompresser)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_uncompress_and_unpickle\u001b[39m(\n\u001b[1;32m     97\u001b[0m     compresser: BaseCompresser, pickler: BasePicklerIO, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     98\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompresser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ss-hab-headless-py39/lib/python3.9/site-packages/compress_pickle/picklers/pickle.py:45\u001b[0m, in \u001b[0;36mBuiltinPicklerIO.load\u001b[0;34m(self, stream, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, stream: IO[\u001b[38;5;28mbytes\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124;03m\"\"\"Load a serialized binary representation of an object from a stream.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m        The python object that was loaded.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ss-hab-headless-py39/lib/python3.9/bz2.py:161\u001b[0m, in \u001b[0;36mBZ2File.peek\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_can_read()\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# Relies on the undocumented fact that BufferedReader.peek()\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# always returns at least one byte (except at EOF), independent\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# of the value of n\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpeek\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ss-hab-headless-py39/lib/python3.9/_compression.py:68\u001b[0m, in \u001b[0;36mDecompressReader.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadinto\u001b[39m(\u001b[38;5;28mself\u001b[39m, b):\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b) \u001b[38;5;28;01mas\u001b[39;00m view, view\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m byte_view:\n\u001b[0;32m---> 68\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbyte_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m         byte_view[:\u001b[38;5;28mlen\u001b[39m(data)] \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/ss-hab-headless-py39/lib/python3.9/_compression.py:103\u001b[0m, in \u001b[0;36mDecompressReader.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m         rawblock \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 103\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decompressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrawblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Specify file name\n",
    "analysis_trajs_filename = \"cats_scenes_trajs_C_6_M_5_N_5__2023_06_01_10_41.bz2\"\n",
    "\n",
    "# Read the filtred trajectories data\n",
    "## Default format is {cat -> { scenes -> traj: []}}\n",
    "with open(analysis_trajs_filename, \"rb\") as f:\n",
    "    cats_scenes_trajs_dict = cpkl.load(f)\n",
    "\n",
    "## Compute the equivalent scenes cat trajs format\n",
    "## {scenes -> { cat -> trajs: []}}\n",
    "scenes_cats_trajs_dict = {}\n",
    "for cat, cat_scenes_trajs in cats_scenes_trajs_dict.items():\n",
    "    for scene, scenes_trajs in cat_scenes_trajs.items():\n",
    "        if scene not in scenes_cats_trajs_dict.keys():\n",
    "            scenes_cats_trajs_dict[scene] = {}\n",
    "        \n",
    "        scenes_cats_trajs_dict[scene][cat] = scenes_trajs\n",
    "\n",
    "# Generic: load the dataset statistics\n",
    "## Compute action coefficient for CEL of BC\n",
    "dataset_stats_filepath = f\"{args.dataset_path}/dataset_statistics.bz2\"\n",
    "# Override dataset statistics if the file already exists\n",
    "if os.path.exists(dataset_stats_filepath):\n",
    "    with open(dataset_stats_filepath, \"rb\") as f:\n",
    "        dataset_statistics = cpkl.load(f)\n",
    "\n",
    "# Extract some global metadata\n",
    "# TARGET_SCENE_LIST = list(cats_scenes_trajs_dict[list(cats_scenes_trajs_dict.keys())[0]].keys())\n",
    "TARGET_SCENE_LIST = list(dataset_statistics[\"scene_counts\"].keys())\n",
    "TARGET_SCENE_DICT = {scene: i for i, scene in enumerate(TARGET_SCENE_LIST)}\n",
    "TARGET_CATEGORY_LIST = list(cats_scenes_trajs_dict.keys())\n",
    "TARGET_CATEGORY_DICT = {cat: i for i, cat in enumerate(TARGET_CATEGORY_LIST)}\n",
    "\n",
    "from soundspaces.mp3d_utils import CATEGORY_INDEX_MAPPING\n",
    "def get_category_name(idx):\n",
    "    assert idx >= 0 and idx <=20, f\"Invalid category index number: {idx}\"\n",
    "\n",
    "    for catname, catidx in CATEGORY_INDEX_MAPPING.items():\n",
    "        if catidx == idx:\n",
    "            return catname\n",
    "\n",
    "def get_sceneid_by_idx(scene_idx):\n",
    "    for k, v in TARGET_SCENE_DICT.items():\n",
    "        if v == scene_idx:\n",
    "            return k\n",
    "\n",
    "C = len(TARGET_CATEGORY_LIST) # C: total number of categories\n",
    "M = len(TARGET_SCENE_LIST) # M: total number of rooms, assuming all categories has N trajs for a same set of scenes.\n",
    "\n",
    "print(f\"# of categories C: {C} | # of scenes: {M}\")\n",
    "print(f\"TARGET_CATEGORY_DICT: {TARGET_CATEGORY_DICT}\")\n",
    "print(f\"TARGET_SCENE_DICT: {TARGET_SCENE_DICT}\")\n",
    "print(\"\")\n",
    "\n",
    "# for catname, cat_scenes_trajs in cats_scenes_trajs_dict.items():\n",
    "#     print(f\"Cat: {catname}; Scenes: {[k for k in cat_scenes_trajs.keys()]}\")\n",
    "\n",
    "# Basic check of the scene -> categories fileted trajectories\n",
    "# for scene, scenes_cat_trajs in scenes_cats_trajs_dict.items():\n",
    "#     print(f\"Scene: {scene}; Cats: {[k for k in scenes_cat_trajs.keys()]}\")\n",
    "\n",
    "# More detailed breakdown of the trajectories per categories then scenes\n",
    "for catname, cat_scenes_trajs in cats_scenes_trajs_dict.items():\n",
    "    print(f\"{catname}:\")\n",
    "    for scene, scene_trajs in cat_scenes_trajs.items():\n",
    "        traj_lengths = [len(traj_data[\"edd\"][\"done_list\"]) for traj_data in scene_trajs]\n",
    "        print(f\"\\t{scene}: {traj_lengths}\")\n",
    "    print(\"\")\n",
    "\n",
    "# More detailed breakdown of the trajectories per categories then scenes\n",
    "for scene, scene_cats_trajs in scenes_cats_trajs_dict.items():\n",
    "    print(f\"{scene}\")\n",
    "    for cat, cat_trajs in scene_cats_trajs.items():\n",
    "        traj_lengths = [len(traj_data[\"edd\"][\"done_list\"]) for traj_data in cat_trajs]\n",
    "        print(f\"\\t{cat}: {traj_lengths}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers to extract traj. data based on \"category\", \"scene\", etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region: Categories -> Scenes\n",
    "## cats_scenes_trajs_dict: dictionary structured as: {category: {scene: [traj_data]}}\n",
    "# TODO: add support for the device in case tensors are returned\n",
    "def get_traj_data_by_category_scene_trajIdx(trajs_dicts, category, scene, trajIdx=0, tensorize=False, device=\"cpu\"):\n",
    "    # Get a single trajectory specified by idx, for a specificed category and scene\n",
    "    # TODO: maybe fix the \"depth\" dimension here directly ?\n",
    "    obs_list_dict = trajs_dicts[category][scene][trajIdx][\"edd\"][\"obs_list\"]\n",
    "    done_list = trajs_dicts[category][scene][trajIdx][\"edd\"][\"done_list\"]\n",
    "\n",
    "    obs_dict_list = []\n",
    "    target_scene_idx_list, target_category_idx_list = [], []\n",
    "\n",
    "    T = len(obs_list_dict[\"rgb\"])\n",
    "    for t in range(T):\n",
    "        obs_dict_list.append({k: v[t] for k, v in obs_list_dict.items()})\n",
    "        target_scene_idx_list.append(TARGET_SCENE_DICT[scene])\n",
    "        target_category_idx_list.append(CATEGORY_INDEX_MAPPING[category])\n",
    "\n",
    "    # Tensorize if required\n",
    "    if tensorize:\n",
    "        done_list__th = []\n",
    "        obs_dict_list__th = []\n",
    "\n",
    "        for t, (obs_dict, done) in enumerate(zip(obs_dict_list, done_list)):\n",
    "            # done_list__th.append(th.Tensor(np.array([done])[None, :]))\n",
    "            done_list__th.append(th.Tensor(np.array([done])).to(device)) # TODO: make sure that the deprecation warning stops showing up. Or always stay on current Torch version.\n",
    "            tmp_dict = {}\n",
    "            for k, v in obs_dict.items():\n",
    "                if k == \"depth\":\n",
    "                    v = np.array(v)[:, :, None] # From (H, W) -> (H, W, 1)\n",
    "                tmp_dict[k] = th.Tensor(v)[None, :].to(device)\n",
    "            \n",
    "            obs_dict_list__th.append(tmp_dict)\n",
    "        \n",
    "        return obs_dict_list__th, done_list__th, target_scene_idx_list, target_category_idx_list\n",
    "\n",
    "    return obs_dict_list, done_list, target_scene_idx_list, target_category_idx_list\n",
    "\n",
    "def get_traj_data_by_category_scene(trajs_dicts, category, scene, max_scenes=0, tensorize=False, device=\"cpu\"):\n",
    "    # Get all trajectories for a specific category and scene\n",
    "    obs_dict_list, done_list = [], []\n",
    "    target_scene_idx_list, target_category_idx_list = [], []\n",
    "\n",
    "    N_SCENES = len(trajs_dicts[category][scene])\n",
    "    res_n_scenes = N_SCENES if max_scenes <= 0 else max_scenes\n",
    "\n",
    "    for i in range(N_SCENES):\n",
    "        traj_obs_dict_list, traj_done_list, target_scene_idxes, target_category_idxes = \\\n",
    "            get_traj_data_by_category_scene_trajIdx(trajs_dicts, category, scene, i, tensorize=tensorize, device=device)\n",
    "\n",
    "        obs_dict_list.extend(traj_obs_dict_list)\n",
    "        done_list.extend(traj_done_list)\n",
    "        target_scene_idx_list.extend(target_scene_idxes)\n",
    "        target_category_idx_list.extend(target_category_idxes)\n",
    "\n",
    "        traj_length = len(traj_done_list)\n",
    "        # print(f\"Selected traj of length: {traj_length}\")\n",
    "        if i >= res_n_scenes - 1:\n",
    "            break\n",
    "\n",
    "    return obs_dict_list, done_list, target_scene_idx_list, target_category_idx_list\n",
    "\n",
    "def get_traj_data_by_category(trajs_dicts, category, max_scenes=0, tensorize=False, device=\"cpu\"):\n",
    "    # Get all trajectories for a specific category, across all scenes and all trajectories\n",
    "    obs_dict_list, done_list =[], []\n",
    "    target_scene_idx_list, target_category_idx_list = [], []\n",
    "\n",
    "    for scene in trajs_dicts[category].keys():\n",
    "        scene_obs_dict_list, scene_done_list, target_scene_idxes, target_category_idxes = \\\n",
    "            get_traj_data_by_category_scene(trajs_dicts, category, scene, max_scenes=max_scenes, tensorize=tensorize, device=device)\n",
    "\n",
    "        obs_dict_list.extend(scene_obs_dict_list)\n",
    "        done_list.extend(scene_done_list)\n",
    "        target_scene_idx_list.extend(target_scene_idxes)\n",
    "        target_category_idx_list.extend(target_category_idxes)\n",
    "    \n",
    "    return obs_dict_list, done_list, target_scene_idx_list, target_category_idx_list\n",
    "\n",
    "def get_all_traj_data_by_category(trajs_dicts, tensorize=False, device=\"cpu\"):\n",
    "    # Get all trajectories for a specific category, across all scenes and all trajectories\n",
    "    obs_dict_list, done_list =[], []\n",
    "    target_scene_idx_list, target_category_idx_list = [], []\n",
    "\n",
    "    for cat in trajs_dicts.keys():\n",
    "        cat_scene_obs_dict_list, cat_scene_done_list, cat_target_scene_idxes, cat_target_category_idxes = \\\n",
    "            get_traj_data_by_category(trajs_dicts, cat, tensorize=tensorize, device=device)\n",
    "\n",
    "        obs_dict_list.extend(cat_scene_obs_dict_list)\n",
    "        done_list.extend(cat_scene_done_list)\n",
    "        target_scene_idx_list.extend(cat_target_scene_idxes)\n",
    "        target_category_idx_list.extend(cat_target_category_idxes)\n",
    "    \n",
    "    return obs_dict_list, done_list, target_scene_idx_list, target_category_idx_list\n",
    "# endregion: Categories -> Scenes\n",
    "\n",
    "\n",
    "# region: Scenes -> Categories\n",
    "# TODO: add \"return\" for target categories and scenes label\n",
    "## scenes_cats_trajs_dict: dictionary structured as: {scene: {category: [traj-data]}}\n",
    "def get_traj_data_by_scene_category_trajIdx(trajs_dicts, scene, category, trajIdx=0, tensorize=False, device=\"cpu\"):\n",
    "    # Get a single trajectory specified by idx, for a specificed category and scene\n",
    "    # TODO: maybe fix the \"depth\" dimension here directly ?\n",
    "    obs_list_dict = trajs_dicts[scene][category][trajIdx][\"edd\"][\"obs_list\"]\n",
    "    done_list = trajs_dicts[scene][category][trajIdx][\"edd\"][\"done_list\"]\n",
    "    target_scene_idx_list, target_category_idx_list = [], []\n",
    "\n",
    "    obs_dict_list = []\n",
    "    T = len(obs_list_dict[\"rgb\"])\n",
    "    for t in range(T):\n",
    "        obs_dict_list.append({k: v[t] for k, v in obs_list_dict.items()})\n",
    "        target_scene_idx_list.append(TARGET_SCENE_DICT[scene])\n",
    "        target_category_idx_list.append(CATEGORY_INDEX_MAPPING[category])\n",
    "\n",
    "    # Tensorize if required\n",
    "    if tensorize:\n",
    "        done_list__th = []\n",
    "        obs_dict_list__th = []\n",
    "\n",
    "        for t, (obs_dict, done) in enumerate(zip(obs_dict_list, done_list)):\n",
    "            # done_list__th.append(th.Tensor(np.array([done])[None, :]))\n",
    "            done_list__th.append(th.Tensor(np.array([done])).to(device)) # TODO: make sure that the deprecation warning stops showing up. Or always stay on current Torch version.\n",
    "            tmp_dict = {}\n",
    "            for k, v in obs_dict.items():\n",
    "                if k == \"depth\":\n",
    "                    v = np.array(v)[:, :, None] # From (H, W) -> (H, W, 1)\n",
    "                tmp_dict[k] = th.Tensor(v)[None, :].to(device)\n",
    "            \n",
    "            obs_dict_list__th.append(tmp_dict)\n",
    "        \n",
    "        return obs_dict_list__th, done_list__th, target_scene_idx_list, target_category_idx_list\n",
    "        \n",
    "    return obs_dict_list, done_list, target_scene_idx_list, target_category_idx_list\n",
    "\n",
    "def get_traj_data_by_scene_category(trajs_dicts, scene, category, tensorize=False, device=\"cpu\"):\n",
    "    # Get all trajectories for a specific category and scene\n",
    "    obs_dict_list, done_list = [], []\n",
    "    target_scene_idx_list, target_category_idx_list = [], []\n",
    "\n",
    "    for i in range(len(trajs_dicts[scene][category])):\n",
    "        traj_obs_dict_list, traj_done_list, target_scene_idxes, target_category_idxes = \\\n",
    "            get_traj_data_by_scene_category_trajIdx(trajs_dicts, scene, category, i, tensorize=tensorize, device=device)\n",
    "\n",
    "        obs_dict_list.extend(traj_obs_dict_list)\n",
    "        done_list.extend(traj_done_list)\n",
    "        target_scene_idx_list.extend(target_scene_idxes)\n",
    "        target_category_idx_list.extend(target_category_idxes)\n",
    "\n",
    "        traj_length = len(traj_done_list)\n",
    "        # print(f\"Selected traj of length: {traj_length}\")\n",
    "\n",
    "    return obs_dict_list, done_list, target_scene_idx_list, target_category_idx_list\n",
    "\n",
    "def get_traj_data_by_scene(trajs_dicts, scene, tensorize=False, device=\"cpu\"):\n",
    "    # Get all trajectories for a specific category, across all scenes and all trajectories\n",
    "    obs_dict_list, done_list =[], []\n",
    "    target_scene_idx_list, target_category_idx_list = [], []\n",
    "    \n",
    "    for cat in trajs_dicts[scene].keys():\n",
    "        cat_obs_dict_list, cat_done_list, target_scene_idxes, target_category_idxes = \\\n",
    "            get_traj_data_by_scene_category(trajs_dicts, scene, cat, tensorize=tensorize, device=device)\n",
    "\n",
    "        obs_dict_list.extend(cat_obs_dict_list)\n",
    "        done_list.extend(cat_done_list)\n",
    "        target_scene_idx_list.extend(target_scene_idxes)\n",
    "        target_category_idx_list.extend(target_category_idxes)\n",
    "    \n",
    "    return obs_dict_list, done_list, target_scene_idx_list, target_category_idx_list\n",
    "\n",
    "def get_all_traj_data_by_scene(trajs_dicts, tensorize=False, device=\"cpu\"):\n",
    "    # Get all trajectories for a specific category, across all scenes and all trajectories\n",
    "    obs_dict_list, done_list =[], []\n",
    "    target_scene_idx_list, target_category_idx_list = [], []\n",
    "\n",
    "    for scene in trajs_dicts.keys():\n",
    "        # Too rushing / lazy to change the names of the temporary list of obs\n",
    "        cat_scene_obs_dict_list, cat_scene_done_list, cat_target_scene_idxes, cat_target_category_idxes = \\\n",
    "            get_traj_data_by_category(trajs_dicts, scene, tensorize=tensorize, device=device)\n",
    "\n",
    "        obs_dict_list.extend(cat_scene_obs_dict_list)\n",
    "        done_list.extend(cat_scene_done_list)\n",
    "        target_scene_idx_list.extend(cat_target_scene_idxes)\n",
    "        target_category_idx_list.extend(cat_target_category_idxes)\n",
    "    \n",
    "    return obs_dict_list, done_list, target_scene_idx_list, target_category_idx_list\n",
    "# endregion: Scenes -> Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GRU Agent: 'ppo_bc__sweep_gru_512'\n",
      "  GW size: 512\n",
      "Loaded GW Agent: 'ppo_bc__sweep_gw_64'\n",
      "  GW size: 512\n"
     ]
    }
   ],
   "source": [
    "# Loading pretrained agent\n",
    "MODEL_VARIANTS_TO_STATEDICT_PATH = {\n",
    "    ## GRU\n",
    "    # region: SAVI BC GRUv3 variants: rec enc gw3 detach\n",
    "    \"ppo_bc__sweep_gru_512\": {\n",
    "        \"pretty_name\": \"GRU 1\",\n",
    "        \"state_dict_path\": \"/home/rousslan/random/rl/exp-logs/ss-hab-bc-revised-sweep/\"\n",
    "            \"ppo_bc_seed_42__2024_02_05_18_30_00_569723.musashi\"\n",
    "            # \"/models/ppo_agent.19995001.ckpt.pth\",\n",
    "            \"/models/ppo_agent.10000500.ckpt.pth\",\n",
    "        # TODO: prending probes\n",
    "        \"probe_path\": \"/home/rousslan/random/rl/exp-logs/ss-hab-bc-probing/\"\n",
    "            \"ppo_bc__savi_ss1_rgb_spectro__gruv3__gw_detach__usenull__grulynrm__entcoef_0.2__no_cew__n_mb_50__prb_dpth_2_seed_111__2023_11_16_16_08_52_068321.conan\"\n",
    "    },\n",
    "    # endregion: SAVI BC GRUv3 variants: rec enc gw3 detach\n",
    "\n",
    "    ## GWTv3 H=512\n",
    "    # region: SAVI BC GWTv3 variants: rec enc gw3 detach; CA uses null\n",
    "    \"ppo_bc__sweep_gw_64\": {\n",
    "        \"pretty_name\": \"GW | 1\",\n",
    "        \"state_dict_path\": \"/home/rousslan/random/rl/exp-logs/ss-hab-bc-revised-sweep/\"\n",
    "            \"ppo_bc_seed_42__2024_01_23_15_44_57_777702.musashi\"\n",
    "            \"/models/ppo_agent.10000500.ckpt.pth\",\n",
    "        # TODO: prending probes\n",
    "        \"probe_path\": \"/home/rousslan/random/rl/exp-logs/ss-hab-bc-probing/\"\n",
    "            \"ppo_bc__savi_ss1_rgb_spectro__gwtv3__gw_detach__usenull__grulynrm__entcoef_0.2__no_cew__n_mb_50__prb_dpth_2_seed_111__2023_11_14_18_38_49_687853.musashi\"\n",
    "    },\n",
    "    # endregion: SAVI BC GWTv3 variants: rec enc gw3 detach; CA uses null\n",
    "}\n",
    "\n",
    "# dev = th.device(\"cpu\")\n",
    "dev = th.device(\"cuda\")\n",
    "\n",
    "# 'variant named' indexed 'torch agent'\n",
    "MODEL_VARIANTS_TO_AGENTMODEL = {}\n",
    "\n",
    "for k, v in MODEL_VARIANTS_TO_STATEDICT_PATH.items():\n",
    "    args_copy = copy.copy(args)\n",
    "    # Override args depending on the model in use\n",
    "    if k.__contains__(\"gru\"):\n",
    "        print(f\"Loaded GRU Agent: '{k}'\")\n",
    "        tmp_args = copy.copy(args)\n",
    "        # TODO: find a better way, swap hidden size and agent type checking script\n",
    "        if k.__contains__(\"64\"):\n",
    "          tmp_args.gw_size = 64\n",
    "        elif k.__contains__(\"512\"):\n",
    "          tmp_args.gw_size = 512\n",
    "\n",
    "        print(f\"  GW size: {tmp_args.hidden_size}\")\n",
    "\n",
    "        agent = GRU_Actor(single_observation_space, single_action_space, tmp_args,\n",
    "            analysis_layers=models.GWTAGENT_DEFAULT_ANALYSIS_LAYER_NAMES)\n",
    "        # print(agent)\n",
    "    elif k.__contains__(\"gw\"):\n",
    "        print(f\"Loaded GW Agent: '{k}'\")\n",
    "        tmp_args = copy.copy(args)\n",
    "        # TODO: find a better way:\n",
    "        if k.__contains__(\"64\"):\n",
    "          tmp_args.gw_size = 64\n",
    "        elif k.__contains__(\"512\"):\n",
    "          tmp_args.gw_size = 512\n",
    "        print(f\"  GW size: {tmp_args.hidden_size}\")\n",
    "\n",
    "        agent = GW_Actor(single_observation_space, single_action_space, tmp_args,\n",
    "            analysis_layers=models.GWTAGENT_DEFAULT_ANALYSIS_LAYER_NAMES + [\"state_encoder.ca.mha\"])\n",
    "        # print(agent)\n",
    "\n",
    "    agent.eval()\n",
    "    # Load the model weights\n",
    "    # TODO: add map location device to use CPU only ?\n",
    "    if v[\"state_dict_path\"] != \"\":\n",
    "        agent_state_dict = th.load(v[\"state_dict_path\"], map_location=dev)\n",
    "        agent.load_state_dict(agent_state_dict)\n",
    "    agent = agent.to(dev)\n",
    "\n",
    "    MODEL_VARIANTS_TO_AGENTMODEL[k] = agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ss-hab-headless-py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
