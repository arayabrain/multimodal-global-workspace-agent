{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook support or argpase\n",
    "import sys; sys.argv=['']; del sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import apex\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import compress_pickle as cpkl\n",
    "\n",
    "import rsatoolbox\n",
    "from torchinfo import summary\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.gridspec import GridSpec\n",
    "# plt.style.use(\"seaborn-darkgrid\")\n",
    "\n",
    "import models\n",
    "from models import GW_Actor, GRU_Actor\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "%matplotlib inline\n",
    "\n",
    "from ss_baselines.common.utils import plot_top_down_map\n",
    "\n",
    "\n",
    "mpl.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "mpl.rcParams[\"axes.facecolor\"] = \"white\"\n",
    "mpl.rcParams[\"savefig.facecolor\"] = \"white\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General config related\n",
    "from configurator import get_arg_dict, generate_args\n",
    "\n",
    "# Env config related\n",
    "from ss_baselines.av_nav.config import get_config\n",
    "from ss_baselines.savi.config.default import get_config as get_savi_config\n",
    "from ss_baselines.common.env_utils import construct_envs\n",
    "from ss_baselines.common.environments import get_env_class\n",
    "\n",
    "# region: Generating additional hyparams\n",
    "CUSTOM_ARGS = [\n",
    "\t# General hyper parameters\n",
    "\tget_arg_dict(\"seed\", int, 111),\n",
    "\tget_arg_dict(\"total-steps\", int, 1_000_000),\n",
    "\n",
    "\t# Behavior cloning gexperiment config\n",
    "\tget_arg_dict(\"dataset-path\", str, \"SAVI_Oracle_Dataset_v0\"),\n",
    "\n",
    "\t# SS env config\n",
    "\tget_arg_dict(\"config-path\", str, \"env_configs/savi/savi_ss1_rgb_spectro.yaml\"),\n",
    "\n",
    "\t# PPO Hyper parameters\n",
    "\tget_arg_dict(\"num-envs\", int, 10), # Number of parallel envs. 10 by default\n",
    "\tget_arg_dict(\"num-steps\", int, 150), # For each env, how many steps are collected to form PPO Agent rollout.\n",
    "\tget_arg_dict(\"num-minibatches\", int, 1), # Number of mini-batches the rollout data is split into to make the updates\n",
    "\tget_arg_dict(\"update-epochs\", int, 4), # Number of gradient step for the policy and value networks\n",
    "\tget_arg_dict(\"gamma\", float, 0.99),\n",
    "\tget_arg_dict(\"gae-lambda\", float, 0.95),\n",
    "\tget_arg_dict(\"norm-adv\", bool, True, metatype=\"bool\"),\n",
    "\tget_arg_dict(\"clip-coef\", float, 0.1), # Surrogate loss clipping coefficient\n",
    "\tget_arg_dict(\"clip-vloss\", bool, True, metatype=\"bool\"),\n",
    "\tget_arg_dict(\"ent-coef\", float, 0.2), # Entropy loss coef; 0.2 in SS baselines\n",
    "\tget_arg_dict(\"vf-coef\", float, 0.5), # Value loss coefficient\n",
    "\tget_arg_dict(\"max-grad-norm\", float, 0.5),\n",
    "\tget_arg_dict(\"target-kl\", float, None),\n",
    "\tget_arg_dict(\"lr\", float, 2.5e-4), # Learning rate\n",
    "\tget_arg_dict(\"optim-wd\", float, 0), # weight decay for adam optim\n",
    "\t## Agent network params\n",
    "\tget_arg_dict(\"agent-type\", str, \"gw\", metatype=\"choice\",\n",
    "\t\tchoices=[\"gw\", \"gru\"]),\n",
    "\tget_arg_dict(\"gru-type\", str, \"layernorm\", metatype=\"choice\",\n",
    "\t\t\t\t\tchoices=[\"default\", \"layernorm\"]),\n",
    "\tget_arg_dict(\"hidden-size\", int, 512), # Size of the visual / audio features\n",
    "\n",
    "\t## BC related hyper parameters\n",
    "\tget_arg_dict(\"batch-chunk-length\", int, 0), # For gradient accumulation\n",
    "\tget_arg_dict(\"dataset-ce-weights\", bool, False, metatype=\"bool\"), # If True, will read CEL weights based on action dist. from the 'dataset_statistics.bz2' file.\n",
    "\tget_arg_dict(\"ce-weights\", float, None, metatype=\"list\"), # Weights for the Cross Entropy loss\n",
    "\n",
    "\t## GW Agent with custom attention, recurrent encoder and null inputs\n",
    "\tget_arg_dict(\"gw-size\", int, 512), # Dim of the GW vector\n",
    "\tget_arg_dict(\"recenc-use-gw\", bool, True, metatype=\"bool\"), # Use GW at Recur. Enc. level\n",
    "\tget_arg_dict(\"recenc-gw-detach\", bool, True, metatype=\"bool\"), # When using GW at Recurrent Encoder level, whether to detach the grads or not\n",
    "\tget_arg_dict(\"gw-use-null\", bool, True, metatype=\"bool\"), # Use Null at CrossAtt level\n",
    "\tget_arg_dict(\"gw-cross-heads\", int, 1), # num_heads of the CrossAttn\n",
    "\n",
    "\t# Eval protocol\n",
    "\tget_arg_dict(\"eval\", bool, True, metatype=\"bool\"),\n",
    "\tget_arg_dict(\"eval-every\", int, int(1.5e4)), # Every X frames || steps sampled\n",
    "\tget_arg_dict(\"eval-n-episodes\", int, 5),\n",
    "\n",
    "\t# Logging params\n",
    "\t# NOTE: Video logging expensive\n",
    "\tget_arg_dict(\"save-videos\", bool, False, metatype=\"bool\"),\n",
    "\tget_arg_dict(\"save-model\", bool, True, metatype=\"bool\"),\n",
    "\tget_arg_dict(\"save-model-every\", int, int(5e5)), # Every X frames || steps sampled\n",
    "\tget_arg_dict(\"log-sampling-stats-every\", int, int(1.5e3)), # Every X frames || steps sampled\n",
    "\tget_arg_dict(\"log-training-stats-every\", int, int(10)), # Every X model update\n",
    "\tget_arg_dict(\"logdir-prefix\", str, \"./logs/\") # Overrides the default one\n",
    "]\n",
    "args = generate_args(CUSTOM_ARGS)\n",
    "# endregion: Generating additional hyparams\n",
    "\n",
    "# Load environment config\n",
    "is_SAVi = str.__contains__(args.config_path, \"savi\")\n",
    "if is_SAVi:\n",
    "\tenv_config = get_savi_config(config_paths=args.config_path)\n",
    "else:\n",
    "\tenv_config = get_config(config_paths=args.config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate obs / act space based on args and env_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dict(audiogoal:Box(-3.4028235e+38, 3.4028235e+38, (2, 16000), float32), rgb:Box(0, 255, (128, 128, 3), uint8), spectrogram:Box(-3.4028235e+38, 3.4028235e+38, (65, 26, 2), float32)),\n",
       " Discrete(4))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overriding some envs parametes from the .yaml env config\n",
    "env_config.defrost()\n",
    "env_config.NUM_PROCESSES = 1 # Corresponds to number of envs, makes script startup faster for debugs\n",
    "env_config.USE_SYNC_VECENV = True\n",
    "# env_config.USE_VECENV = False\n",
    "# env_config.CONTINUOUS = args.env_continuous\n",
    "## In caes video saving is enabled, make sure there is also the rgb videos\n",
    "env_config.freeze()\n",
    "# print(env_config)\n",
    "\n",
    "# Environment instantiation\n",
    "# envs = construct_envs(env_config, get_env_class(env_config.ENV_NAME))\n",
    "# Dummy environment spaces\n",
    "\n",
    "# TODO: add dyanmicallly set single_observation_space so that RGB and RGBD based variants\n",
    "# can be evaluated at thet same time\n",
    "from gym import spaces\n",
    "single_action_space = spaces.Discrete(4)\n",
    "single_observation_space = spaces.Dict({\n",
    "    \"rgb\": spaces.Box(shape=[128,128,3], low=0, high=255, dtype=np.uint8),\n",
    "    # \"depth\": spaces.Box(shape=[128,128,1], low=0, high=255, dtype=np.uint8),\n",
    "    \"audiogoal\": spaces.Box(shape=[2,16000], low=-3.4028235e+38, high=3.4028235e+38, dtype=np.float32),\n",
    "    \"spectrogram\": spaces.Box(shape=[65,26,2], low=-3.4028235e+38, high=3.4028235e+38, dtype=np.float32)\n",
    "})\n",
    "# single_observation_space = envs.observation_spaces[0]\n",
    "# single_action_space = envs.action_spaces[0]\n",
    "\n",
    "single_observation_space, single_action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Category-Scene-Trajs, Scene-Category-Trajs, and Dataset's metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loads data for analysis, as well as dataset's metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of categories C: 6 | # of scenes: 56\n",
      "TARGET_CATEGORY_DICT: {'chair': 0, 'picture': 1, 'table': 2, 'cushion': 3, 'cabinet': 4, 'plant': 5}\n",
      "TARGET_SCENE_DICT: {'gTV8FGcVJC9': 0, '5LpN3gDmAk7': 1, 'vyrNrziPKCB': 2, 'b8cTxDM8gDG': 3, 'Vvot9Ly1tCj': 4, 'rPc6DW4iMge': 5, 'PuKPg4mmafe': 6, '759xd9YjKW5': 7, 'ZMojNkEp431': 8, 'VzqfbhrpDEA': 9, 'ac26ZMwG7aT': 10, 'D7N2EKCX4Sj': 11, 'E9uDoFAP3SH': 12, 'S9hNv5qa7GM': 13, '5q7pvUzZiYa': 14, 'kEZ7cmS4wCh': 15, 'VFuaQ6m2Qom': 16, '7y3sRwLe3Va': 17, 'p5wJjkQkbXX': 18, 'V2XKFyX4ASd': 19, 'VVfe2KiqLaN': 20, 'mJXqzFtmKg4': 21, 'SN83YJsR3w2': 22, 'EDJbREhghzL': 23, 'PX4nDJXEHrG': 24, 'JmbYfDe2QKZ': 25, 'r1Q1Z4BcV1o': 26, 'aayBHfsNo7d': 27, 'r47D5H71a5s': 28, 'pRbA3pwrgk9': 29, 'Pm6F8kyY3z2': 30, 'sKLMLpTHeUy': 31, 'GdvgFV5R1Z5': 32, 'e9zR4mvMWw7': 33, 'JeFG25nYj2p': 34, 'B6ByNegPMKs': 35, 'uNb9QFRL6hY': 36, 'cV4RVeZvu5T': 37, 'D7G3Y4RVNrH': 38, 'XcA2TqTSSAj': 39, 'ur6pFq6Qu1A': 40, '29hnd4uzFmX': 41, 's8pcmisQ38h': 42, 'qoiz87JEwZ2': 43, 'ULsKaCPVFJR': 44, '1pXnuDYAj8r': 45, 'VLzqgDo317F': 46, 'YmJkqBEsHnH': 47, 'sT4fr6TAbpF': 48, 'jh4fc5c5qoQ': 49, '8WUmhLawc2A': 50, '1LXtFkjw3qL': 51, '17DRP5sb8fy': 52, '82sE5b5pLXE': 53, 'JF19kD82Mey': 54, 'Uxmj2M2itWa': 55}\n",
      "\n",
      "chair:\n",
      "\tgTV8FGcVJC9: [28, 10, 46, 9, 6]\n",
      "\tb8cTxDM8gDG: [15, 19, 26, 20, 8]\n",
      "\tD7N2EKCX4Sj: [19, 36, 12, 40, 33]\n",
      "\tVvot9Ly1tCj: [18, 21, 23, 16, 27]\n",
      "\tvyrNrziPKCB: [20, 24, 10, 14, 28]\n",
      "\n",
      "picture:\n",
      "\tgTV8FGcVJC9: [10, 12, 16, 20, 17]\n",
      "\tD7N2EKCX4Sj: [46, 31, 53, 39, 43]\n",
      "\tvyrNrziPKCB: [12, 38, 18, 14, 15]\n",
      "\tVvot9Ly1tCj: [24, 51, 31, 41, 35]\n",
      "\tb8cTxDM8gDG: [33, 12, 13, 20, 11]\n",
      "\n",
      "table:\n",
      "\tvyrNrziPKCB: [22, 22, 54, 57, 12]\n",
      "\tb8cTxDM8gDG: [17, 9, 16, 25, 14]\n",
      "\tD7N2EKCX4Sj: [6, 31, 24, 28, 17]\n",
      "\tVvot9Ly1tCj: [23, 41, 14, 34, 32]\n",
      "\tgTV8FGcVJC9: [16, 13, 15, 18, 15]\n",
      "\n",
      "cushion:\n",
      "\tb8cTxDM8gDG: [7, 14, 22, 12, 8]\n",
      "\tVvot9Ly1tCj: [36, 32, 47, 36, 46]\n",
      "\tvyrNrziPKCB: [62, 18, 21, 42, 54]\n",
      "\tgTV8FGcVJC9: [10, 11, 27, 7, 13]\n",
      "\tD7N2EKCX4Sj: [21, 12, 14, 14, 20]\n",
      "\n",
      "cabinet:\n",
      "\tgTV8FGcVJC9: [13, 13, 18, 47, 13]\n",
      "\tvyrNrziPKCB: [30, 22, 22, 40, 47]\n",
      "\tb8cTxDM8gDG: [10, 14, 21, 24, 16]\n",
      "\tVvot9Ly1tCj: [9, 35, 42, 39, 28]\n",
      "\tD7N2EKCX4Sj: [21, 34, 14, 40, 10]\n",
      "\n",
      "plant:\n",
      "\tgTV8FGcVJC9: [6, 13, 42, 6, 41]\n",
      "\tVvot9Ly1tCj: [16, 47, 23, 11, 26]\n",
      "\tb8cTxDM8gDG: [6, 8, 13, 11, 8]\n",
      "\tvyrNrziPKCB: [36, 21, 59, 34, 34]\n",
      "\tD7N2EKCX4Sj: [27, 31, 37, 26, 47]\n",
      "\n",
      "gTV8FGcVJC9\n",
      "\tchair: [28, 10, 46, 9, 6]\n",
      "\tpicture: [10, 12, 16, 20, 17]\n",
      "\ttable: [16, 13, 15, 18, 15]\n",
      "\tcushion: [10, 11, 27, 7, 13]\n",
      "\tcabinet: [13, 13, 18, 47, 13]\n",
      "\tplant: [6, 13, 42, 6, 41]\n",
      "\n",
      "b8cTxDM8gDG\n",
      "\tchair: [15, 19, 26, 20, 8]\n",
      "\tpicture: [33, 12, 13, 20, 11]\n",
      "\ttable: [17, 9, 16, 25, 14]\n",
      "\tcushion: [7, 14, 22, 12, 8]\n",
      "\tcabinet: [10, 14, 21, 24, 16]\n",
      "\tplant: [6, 8, 13, 11, 8]\n",
      "\n",
      "D7N2EKCX4Sj\n",
      "\tchair: [19, 36, 12, 40, 33]\n",
      "\tpicture: [46, 31, 53, 39, 43]\n",
      "\ttable: [6, 31, 24, 28, 17]\n",
      "\tcushion: [21, 12, 14, 14, 20]\n",
      "\tcabinet: [21, 34, 14, 40, 10]\n",
      "\tplant: [27, 31, 37, 26, 47]\n",
      "\n",
      "Vvot9Ly1tCj\n",
      "\tchair: [18, 21, 23, 16, 27]\n",
      "\tpicture: [24, 51, 31, 41, 35]\n",
      "\ttable: [23, 41, 14, 34, 32]\n",
      "\tcushion: [36, 32, 47, 36, 46]\n",
      "\tcabinet: [9, 35, 42, 39, 28]\n",
      "\tplant: [16, 47, 23, 11, 26]\n",
      "\n",
      "vyrNrziPKCB\n",
      "\tchair: [20, 24, 10, 14, 28]\n",
      "\tpicture: [12, 38, 18, 14, 15]\n",
      "\ttable: [22, 22, 54, 57, 12]\n",
      "\tcushion: [62, 18, 21, 42, 54]\n",
      "\tcabinet: [30, 22, 22, 40, 47]\n",
      "\tplant: [36, 21, 59, 34, 34]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify file name\n",
    "analysis_trajs_filename = \"cats_scenes_trajs_C_6_M_5_N_5__2023_06_01_10_41.bz2\"\n",
    "\n",
    "# Read the filtred trajectories data\n",
    "## Default format is {cat -> { scenes -> traj: []}}\n",
    "with open(analysis_trajs_filename, \"rb\") as f:\n",
    "    cats_scenes_trajs_dict = cpkl.load(f)\n",
    "\n",
    "## Compute the equivalent scenes cat trajs format\n",
    "## {scenes -> { cat -> trajs: []}}\n",
    "scenes_cats_trajs_dict = {}\n",
    "for cat, cat_scenes_trajs in cats_scenes_trajs_dict.items():\n",
    "    for scene, scenes_trajs in cat_scenes_trajs.items():\n",
    "        if scene not in scenes_cats_trajs_dict.keys():\n",
    "            scenes_cats_trajs_dict[scene] = {}\n",
    "        \n",
    "        scenes_cats_trajs_dict[scene][cat] = scenes_trajs\n",
    "\n",
    "# Generic: load the dataset statistics\n",
    "## Compute action coefficient for CEL of BC\n",
    "dataset_stats_filepath = f\"{args.dataset_path}/dataset_statistics.bz2\"\n",
    "# Override dataset statistics if the file already exists\n",
    "if os.path.exists(dataset_stats_filepath):\n",
    "    with open(dataset_stats_filepath, \"rb\") as f:\n",
    "        dataset_statistics = cpkl.load(f)\n",
    "\n",
    "# Extract some global metadata\n",
    "# TARGET_SCENE_LIST = list(cats_scenes_trajs_dict[list(cats_scenes_trajs_dict.keys())[0]].keys())\n",
    "TARGET_SCENE_LIST = list(dataset_statistics[\"scene_counts\"].keys())\n",
    "TARGET_SCENE_DICT = {scene: i for i, scene in enumerate(TARGET_SCENE_LIST)}\n",
    "TARGET_CATEGORY_LIST = list(cats_scenes_trajs_dict.keys())\n",
    "TARGET_CATEGORY_DICT = {cat: i for i, cat in enumerate(TARGET_CATEGORY_LIST)}\n",
    "\n",
    "from soundspaces.mp3d_utils import CATEGORY_INDEX_MAPPING\n",
    "def get_category_name(idx):\n",
    "    assert idx >= 0 and idx <=20, f\"Invalid category index number: {idx}\"\n",
    "\n",
    "    for catname, catidx in CATEGORY_INDEX_MAPPING.items():\n",
    "        if catidx == idx:\n",
    "            return catname\n",
    "\n",
    "def get_sceneid_by_idx(scene_idx):\n",
    "    for k, v in TARGET_SCENE_DICT.items():\n",
    "        if v == scene_idx:\n",
    "            return k\n",
    "\n",
    "C = len(TARGET_CATEGORY_LIST) # C: total number of categories\n",
    "M = len(TARGET_SCENE_LIST) # M: total number of rooms, assuming all categories has N trajs for a same set of scenes.\n",
    "\n",
    "print(f\"# of categories C: {C} | # of scenes: {M}\")\n",
    "print(f\"TARGET_CATEGORY_DICT: {TARGET_CATEGORY_DICT}\")\n",
    "print(f\"TARGET_SCENE_DICT: {TARGET_SCENE_DICT}\")\n",
    "print(\"\")\n",
    "\n",
    "# for catname, cat_scenes_trajs in cats_scenes_trajs_dict.items():\n",
    "#     print(f\"Cat: {catname}; Scenes: {[k for k in cat_scenes_trajs.keys()]}\")\n",
    "\n",
    "# Basic check of the scene -> categories fileted trajectories\n",
    "# for scene, scenes_cat_trajs in scenes_cats_trajs_dict.items():\n",
    "#     print(f\"Scene: {scene}; Cats: {[k for k in scenes_cat_trajs.keys()]}\")\n",
    "\n",
    "# More detailed breakdown of the trajectories per categories then scenes\n",
    "for catname, cat_scenes_trajs in cats_scenes_trajs_dict.items():\n",
    "    print(f\"{catname}:\")\n",
    "    for scene, scene_trajs in cat_scenes_trajs.items():\n",
    "        traj_lengths = [len(traj_data[\"edd\"][\"done_list\"]) for traj_data in scene_trajs]\n",
    "        print(f\"\\t{scene}: {traj_lengths}\")\n",
    "    print(\"\")\n",
    "\n",
    "# More detailed breakdown of the trajectories per categories then scenes\n",
    "for scene, scene_cats_trajs in scenes_cats_trajs_dict.items():\n",
    "    print(f\"{scene}\")\n",
    "    for cat, cat_trajs in scene_cats_trajs.items():\n",
    "        traj_lengths = [len(traj_data[\"edd\"][\"done_list\"]) for traj_data in cat_trajs]\n",
    "        print(f\"\\t{cat}: {traj_lengths}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers to extract traj. data based on \"category\", \"scene\", etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region: Categories -> Scenes\n",
    "## cats_scenes_trajs_dict: dictionary structured as: {category: {scene: [traj_data]}}\n",
    "# TODO: add support for the device in case tensors are returned\n",
    "def get_traj_data_by_category_scene_trajIdx(trajs_dicts, category, scene, trajIdx=0, tensorize=False, device=\"cpu\"):\n",
    "    # Get a single trajectory specified by idx, for a specificed category and scene\n",
    "    # TODO: maybe fix the \"depth\" dimension here directly ?\n",
    "    obs_list_dict = trajs_dicts[category][scene][trajIdx][\"edd\"][\"obs_list\"]\n",
    "    done_list = trajs_dicts[category][scene][trajIdx][\"edd\"][\"done_list\"]\n",
    "\n",
    "    obs_dict_list = []\n",
    "    target_scene_idx_list, target_category_idx_list = [], []\n",
    "\n",
    "    T = len(obs_list_dict[\"rgb\"])\n",
    "    for t in range(T):\n",
    "        obs_dict_list.append({k: v[t] for k, v in obs_list_dict.items()})\n",
    "        target_scene_idx_list.append(TARGET_SCENE_DICT[scene])\n",
    "        target_category_idx_list.append(CATEGORY_INDEX_MAPPING[category])\n",
    "\n",
    "    # Tensorize if required\n",
    "    if tensorize:\n",
    "        done_list__th = []\n",
    "        obs_dict_list__th = []\n",
    "\n",
    "        for t, (obs_dict, done) in enumerate(zip(obs_dict_list, done_list)):\n",
    "            # done_list__th.append(th.Tensor(np.array([done])[None, :]))\n",
    "            done_list__th.append(th.Tensor(np.array([done])).to(device)) # TODO: make sure that the deprecation warning stops showing up. Or always stay on current Torch version.\n",
    "            tmp_dict = {}\n",
    "            for k, v in obs_dict.items():\n",
    "                if k == \"depth\":\n",
    "                    v = np.array(v)[:, :, None] # From (H, W) -> (H, W, 1)\n",
    "                tmp_dict[k] = th.Tensor(v)[None, :].to(device)\n",
    "            \n",
    "            obs_dict_list__th.append(tmp_dict)\n",
    "        \n",
    "        return obs_dict_list__th, done_list__th, target_scene_idx_list, target_category_idx_list\n",
    "\n",
    "    return obs_dict_list, done_list, target_scene_idx_list, target_category_idx_list\n",
    "\n",
    "def get_traj_data_by_category_scene(trajs_dicts, category, scene, max_scenes=0, tensorize=False, device=\"cpu\"):\n",
    "    # Get all trajectories for a specific category and scene\n",
    "    obs_dict_list, done_list = [], []\n",
    "    target_scene_idx_list, target_category_idx_list = [], []\n",
    "\n",
    "    N_SCENES = len(trajs_dicts[category][scene])\n",
    "    res_n_scenes = N_SCENES if max_scenes <= 0 else max_scenes\n",
    "\n",
    "    for i in range(N_SCENES):\n",
    "        traj_obs_dict_list, traj_done_list, target_scene_idxes, target_category_idxes = \\\n",
    "            get_traj_data_by_category_scene_trajIdx(trajs_dicts, category, scene, i, tensorize=tensorize, device=device)\n",
    "\n",
    "        obs_dict_list.extend(traj_obs_dict_list)\n",
    "        done_list.extend(traj_done_list)\n",
    "        target_scene_idx_list.extend(target_scene_idxes)\n",
    "        target_category_idx_list.extend(target_category_idxes)\n",
    "\n",
    "        traj_length = len(traj_done_list)\n",
    "        # print(f\"Selected traj of length: {traj_length}\")\n",
    "        if i >= res_n_scenes - 1:\n",
    "            break\n",
    "\n",
    "    return obs_dict_list, done_list, target_scene_idx_list, target_category_idx_list\n",
    "\n",
    "def get_traj_data_by_category(trajs_dicts, category, max_scenes=0, tensorize=False, device=\"cpu\"):\n",
    "    # Get all trajectories for a specific category, across all scenes and all trajectories\n",
    "    obs_dict_list, done_list =[], []\n",
    "    target_scene_idx_list, target_category_idx_list = [], []\n",
    "\n",
    "    for scene in trajs_dicts[category].keys():\n",
    "        scene_obs_dict_list, scene_done_list, target_scene_idxes, target_category_idxes = \\\n",
    "            get_traj_data_by_category_scene(trajs_dicts, category, scene, max_scenes=max_scenes, tensorize=tensorize, device=device)\n",
    "\n",
    "        obs_dict_list.extend(scene_obs_dict_list)\n",
    "        done_list.extend(scene_done_list)\n",
    "        target_scene_idx_list.extend(target_scene_idxes)\n",
    "        target_category_idx_list.extend(target_category_idxes)\n",
    "    \n",
    "    return obs_dict_list, done_list, target_scene_idx_list, target_category_idx_list\n",
    "\n",
    "def get_all_traj_data_by_category(trajs_dicts, tensorize=False, device=\"cpu\"):\n",
    "    # Get all trajectories for a specific category, across all scenes and all trajectories\n",
    "    obs_dict_list, done_list =[], []\n",
    "    target_scene_idx_list, target_category_idx_list = [], []\n",
    "\n",
    "    for cat in trajs_dicts.keys():\n",
    "        cat_scene_obs_dict_list, cat_scene_done_list, cat_target_scene_idxes, cat_target_category_idxes = \\\n",
    "            get_traj_data_by_category(trajs_dicts, cat, tensorize=tensorize, device=device)\n",
    "\n",
    "        obs_dict_list.extend(cat_scene_obs_dict_list)\n",
    "        done_list.extend(cat_scene_done_list)\n",
    "        target_scene_idx_list.extend(cat_target_scene_idxes)\n",
    "        target_category_idx_list.extend(cat_target_category_idxes)\n",
    "    \n",
    "    return obs_dict_list, done_list, target_scene_idx_list, target_category_idx_list\n",
    "# endregion: Categories -> Scenes\n",
    "\n",
    "\n",
    "# region: Scenes -> Categories\n",
    "# TODO: add \"return\" for target categories and scenes label\n",
    "## scenes_cats_trajs_dict: dictionary structured as: {scene: {category: [traj-data]}}\n",
    "def get_traj_data_by_scene_category_trajIdx(trajs_dicts, scene, category, trajIdx=0, tensorize=False, device=\"cpu\"):\n",
    "    # Get a single trajectory specified by idx, for a specificed category and scene\n",
    "    # TODO: maybe fix the \"depth\" dimension here directly ?\n",
    "    obs_list_dict = trajs_dicts[scene][category][trajIdx][\"edd\"][\"obs_list\"]\n",
    "    done_list = trajs_dicts[scene][category][trajIdx][\"edd\"][\"done_list\"]\n",
    "    target_scene_idx_list, target_category_idx_list = [], []\n",
    "\n",
    "    obs_dict_list = []\n",
    "    T = len(obs_list_dict[\"rgb\"])\n",
    "    for t in range(T):\n",
    "        obs_dict_list.append({k: v[t] for k, v in obs_list_dict.items()})\n",
    "        target_scene_idx_list.append(TARGET_SCENE_DICT[scene])\n",
    "        target_category_idx_list.append(CATEGORY_INDEX_MAPPING[category])\n",
    "\n",
    "    # Tensorize if required\n",
    "    if tensorize:\n",
    "        done_list__th = []\n",
    "        obs_dict_list__th = []\n",
    "\n",
    "        for t, (obs_dict, done) in enumerate(zip(obs_dict_list, done_list)):\n",
    "            # done_list__th.append(th.Tensor(np.array([done])[None, :]))\n",
    "            done_list__th.append(th.Tensor(np.array([done])).to(device)) # TODO: make sure that the deprecation warning stops showing up. Or always stay on current Torch version.\n",
    "            tmp_dict = {}\n",
    "            for k, v in obs_dict.items():\n",
    "                if k == \"depth\":\n",
    "                    v = np.array(v)[:, :, None] # From (H, W) -> (H, W, 1)\n",
    "                tmp_dict[k] = th.Tensor(v)[None, :].to(device)\n",
    "            \n",
    "            obs_dict_list__th.append(tmp_dict)\n",
    "        \n",
    "        return obs_dict_list__th, done_list__th, target_scene_idx_list, target_category_idx_list\n",
    "        \n",
    "    return obs_dict_list, done_list, target_scene_idx_list, target_category_idx_list\n",
    "\n",
    "def get_traj_data_by_scene_category(trajs_dicts, scene, category, tensorize=False, device=\"cpu\"):\n",
    "    # Get all trajectories for a specific category and scene\n",
    "    obs_dict_list, done_list = [], []\n",
    "    target_scene_idx_list, target_category_idx_list = [], []\n",
    "\n",
    "    for i in range(len(trajs_dicts[scene][category])):\n",
    "        traj_obs_dict_list, traj_done_list, target_scene_idxes, target_category_idxes = \\\n",
    "            get_traj_data_by_scene_category_trajIdx(trajs_dicts, scene, category, i, tensorize=tensorize, device=device)\n",
    "\n",
    "        obs_dict_list.extend(traj_obs_dict_list)\n",
    "        done_list.extend(traj_done_list)\n",
    "        target_scene_idx_list.extend(target_scene_idxes)\n",
    "        target_category_idx_list.extend(target_category_idxes)\n",
    "\n",
    "        traj_length = len(traj_done_list)\n",
    "        # print(f\"Selected traj of length: {traj_length}\")\n",
    "\n",
    "    return obs_dict_list, done_list, target_scene_idx_list, target_category_idx_list\n",
    "\n",
    "def get_traj_data_by_scene(trajs_dicts, scene, tensorize=False, device=\"cpu\"):\n",
    "    # Get all trajectories for a specific category, across all scenes and all trajectories\n",
    "    obs_dict_list, done_list =[], []\n",
    "    target_scene_idx_list, target_category_idx_list = [], []\n",
    "    \n",
    "    for cat in trajs_dicts[scene].keys():\n",
    "        cat_obs_dict_list, cat_done_list, target_scene_idxes, target_category_idxes = \\\n",
    "            get_traj_data_by_scene_category(trajs_dicts, scene, cat, tensorize=tensorize, device=device)\n",
    "\n",
    "        obs_dict_list.extend(cat_obs_dict_list)\n",
    "        done_list.extend(cat_done_list)\n",
    "        target_scene_idx_list.extend(target_scene_idxes)\n",
    "        target_category_idx_list.extend(target_category_idxes)\n",
    "    \n",
    "    return obs_dict_list, done_list, target_scene_idx_list, target_category_idx_list\n",
    "\n",
    "def get_all_traj_data_by_scene(trajs_dicts, tensorize=False, device=\"cpu\"):\n",
    "    # Get all trajectories for a specific category, across all scenes and all trajectories\n",
    "    obs_dict_list, done_list =[], []\n",
    "    target_scene_idx_list, target_category_idx_list = [], []\n",
    "\n",
    "    for scene in trajs_dicts.keys():\n",
    "        # Too rushing / lazy to change the names of the temporary list of obs\n",
    "        cat_scene_obs_dict_list, cat_scene_done_list, cat_target_scene_idxes, cat_target_category_idxes = \\\n",
    "            get_traj_data_by_category(trajs_dicts, scene, tensorize=tensorize, device=device)\n",
    "\n",
    "        obs_dict_list.extend(cat_scene_obs_dict_list)\n",
    "        done_list.extend(cat_scene_done_list)\n",
    "        target_scene_idx_list.extend(cat_target_scene_idxes)\n",
    "        target_category_idx_list.extend(cat_target_category_idxes)\n",
    "    \n",
    "    return obs_dict_list, done_list, target_scene_idx_list, target_category_idx_list\n",
    "# endregion: Scenes -> Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GRU Agent: 'ppo_bc__sweep_gru_512'\n",
      "  GW size: 512\n",
      "Loaded GW Agent: 'ppo_bc__sweep_gw_64'\n",
      "  GW size: 512\n"
     ]
    }
   ],
   "source": [
    "# Loading pretrained agent\n",
    "MODEL_VARIANTS_TO_STATEDICT_PATH = {\n",
    "    ## GRU\n",
    "    # region: SAVI BC GRUv3 variants: rec enc gw3 detach\n",
    "    \"ppo_bc__sweep_gru_512\": {\n",
    "        \"pretty_name\": \"GRU 1\",\n",
    "        \"state_dict_path\": \"/home/rousslan/random/rl/exp-logs/ss-hab-bc-revised-sweep/\"\n",
    "            \"ppo_bc_seed_42__2024_02_05_18_30_00_569723.musashi\"\n",
    "            # \"/models/ppo_agent.19995001.ckpt.pth\",\n",
    "            \"/models/ppo_agent.10000500.ckpt.pth\",\n",
    "        # TODO: prending probes\n",
    "        \"probe_path\": \"/home/rousslan/random/rl/exp-logs/ss-hab-bc-probing/\"\n",
    "            \"ppo_bc__savi_ss1_rgb_spectro__gruv3__gw_detach__usenull__grulynrm__entcoef_0.2__no_cew__n_mb_50__prb_dpth_2_seed_111__2023_11_16_16_08_52_068321.conan\"\n",
    "    },\n",
    "    # endregion: SAVI BC GRUv3 variants: rec enc gw3 detach\n",
    "\n",
    "    ## GWTv3 H=512\n",
    "    # region: SAVI BC GWTv3 variants: rec enc gw3 detach; CA uses null\n",
    "    \"ppo_bc__sweep_gw_64\": {\n",
    "        \"pretty_name\": \"GW | 1\",\n",
    "        \"state_dict_path\": \"/home/rousslan/random/rl/exp-logs/ss-hab-bc-revised-sweep/\"\n",
    "            \"ppo_bc_seed_42__2024_01_23_15_44_57_777702.musashi\"\n",
    "            \"/models/ppo_agent.10000500.ckpt.pth\",\n",
    "        # TODO: prending probes\n",
    "        \"probe_path\": \"/home/rousslan/random/rl/exp-logs/ss-hab-bc-probing/\"\n",
    "            \"ppo_bc__savi_ss1_rgb_spectro__gwtv3__gw_detach__usenull__grulynrm__entcoef_0.2__no_cew__n_mb_50__prb_dpth_2_seed_111__2023_11_14_18_38_49_687853.musashi\"\n",
    "    },\n",
    "    # endregion: SAVI BC GWTv3 variants: rec enc gw3 detach; CA uses null\n",
    "}\n",
    "\n",
    "# dev = th.device(\"cpu\")\n",
    "dev = th.device(\"cuda\")\n",
    "\n",
    "# 'variant named' indexed 'torch agent'\n",
    "MODEL_VARIANTS_TO_AGENTMODEL = {}\n",
    "\n",
    "for k, v in MODEL_VARIANTS_TO_STATEDICT_PATH.items():\n",
    "    args_copy = copy.copy(args)\n",
    "    # Override args depending on the model in use\n",
    "    if k.__contains__(\"gru\"):\n",
    "        print(f\"Loaded GRU Agent: '{k}'\")\n",
    "        tmp_args = copy.copy(args)\n",
    "        # TODO: find a better way, swap hidden size and agent type checking script\n",
    "        if k.__contains__(\"64\"):\n",
    "          tmp_args.gw_size = 64\n",
    "        elif k.__contains__(\"512\"):\n",
    "          tmp_args.gw_size = 512\n",
    "\n",
    "        print(f\"  GW size: {tmp_args.hidden_size}\")\n",
    "\n",
    "        agent = GRU_Actor(single_observation_space, single_action_space, tmp_args,\n",
    "            analysis_layers=models.GWTAGENT_DEFAULT_ANALYSIS_LAYER_NAMES)\n",
    "        # print(agent)\n",
    "    elif k.__contains__(\"gw\"):\n",
    "        print(f\"Loaded GW Agent: '{k}'\")\n",
    "        tmp_args = copy.copy(args)\n",
    "        # TODO: find a better way:\n",
    "        if k.__contains__(\"64\"):\n",
    "          tmp_args.gw_size = 64\n",
    "        elif k.__contains__(\"512\"):\n",
    "          tmp_args.gw_size = 512\n",
    "        print(f\"  GW size: {tmp_args.hidden_size}\")\n",
    "\n",
    "        agent = GW_Actor(single_observation_space, single_action_space, tmp_args,\n",
    "            analysis_layers=models.GWTAGENT_DEFAULT_ANALYSIS_LAYER_NAMES + [\"state_encoder.ca.mha\"])\n",
    "        # print(agent)\n",
    "\n",
    "    agent.eval()\n",
    "    # Load the model weights\n",
    "    # TODO: add map location device to use CPU only ?\n",
    "    if v[\"state_dict_path\"] != \"\":\n",
    "        agent_state_dict = th.load(v[\"state_dict_path\"], map_location=dev)\n",
    "        agent.load_state_dict(agent_state_dict)\n",
    "    agent = agent.to(dev)\n",
    "\n",
    "    MODEL_VARIANTS_TO_AGENTMODEL[k] = agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ss-hab-headless-py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
