{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook support or argpase\n",
    "import sys; sys.argv=['']; del sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import apex\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import compress_pickle as cpkl\n",
    "\n",
    "import rsatoolbox\n",
    "from torchinfo import summary\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.gridspec import GridSpec\n",
    "# plt.style.use(\"seaborn-darkgrid\")\n",
    "\n",
    "import wandb\n",
    "\n",
    "import models\n",
    "from models import GW_Actor, GRU_Actor\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "%matplotlib inline\n",
    "\n",
    "from ss_baselines.common.utils import plot_top_down_map\n",
    "\n",
    "\n",
    "mpl.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "mpl.rcParams[\"axes.facecolor\"] = \"white\"\n",
    "mpl.rcParams[\"savefig.facecolor\"] = \"white\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General config related\n",
    "from configurator import get_arg_dict, generate_args\n",
    "\n",
    "# Env config related\n",
    "from ss_baselines.av_nav.config import get_config\n",
    "from ss_baselines.savi.config.default import get_config as get_savi_config\n",
    "from ss_baselines.common.env_utils import construct_envs\n",
    "from ss_baselines.common.environments import get_env_class\n",
    "\n",
    "# region: Generating additional hyparams\n",
    "CUSTOM_ARGS = [\n",
    "\t# General hyper parameters\n",
    "\tget_arg_dict(\"seed\", int, 111),\n",
    "\tget_arg_dict(\"total-steps\", int, 1_000_000),\n",
    "\n",
    "\t# Behavior cloning gexperiment config\n",
    "\tget_arg_dict(\"dataset-path\", str, \"SAVI_Oracle_Dataset_v0\"),\n",
    "\n",
    "\t# SS env config\n",
    "\tget_arg_dict(\"config-path\", str, \"env_configs/savi/savi_ss1_rgb_spectro.yaml\"),\n",
    "\n",
    "\t# PPO Hyper parameters\n",
    "\tget_arg_dict(\"num-envs\", int, 10), # Number of parallel envs. 10 by default\n",
    "\tget_arg_dict(\"num-steps\", int, 150), # For each env, how many steps are collected to form PPO Agent rollout.\n",
    "\tget_arg_dict(\"num-minibatches\", int, 1), # Number of mini-batches the rollout data is split into to make the updates\n",
    "\tget_arg_dict(\"update-epochs\", int, 4), # Number of gradient step for the policy and value networks\n",
    "\tget_arg_dict(\"gamma\", float, 0.99),\n",
    "\tget_arg_dict(\"gae-lambda\", float, 0.95),\n",
    "\tget_arg_dict(\"norm-adv\", bool, True, metatype=\"bool\"),\n",
    "\tget_arg_dict(\"clip-coef\", float, 0.1), # Surrogate loss clipping coefficient\n",
    "\tget_arg_dict(\"clip-vloss\", bool, True, metatype=\"bool\"),\n",
    "\tget_arg_dict(\"ent-coef\", float, 0.2), # Entropy loss coef; 0.2 in SS baselines\n",
    "\tget_arg_dict(\"vf-coef\", float, 0.5), # Value loss coefficient\n",
    "\tget_arg_dict(\"max-grad-norm\", float, 0.5),\n",
    "\tget_arg_dict(\"target-kl\", float, None),\n",
    "\tget_arg_dict(\"lr\", float, 2.5e-4), # Learning rate\n",
    "\tget_arg_dict(\"optim-wd\", float, 0), # weight decay for adam optim\n",
    "\t## Agent network params\n",
    "\tget_arg_dict(\"agent-type\", str, \"gw\", metatype=\"choice\",\n",
    "\t\tchoices=[\"gw\", \"gru\"]),\n",
    "\tget_arg_dict(\"gru-type\", str, \"layernorm\", metatype=\"choice\",\n",
    "\t\t\t\t\tchoices=[\"default\", \"layernorm\"]),\n",
    "\tget_arg_dict(\"hidden-size\", int, 512), # Size of the visual / audio features\n",
    "\n",
    "\t## BC related hyper parameters\n",
    "\tget_arg_dict(\"batch-chunk-length\", int, 0), # For gradient accumulation\n",
    "\tget_arg_dict(\"dataset-ce-weights\", bool, False, metatype=\"bool\"), # If True, will read CEL weights based on action dist. from the 'dataset_statistics.bz2' file.\n",
    "\tget_arg_dict(\"ce-weights\", float, None, metatype=\"list\"), # Weights for the Cross Entropy loss\n",
    "\n",
    "\t## GW Agent with custom attention, recurrent encoder and null inputs\n",
    "\tget_arg_dict(\"gw-size\", int, 512), # Dim of the GW vector\n",
    "\tget_arg_dict(\"recenc-use-gw\", bool, True, metatype=\"bool\"), # Use GW at Recur. Enc. level\n",
    "\tget_arg_dict(\"recenc-gw-detach\", bool, True, metatype=\"bool\"), # When using GW at Recurrent Encoder level, whether to detach the grads or not\n",
    "\tget_arg_dict(\"gw-use-null\", bool, True, metatype=\"bool\"), # Use Null at CrossAtt level\n",
    "\tget_arg_dict(\"gw-cross-heads\", int, 1), # num_heads of the CrossAttn\n",
    "\n",
    "\t# Eval protocol\n",
    "\tget_arg_dict(\"eval\", bool, True, metatype=\"bool\"),\n",
    "\tget_arg_dict(\"eval-every\", int, int(1.5e4)), # Every X frames || steps sampled\n",
    "\tget_arg_dict(\"eval-n-episodes\", int, 5),\n",
    "\n",
    "\t# Logging params\n",
    "\t# NOTE: Video logging expensive\n",
    "\tget_arg_dict(\"save-videos\", bool, False, metatype=\"bool\"),\n",
    "\tget_arg_dict(\"save-model\", bool, True, metatype=\"bool\"),\n",
    "\tget_arg_dict(\"save-model-every\", int, int(5e5)), # Every X frames || steps sampled\n",
    "\tget_arg_dict(\"log-sampling-stats-every\", int, int(1.5e3)), # Every X frames || steps sampled\n",
    "\tget_arg_dict(\"log-training-stats-every\", int, int(10)), # Every X model update\n",
    "\tget_arg_dict(\"logdir-prefix\", str, \"./logs/\") # Overrides the default one\n",
    "]\n",
    "args = generate_args(CUSTOM_ARGS)\n",
    "# endregion: Generating additional hyparams\n",
    "\n",
    "# Load environment config\n",
    "is_SAVi = str.__contains__(args.config_path, \"savi\")\n",
    "if is_SAVi:\n",
    "\tenv_config = get_savi_config(config_paths=args.config_path)\n",
    "else:\n",
    "\tenv_config = get_config(config_paths=args.config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate obs / act space based on args and env_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dict(audiogoal:Box(-3.4028235e+38, 3.4028235e+38, (2, 16000), float32), rgb:Box(0, 255, (128, 128, 3), uint8), spectrogram:Box(-3.4028235e+38, 3.4028235e+38, (65, 26, 2), float32)),\n",
       " Discrete(4))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overriding some envs parametes from the .yaml env config\n",
    "env_config.defrost()\n",
    "env_config.NUM_PROCESSES = 1 # Corresponds to number of envs, makes script startup faster for debugs\n",
    "env_config.USE_SYNC_VECENV = True\n",
    "# env_config.USE_VECENV = False\n",
    "# env_config.CONTINUOUS = args.env_continuous\n",
    "## In caes video saving is enabled, make sure there is also the rgb videos\n",
    "env_config.freeze()\n",
    "# print(env_config)\n",
    "\n",
    "# Environment instantiation\n",
    "# envs = construct_envs(env_config, get_env_class(env_config.ENV_NAME))\n",
    "# Dummy environment spaces\n",
    "\n",
    "# TODO: add dyanmicallly set single_observation_space so that RGB and RGBD based variants\n",
    "# can be evaluated at thet same time\n",
    "from gym import spaces\n",
    "single_action_space = spaces.Discrete(4)\n",
    "single_observation_space = spaces.Dict({\n",
    "    \"rgb\": spaces.Box(shape=[128,128,3], low=0, high=255, dtype=np.uint8),\n",
    "    # \"depth\": spaces.Box(shape=[128,128,1], low=0, high=255, dtype=np.uint8),\n",
    "    \"audiogoal\": spaces.Box(shape=[2,16000], low=-3.4028235e+38, high=3.4028235e+38, dtype=np.float32),\n",
    "    \"spectrogram\": spaces.Box(shape=[65,26,2], low=-3.4028235e+38, high=3.4028235e+38, dtype=np.float32)\n",
    "})\n",
    "# single_observation_space = envs.observation_spaces[0]\n",
    "# single_action_space = envs.action_spaces[0]\n",
    "\n",
    "single_observation_space, single_action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Category-Scene-Trajs, Scene-Category-Trajs, and Dataset's metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loads data for analysis, as well as dataset's metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of categories C: 6 | # of scenes: 56\n",
      "TARGET_CATEGORY_DICT: {'chair': 0, 'picture': 1, 'table': 2, 'cushion': 3, 'cabinet': 4, 'plant': 5}\n",
      "TARGET_SCENE_DICT: {'gTV8FGcVJC9': 0, '5LpN3gDmAk7': 1, 'vyrNrziPKCB': 2, 'b8cTxDM8gDG': 3, 'Vvot9Ly1tCj': 4, 'rPc6DW4iMge': 5, 'PuKPg4mmafe': 6, '759xd9YjKW5': 7, 'ZMojNkEp431': 8, 'VzqfbhrpDEA': 9, 'ac26ZMwG7aT': 10, 'D7N2EKCX4Sj': 11, 'E9uDoFAP3SH': 12, 'S9hNv5qa7GM': 13, '5q7pvUzZiYa': 14, 'kEZ7cmS4wCh': 15, 'VFuaQ6m2Qom': 16, '7y3sRwLe3Va': 17, 'p5wJjkQkbXX': 18, 'V2XKFyX4ASd': 19, 'VVfe2KiqLaN': 20, 'mJXqzFtmKg4': 21, 'SN83YJsR3w2': 22, 'EDJbREhghzL': 23, 'PX4nDJXEHrG': 24, 'JmbYfDe2QKZ': 25, 'r1Q1Z4BcV1o': 26, 'aayBHfsNo7d': 27, 'r47D5H71a5s': 28, 'pRbA3pwrgk9': 29, 'Pm6F8kyY3z2': 30, 'sKLMLpTHeUy': 31, 'GdvgFV5R1Z5': 32, 'e9zR4mvMWw7': 33, 'JeFG25nYj2p': 34, 'B6ByNegPMKs': 35, 'uNb9QFRL6hY': 36, 'cV4RVeZvu5T': 37, 'D7G3Y4RVNrH': 38, 'XcA2TqTSSAj': 39, 'ur6pFq6Qu1A': 40, '29hnd4uzFmX': 41, 's8pcmisQ38h': 42, 'qoiz87JEwZ2': 43, 'ULsKaCPVFJR': 44, '1pXnuDYAj8r': 45, 'VLzqgDo317F': 46, 'YmJkqBEsHnH': 47, 'sT4fr6TAbpF': 48, 'jh4fc5c5qoQ': 49, '8WUmhLawc2A': 50, '1LXtFkjw3qL': 51, '17DRP5sb8fy': 52, '82sE5b5pLXE': 53, 'JF19kD82Mey': 54, 'Uxmj2M2itWa': 55}\n",
      "\n",
      "chair:\n",
      "\tgTV8FGcVJC9: [28, 10, 46, 9, 6]\n",
      "\tb8cTxDM8gDG: [15, 19, 26, 20, 8]\n",
      "\tD7N2EKCX4Sj: [19, 36, 12, 40, 33]\n",
      "\tVvot9Ly1tCj: [18, 21, 23, 16, 27]\n",
      "\tvyrNrziPKCB: [20, 24, 10, 14, 28]\n",
      "\n",
      "picture:\n",
      "\tgTV8FGcVJC9: [10, 12, 16, 20, 17]\n",
      "\tD7N2EKCX4Sj: [46, 31, 53, 39, 43]\n",
      "\tvyrNrziPKCB: [12, 38, 18, 14, 15]\n",
      "\tVvot9Ly1tCj: [24, 51, 31, 41, 35]\n",
      "\tb8cTxDM8gDG: [33, 12, 13, 20, 11]\n",
      "\n",
      "table:\n",
      "\tvyrNrziPKCB: [22, 22, 54, 57, 12]\n",
      "\tb8cTxDM8gDG: [17, 9, 16, 25, 14]\n",
      "\tD7N2EKCX4Sj: [6, 31, 24, 28, 17]\n",
      "\tVvot9Ly1tCj: [23, 41, 14, 34, 32]\n",
      "\tgTV8FGcVJC9: [16, 13, 15, 18, 15]\n",
      "\n",
      "cushion:\n",
      "\tb8cTxDM8gDG: [7, 14, 22, 12, 8]\n",
      "\tVvot9Ly1tCj: [36, 32, 47, 36, 46]\n",
      "\tvyrNrziPKCB: [62, 18, 21, 42, 54]\n",
      "\tgTV8FGcVJC9: [10, 11, 27, 7, 13]\n",
      "\tD7N2EKCX4Sj: [21, 12, 14, 14, 20]\n",
      "\n",
      "cabinet:\n",
      "\tgTV8FGcVJC9: [13, 13, 18, 47, 13]\n",
      "\tvyrNrziPKCB: [30, 22, 22, 40, 47]\n",
      "\tb8cTxDM8gDG: [10, 14, 21, 24, 16]\n",
      "\tVvot9Ly1tCj: [9, 35, 42, 39, 28]\n",
      "\tD7N2EKCX4Sj: [21, 34, 14, 40, 10]\n",
      "\n",
      "plant:\n",
      "\tgTV8FGcVJC9: [6, 13, 42, 6, 41]\n",
      "\tVvot9Ly1tCj: [16, 47, 23, 11, 26]\n",
      "\tb8cTxDM8gDG: [6, 8, 13, 11, 8]\n",
      "\tvyrNrziPKCB: [36, 21, 59, 34, 34]\n",
      "\tD7N2EKCX4Sj: [27, 31, 37, 26, 47]\n",
      "\n",
      "gTV8FGcVJC9\n",
      "\tchair: [28, 10, 46, 9, 6]\n",
      "\tpicture: [10, 12, 16, 20, 17]\n",
      "\ttable: [16, 13, 15, 18, 15]\n",
      "\tcushion: [10, 11, 27, 7, 13]\n",
      "\tcabinet: [13, 13, 18, 47, 13]\n",
      "\tplant: [6, 13, 42, 6, 41]\n",
      "\n",
      "b8cTxDM8gDG\n",
      "\tchair: [15, 19, 26, 20, 8]\n",
      "\tpicture: [33, 12, 13, 20, 11]\n",
      "\ttable: [17, 9, 16, 25, 14]\n",
      "\tcushion: [7, 14, 22, 12, 8]\n",
      "\tcabinet: [10, 14, 21, 24, 16]\n",
      "\tplant: [6, 8, 13, 11, 8]\n",
      "\n",
      "D7N2EKCX4Sj\n",
      "\tchair: [19, 36, 12, 40, 33]\n",
      "\tpicture: [46, 31, 53, 39, 43]\n",
      "\ttable: [6, 31, 24, 28, 17]\n",
      "\tcushion: [21, 12, 14, 14, 20]\n",
      "\tcabinet: [21, 34, 14, 40, 10]\n",
      "\tplant: [27, 31, 37, 26, 47]\n",
      "\n",
      "Vvot9Ly1tCj\n",
      "\tchair: [18, 21, 23, 16, 27]\n",
      "\tpicture: [24, 51, 31, 41, 35]\n",
      "\ttable: [23, 41, 14, 34, 32]\n",
      "\tcushion: [36, 32, 47, 36, 46]\n",
      "\tcabinet: [9, 35, 42, 39, 28]\n",
      "\tplant: [16, 47, 23, 11, 26]\n",
      "\n",
      "vyrNrziPKCB\n",
      "\tchair: [20, 24, 10, 14, 28]\n",
      "\tpicture: [12, 38, 18, 14, 15]\n",
      "\ttable: [22, 22, 54, 57, 12]\n",
      "\tcushion: [62, 18, 21, 42, 54]\n",
      "\tcabinet: [30, 22, 22, 40, 47]\n",
      "\tplant: [36, 21, 59, 34, 34]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify file name\n",
    "analysis_trajs_filename = \"cats_scenes_trajs_C_6_M_5_N_5__2023_06_01_10_41.bz2\"\n",
    "\n",
    "# Read the filtred trajectories data\n",
    "## Default format is {cat -> { scenes -> traj: []}}\n",
    "with open(analysis_trajs_filename, \"rb\") as f:\n",
    "    cats_scenes_trajs_dict = cpkl.load(f)\n",
    "\n",
    "## Compute the equivalent scenes cat trajs format\n",
    "## {scenes -> { cat -> trajs: []}}\n",
    "scenes_cats_trajs_dict = {}\n",
    "for cat, cat_scenes_trajs in cats_scenes_trajs_dict.items():\n",
    "    for scene, scenes_trajs in cat_scenes_trajs.items():\n",
    "        if scene not in scenes_cats_trajs_dict.keys():\n",
    "            scenes_cats_trajs_dict[scene] = {}\n",
    "        \n",
    "        scenes_cats_trajs_dict[scene][cat] = scenes_trajs\n",
    "\n",
    "# Generic: load the dataset statistics\n",
    "## Compute action coefficient for CEL of BC\n",
    "dataset_stats_filepath = f\"{args.dataset_path}/dataset_statistics.bz2\"\n",
    "# Override dataset statistics if the file already exists\n",
    "if os.path.exists(dataset_stats_filepath):\n",
    "    with open(dataset_stats_filepath, \"rb\") as f:\n",
    "        dataset_statistics = cpkl.load(f)\n",
    "\n",
    "# Extract some global metadata\n",
    "# TARGET_SCENE_LIST = list(cats_scenes_trajs_dict[list(cats_scenes_trajs_dict.keys())[0]].keys())\n",
    "TARGET_SCENE_LIST = list(dataset_statistics[\"scene_counts\"].keys())\n",
    "TARGET_SCENE_DICT = {scene: i for i, scene in enumerate(TARGET_SCENE_LIST)}\n",
    "TARGET_CATEGORY_LIST = list(cats_scenes_trajs_dict.keys())\n",
    "TARGET_CATEGORY_DICT = {cat: i for i, cat in enumerate(TARGET_CATEGORY_LIST)}\n",
    "\n",
    "from soundspaces.mp3d_utils import CATEGORY_INDEX_MAPPING\n",
    "def get_category_name(idx):\n",
    "    assert idx >= 0 and idx <=20, f\"Invalid category index number: {idx}\"\n",
    "\n",
    "    for catname, catidx in CATEGORY_INDEX_MAPPING.items():\n",
    "        if catidx == idx:\n",
    "            return catname\n",
    "\n",
    "def get_sceneid_by_idx(scene_idx):\n",
    "    for k, v in TARGET_SCENE_DICT.items():\n",
    "        if v == scene_idx:\n",
    "            return k\n",
    "\n",
    "C = len(TARGET_CATEGORY_LIST) # C: total number of categories\n",
    "M = len(TARGET_SCENE_LIST) # M: total number of rooms, assuming all categories has N trajs for a same set of scenes.\n",
    "\n",
    "print(f\"# of categories C: {C} | # of scenes: {M}\")\n",
    "print(f\"TARGET_CATEGORY_DICT: {TARGET_CATEGORY_DICT}\")\n",
    "print(f\"TARGET_SCENE_DICT: {TARGET_SCENE_DICT}\")\n",
    "print(\"\")\n",
    "\n",
    "# for catname, cat_scenes_trajs in cats_scenes_trajs_dict.items():\n",
    "#     print(f\"Cat: {catname}; Scenes: {[k for k in cat_scenes_trajs.keys()]}\")\n",
    "\n",
    "# Basic check of the scene -> categories fileted trajectories\n",
    "# for scene, scenes_cat_trajs in scenes_cats_trajs_dict.items():\n",
    "#     print(f\"Scene: {scene}; Cats: {[k for k in scenes_cat_trajs.keys()]}\")\n",
    "\n",
    "# More detailed breakdown of the trajectories per categories then scenes\n",
    "for catname, cat_scenes_trajs in cats_scenes_trajs_dict.items():\n",
    "    print(f\"{catname}:\")\n",
    "    for scene, scene_trajs in cat_scenes_trajs.items():\n",
    "        traj_lengths = [len(traj_data[\"edd\"][\"done_list\"]) for traj_data in scene_trajs]\n",
    "        print(f\"\\t{scene}: {traj_lengths}\")\n",
    "    print(\"\")\n",
    "\n",
    "# More detailed breakdown of the trajectories per categories then scenes\n",
    "for scene, scene_cats_trajs in scenes_cats_trajs_dict.items():\n",
    "    print(f\"{scene}\")\n",
    "    for cat, cat_trajs in scene_cats_trajs.items():\n",
    "        traj_lengths = [len(traj_data[\"edd\"][\"done_list\"]) for traj_data in cat_trajs]\n",
    "        print(f\"\\t{cat}: {traj_lengths}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers to extract traj. data based on \"category\", \"scene\", etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region: Categories -> Scenes\n",
    "## cats_scenes_trajs_dict: dictionary structured as: {category: {scene: [traj_data]}}\n",
    "# TODO: add support for the device in case tensors are returned\n",
    "def get_traj_data_by_category_scene_trajIdx(trajs_dicts, category, scene, trajIdx=0, tensorize=False, device=\"cpu\"):\n",
    "    # Get a single trajectory specified by idx, for a specificed category and scene\n",
    "    # TODO: maybe fix the \"depth\" dimension here directly ?\n",
    "    obs_list_dict = trajs_dicts[category][scene][trajIdx][\"edd\"][\"obs_list\"]\n",
    "    done_list = trajs_dicts[category][scene][trajIdx][\"edd\"][\"done_list\"]\n",
    "\n",
    "    obs_dict_list = []\n",
    "    target_scene_idx_list, target_category_idx_list = [], []\n",
    "\n",
    "    T = len(obs_list_dict[\"rgb\"])\n",
    "    for t in range(T):\n",
    "        obs_dict_list.append({k: v[t] for k, v in obs_list_dict.items()})\n",
    "        target_scene_idx_list.append(TARGET_SCENE_DICT[scene])\n",
    "        target_category_idx_list.append(CATEGORY_INDEX_MAPPING[category])\n",
    "\n",
    "    # Tensorize if required\n",
    "    if tensorize:\n",
    "        done_list__th = []\n",
    "        obs_dict_list__th = []\n",
    "\n",
    "        for t, (obs_dict, done) in enumerate(zip(obs_dict_list, done_list)):\n",
    "            # done_list__th.append(th.Tensor(np.array([done])[None, :]))\n",
    "            done_list__th.append(th.Tensor(np.array([done])).to(device)) # TODO: make sure that the deprecation warning stops showing up. Or always stay on current Torch version.\n",
    "            tmp_dict = {}\n",
    "            for k, v in obs_dict.items():\n",
    "                if k == \"depth\":\n",
    "                    v = np.array(v)[:, :, None] # From (H, W) -> (H, W, 1)\n",
    "                tmp_dict[k] = th.Tensor(v)[None, :].to(device)\n",
    "            \n",
    "            obs_dict_list__th.append(tmp_dict)\n",
    "        \n",
    "        return obs_dict_list__th, done_list__th, target_scene_idx_list, target_category_idx_list\n",
    "\n",
    "    return obs_dict_list, done_list, target_scene_idx_list, target_category_idx_list\n",
    "\n",
    "def get_traj_data_by_category_scene(trajs_dicts, category, scene, max_scenes=0, tensorize=False, device=\"cpu\"):\n",
    "    # Get all trajectories for a specific category and scene\n",
    "    obs_dict_list, done_list = [], []\n",
    "    target_scene_idx_list, target_category_idx_list = [], []\n",
    "\n",
    "    N_SCENES = len(trajs_dicts[category][scene])\n",
    "    res_n_scenes = N_SCENES if max_scenes <= 0 else max_scenes\n",
    "\n",
    "    for i in range(N_SCENES):\n",
    "        traj_obs_dict_list, traj_done_list, target_scene_idxes, target_category_idxes = \\\n",
    "            get_traj_data_by_category_scene_trajIdx(trajs_dicts, category, scene, i, tensorize=tensorize, device=device)\n",
    "\n",
    "        obs_dict_list.extend(traj_obs_dict_list)\n",
    "        done_list.extend(traj_done_list)\n",
    "        target_scene_idx_list.extend(target_scene_idxes)\n",
    "        target_category_idx_list.extend(target_category_idxes)\n",
    "\n",
    "        traj_length = len(traj_done_list)\n",
    "        # print(f\"Selected traj of length: {traj_length}\")\n",
    "        if i >= res_n_scenes - 1:\n",
    "            break\n",
    "\n",
    "    return obs_dict_list, done_list, target_scene_idx_list, target_category_idx_list\n",
    "\n",
    "def get_traj_data_by_category(trajs_dicts, category, max_scenes=0, tensorize=False, device=\"cpu\"):\n",
    "    # Get all trajectories for a specific category, across all scenes and all trajectories\n",
    "    obs_dict_list, done_list =[], []\n",
    "    target_scene_idx_list, target_category_idx_list = [], []\n",
    "\n",
    "    for scene in trajs_dicts[category].keys():\n",
    "        scene_obs_dict_list, scene_done_list, target_scene_idxes, target_category_idxes = \\\n",
    "            get_traj_data_by_category_scene(trajs_dicts, category, scene, max_scenes=max_scenes, tensorize=tensorize, device=device)\n",
    "\n",
    "        obs_dict_list.extend(scene_obs_dict_list)\n",
    "        done_list.extend(scene_done_list)\n",
    "        target_scene_idx_list.extend(target_scene_idxes)\n",
    "        target_category_idx_list.extend(target_category_idxes)\n",
    "    \n",
    "    return obs_dict_list, done_list, target_scene_idx_list, target_category_idx_list\n",
    "\n",
    "def get_all_traj_data_by_category(trajs_dicts, tensorize=False, device=\"cpu\"):\n",
    "    # Get all trajectories for a specific category, across all scenes and all trajectories\n",
    "    obs_dict_list, done_list =[], []\n",
    "    target_scene_idx_list, target_category_idx_list = [], []\n",
    "\n",
    "    for cat in trajs_dicts.keys():\n",
    "        cat_scene_obs_dict_list, cat_scene_done_list, cat_target_scene_idxes, cat_target_category_idxes = \\\n",
    "            get_traj_data_by_category(trajs_dicts, cat, tensorize=tensorize, device=device)\n",
    "\n",
    "        obs_dict_list.extend(cat_scene_obs_dict_list)\n",
    "        done_list.extend(cat_scene_done_list)\n",
    "        target_scene_idx_list.extend(cat_target_scene_idxes)\n",
    "        target_category_idx_list.extend(cat_target_category_idxes)\n",
    "    \n",
    "    return obs_dict_list, done_list, target_scene_idx_list, target_category_idx_list\n",
    "# endregion: Categories -> Scenes\n",
    "\n",
    "\n",
    "# region: Scenes -> Categories\n",
    "# TODO: add \"return\" for target categories and scenes label\n",
    "## scenes_cats_trajs_dict: dictionary structured as: {scene: {category: [traj-data]}}\n",
    "def get_traj_data_by_scene_category_trajIdx(trajs_dicts, scene, category, trajIdx=0, tensorize=False, device=\"cpu\"):\n",
    "    # Get a single trajectory specified by idx, for a specificed category and scene\n",
    "    # TODO: maybe fix the \"depth\" dimension here directly ?\n",
    "    obs_list_dict = trajs_dicts[scene][category][trajIdx][\"edd\"][\"obs_list\"]\n",
    "    done_list = trajs_dicts[scene][category][trajIdx][\"edd\"][\"done_list\"]\n",
    "    target_scene_idx_list, target_category_idx_list = [], []\n",
    "\n",
    "    obs_dict_list = []\n",
    "    T = len(obs_list_dict[\"rgb\"])\n",
    "    for t in range(T):\n",
    "        obs_dict_list.append({k: v[t] for k, v in obs_list_dict.items()})\n",
    "        target_scene_idx_list.append(TARGET_SCENE_DICT[scene])\n",
    "        target_category_idx_list.append(CATEGORY_INDEX_MAPPING[category])\n",
    "\n",
    "    # Tensorize if required\n",
    "    if tensorize:\n",
    "        done_list__th = []\n",
    "        obs_dict_list__th = []\n",
    "\n",
    "        for t, (obs_dict, done) in enumerate(zip(obs_dict_list, done_list)):\n",
    "            # done_list__th.append(th.Tensor(np.array([done])[None, :]))\n",
    "            done_list__th.append(th.Tensor(np.array([done])).to(device)) # TODO: make sure that the deprecation warning stops showing up. Or always stay on current Torch version.\n",
    "            tmp_dict = {}\n",
    "            for k, v in obs_dict.items():\n",
    "                if k == \"depth\":\n",
    "                    v = np.array(v)[:, :, None] # From (H, W) -> (H, W, 1)\n",
    "                tmp_dict[k] = th.Tensor(v)[None, :].to(device)\n",
    "            \n",
    "            obs_dict_list__th.append(tmp_dict)\n",
    "        \n",
    "        return obs_dict_list__th, done_list__th, target_scene_idx_list, target_category_idx_list\n",
    "        \n",
    "    return obs_dict_list, done_list, target_scene_idx_list, target_category_idx_list\n",
    "\n",
    "def get_traj_data_by_scene_category(trajs_dicts, scene, category, tensorize=False, device=\"cpu\"):\n",
    "    # Get all trajectories for a specific category and scene\n",
    "    obs_dict_list, done_list = [], []\n",
    "    target_scene_idx_list, target_category_idx_list = [], []\n",
    "\n",
    "    for i in range(len(trajs_dicts[scene][category])):\n",
    "        traj_obs_dict_list, traj_done_list, target_scene_idxes, target_category_idxes = \\\n",
    "            get_traj_data_by_scene_category_trajIdx(trajs_dicts, scene, category, i, tensorize=tensorize, device=device)\n",
    "\n",
    "        obs_dict_list.extend(traj_obs_dict_list)\n",
    "        done_list.extend(traj_done_list)\n",
    "        target_scene_idx_list.extend(target_scene_idxes)\n",
    "        target_category_idx_list.extend(target_category_idxes)\n",
    "\n",
    "        traj_length = len(traj_done_list)\n",
    "        # print(f\"Selected traj of length: {traj_length}\")\n",
    "\n",
    "    return obs_dict_list, done_list, target_scene_idx_list, target_category_idx_list\n",
    "\n",
    "def get_traj_data_by_scene(trajs_dicts, scene, tensorize=False, device=\"cpu\"):\n",
    "    # Get all trajectories for a specific category, across all scenes and all trajectories\n",
    "    obs_dict_list, done_list =[], []\n",
    "    target_scene_idx_list, target_category_idx_list = [], []\n",
    "    \n",
    "    for cat in trajs_dicts[scene].keys():\n",
    "        cat_obs_dict_list, cat_done_list, target_scene_idxes, target_category_idxes = \\\n",
    "            get_traj_data_by_scene_category(trajs_dicts, scene, cat, tensorize=tensorize, device=device)\n",
    "\n",
    "        obs_dict_list.extend(cat_obs_dict_list)\n",
    "        done_list.extend(cat_done_list)\n",
    "        target_scene_idx_list.extend(target_scene_idxes)\n",
    "        target_category_idx_list.extend(target_category_idxes)\n",
    "    \n",
    "    return obs_dict_list, done_list, target_scene_idx_list, target_category_idx_list\n",
    "\n",
    "def get_all_traj_data_by_scene(trajs_dicts, tensorize=False, device=\"cpu\"):\n",
    "    # Get all trajectories for a specific category, across all scenes and all trajectories\n",
    "    obs_dict_list, done_list =[], []\n",
    "    target_scene_idx_list, target_category_idx_list = [], []\n",
    "\n",
    "    for scene in trajs_dicts.keys():\n",
    "        # Too rushing / lazy to change the names of the temporary list of obs\n",
    "        cat_scene_obs_dict_list, cat_scene_done_list, cat_target_scene_idxes, cat_target_category_idxes = \\\n",
    "            get_traj_data_by_category(trajs_dicts, scene, tensorize=tensorize, device=device)\n",
    "\n",
    "        obs_dict_list.extend(cat_scene_obs_dict_list)\n",
    "        done_list.extend(cat_scene_done_list)\n",
    "        target_scene_idx_list.extend(cat_target_scene_idxes)\n",
    "        target_category_idx_list.extend(cat_target_category_idxes)\n",
    "    \n",
    "    return obs_dict_list, done_list, target_scene_idx_list, target_category_idx_list\n",
    "# endregion: Scenes -> Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ppo_bc__gw_32': {'pretty_name': 'GW 32 [1]', 'state_dict_path': '/home/rousslan/random/rl/exp-logs/ss-hab-bc-revised-final/ppo_bc_seed_1__2024_02_13_10_37_37_585583.Loki/ppo_agent.20001000.ckpt.pth'}}\n",
      "{'ppo_bc__gw_32': {'pretty_name': 'GW 32 [1]', 'state_dict_path': '/home/rousslan/random/rl/exp-logs/ss-hab-bc-revised-final/ppo_bc_seed_1__2024_02_13_10_37_37_585583.Loki/ppo_agent.20001000.ckpt.pth'}, 'ppo_bc__gw_64': {'pretty_name': 'GW 64 [1]', 'state_dict_path': '/home/rousslan/random/rl/exp-logs/ss-hab-bc-revised-final/ppo_bc_seed_1__2024_02_13_10_37_42_215535.Loki/ppo_agent.20001000.ckpt.pth'}}\n",
      "{'ppo_bc__gw_32': {'pretty_name': 'GW 32 [1]', 'state_dict_path': '/home/rousslan/random/rl/exp-logs/ss-hab-bc-revised-final/ppo_bc_seed_1__2024_02_13_10_37_37_585583.Loki/ppo_agent.20001000.ckpt.pth'}, 'ppo_bc__gw_64': {'pretty_name': 'GW 64 [1]', 'state_dict_path': '/home/rousslan/random/rl/exp-logs/ss-hab-bc-revised-final/ppo_bc_seed_1__2024_02_13_10_37_42_215535.Loki/ppo_agent.20001000.ckpt.pth'}, 'ppo_bc__gw_128': {'pretty_name': 'GW 128 [1]', 'state_dict_path': '=====================================================================================/ppo_agent.20001000.ckpt.pth'}}\n",
      "{'ppo_bc__gw_32': {'pretty_name': 'GW 32 [1]', 'state_dict_path': '/home/rousslan/random/rl/exp-logs/ss-hab-bc-revised-final/ppo_bc_seed_1__2024_02_13_10_37_37_585583.Loki/ppo_agent.20001000.ckpt.pth'}, 'ppo_bc__gw_64': {'pretty_name': 'GW 64 [1]', 'state_dict_path': '/home/rousslan/random/rl/exp-logs/ss-hab-bc-revised-final/ppo_bc_seed_1__2024_02_13_10_37_42_215535.Loki/ppo_agent.20001000.ckpt.pth'}, 'ppo_bc__gw_128': {'pretty_name': 'GW 128 [1]', 'state_dict_path': '=====================================================================================/ppo_agent.20001000.ckpt.pth'}, 'ppo_bc__gw_256': {'pretty_name': 'GW 256 [1]', 'state_dict_path': '/home/rousslan/random/rl/exp-logs/ss-hab-bc-revised-final/ppo_bc_seed_1__2024_02_13_10_37_41_449423.Loki/ppo_agent.20001000.ckpt.pth'}}\n",
      "{'ppo_bc__gw_32': {'pretty_name': 'GW 32 [1]', 'state_dict_path': '/home/rousslan/random/rl/exp-logs/ss-hab-bc-revised-final/ppo_bc_seed_1__2024_02_13_10_37_37_585583.Loki/ppo_agent.20001000.ckpt.pth'}, 'ppo_bc__gw_64': {'pretty_name': 'GW 64 [1]', 'state_dict_path': '/home/rousslan/random/rl/exp-logs/ss-hab-bc-revised-final/ppo_bc_seed_1__2024_02_13_10_37_42_215535.Loki/ppo_agent.20001000.ckpt.pth'}, 'ppo_bc__gw_128': {'pretty_name': 'GW 128 [1]', 'state_dict_path': '=====================================================================================/ppo_agent.20001000.ckpt.pth'}, 'ppo_bc__gw_256': {'pretty_name': 'GW 256 [1]', 'state_dict_path': '/home/rousslan/random/rl/exp-logs/ss-hab-bc-revised-final/ppo_bc_seed_1__2024_02_13_10_37_41_449423.Loki/ppo_agent.20001000.ckpt.pth'}, 'ppo_bc__gru_32': {'pretty_name': 'GRU 32 [2]', 'state_dict_path': '/home/rousslan/random/rl/exp-logs/ss-hab-bc-revised-final/ppo_bc_seed_2__2024_02_14_23_16_31_981756.musashi/ppo_agent.20001000.ckpt.pth'}}\n",
      "{'ppo_bc__gw_32': {'pretty_name': 'GW 32 [1]', 'state_dict_path': '/home/rousslan/random/rl/exp-logs/ss-hab-bc-revised-final/ppo_bc_seed_1__2024_02_13_10_37_37_585583.Loki/ppo_agent.20001000.ckpt.pth'}, 'ppo_bc__gw_64': {'pretty_name': 'GW 64 [1]', 'state_dict_path': '/home/rousslan/random/rl/exp-logs/ss-hab-bc-revised-final/ppo_bc_seed_1__2024_02_13_10_37_42_215535.Loki/ppo_agent.20001000.ckpt.pth'}, 'ppo_bc__gw_128': {'pretty_name': 'GW 128 [1]', 'state_dict_path': '=====================================================================================/ppo_agent.20001000.ckpt.pth'}, 'ppo_bc__gw_256': {'pretty_name': 'GW 256 [1]', 'state_dict_path': '/home/rousslan/random/rl/exp-logs/ss-hab-bc-revised-final/ppo_bc_seed_1__2024_02_13_10_37_41_449423.Loki/ppo_agent.20001000.ckpt.pth'}, 'ppo_bc__gru_32': {'pretty_name': 'GRU 32 [2]', 'state_dict_path': '/home/rousslan/random/rl/exp-logs/ss-hab-bc-revised-final/ppo_bc_seed_2__2024_02_14_23_16_31_981756.musashi/ppo_agent.20001000.ckpt.pth'}, 'ppo_bc__gru_64': {'pretty_name': 'GRU 64 [2]', 'state_dict_path': '/home/rousslan/random/rl/exp-logs/ss-hab-bc-revised-final/ppo_bc_seed_2__2024_02_14_23_16_39_041498.musashi/ppo_agent.20001000.ckpt.pth'}}\n"
     ]
    }
   ],
   "source": [
    "# Programmatically all the experiment runs, as well as their corresponding probing runs.\n",
    "## Consts\n",
    "WANDB_DL_PREFIX = \"wandb_api_dls\"\n",
    "\n",
    "## Placeholder for the run restuls\n",
    "REVISED_RUNS_DICT = {}\n",
    "\n",
    "## Read the list of probing runs first, and build a correspondance map\n",
    "## from original experimtn to probing runs\n",
    "revised_probing_runs = wandb.Api().runs(\"dosssman/ss-hab-bc-revised-finals-probing\"); revised_probing_runs # (iterable) list\n",
    "\n",
    "## Read the list of runs\n",
    "revised_exp_runs = wandb.Api().runs(\"dosssman/ss-hab-bc-revised-finals\"); revised_exp_runs # (iterable) list\n",
    "\n",
    "for idx, revised_run in enumerate(list(revised_exp_runs)[::-1]):\n",
    "  ## Recover some config attribute from the run, make a name for it\n",
    "  agent_type = revised_run.config[\"agent_type\"]\n",
    "  gw_size = revised_run.config[\"gw_size\"]\n",
    "  seed = revised_run.config[\"seed\"]\n",
    "  exp_name = revised_run.config[\"exp_name\"]\n",
    "\n",
    "  run_name = f\"ppo_bc__{agent_type}_{gw_size}\"\n",
    "\n",
    "  # Download the output log which should have the final experiment name\n",
    "  output_save_folder = f\"{WANDB_DL_PREFIX}/{run_name}\"\n",
    "  list(revised_run.files(\"output.log\"))[0].download(output_save_folder, exist_ok=True)\n",
    "\n",
    "  with open(f\"{output_save_folder}/output.log\", 'r') as f:\n",
    "    # Extract the folder where the experimetns results and weights\n",
    "    # were ultimately saved in\n",
    "    exp_logdir_path = f.readlines()[2].replace(\"# Logdir: \", \"\")\n",
    "    exp_logdir_path = exp_logdir_path.replace(\"\\n\", \"\") # Get rid of return to line char\n",
    "    updated_exp_name = exp_logdir_path.split('/')[-1]\n",
    "    \n",
    "    # TODO: also extract the path for the probing run model\n",
    "  REVISED_RUNS_DICT[run_name] = {\n",
    "    \"pretty_name\": f\"{agent_type.upper()} {gw_size} [{seed}]\",\n",
    "    # TODO: do all the run properly finish and have this ckpt ?\n",
    "    \"state_dict_path\": f\"{exp_logdir_path}/ppo_agent.20001000.ckpt.pth\",\n",
    "  }\n",
    "\n",
    "  # print(exp_logdir_path)\n",
    "  # print(updated_exp_name)\n",
    "\n",
    "  # REVISED_RUNS_DICT\n",
    "  print(REVISED_RUNS_DICT)\n",
    "\n",
    "  if idx >= 5:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gru\n",
      "32\n",
      "42\n",
      "ppo_bc__gru_32__seed_5\n",
      "ppo_bc_seed_5__2024_03_18_15_32_51_804393.Loki\n",
      "\n",
      "gru\n",
      "128\n",
      "42\n",
      "ppo_bc__gru_128__seed_5\n",
      "ppo_bc_seed_5__2024_03_18_15_33_00_377812.Loki\n",
      "\n",
      "gru\n",
      "512\n",
      "42\n",
      "ppo_bc__gru_512__seed_4\n",
      "ppo_bc_seed_4__2024_03_13_05_53_11_750600.musashi\n",
      "\n",
      "gru\n",
      "256\n",
      "42\n",
      "ppo_bc__gru_256__seed_5\n",
      "ppo_bc_seed_5__2024_03_11_09_00_37_506684.Loki\n",
      "\n",
      "gw\n",
      "64\n",
      "42\n",
      "ppo_bc__gw_64__seed_3\n",
      "ppo_bc_seed_3__2024_03_16_01_28_14_973721.Loki\n",
      "\n",
      "gru\n",
      "512\n",
      "42\n",
      "ppo_bc__gru_512__seed_3\n",
      "ppo_bc_seed_3__2024_03_13_02_17_37_317057.musashi\n",
      "\n",
      "{'ppo_bc_seed_5__2024_03_18_15_32_51_804393.Loki': 'exp-logs/ss-hab-bc-probing/ppo_bc_seed_2__2024_02_14_23_16_39_041498.musashi', 'ppo_bc_seed_5__2024_03_18_15_33_00_377812.Loki': 'exp-logs/ss-hab-bc-probing/ppo_bc_seed_2__2024_02_14_23_16_39_041498.musashi', 'ppo_bc_seed_4__2024_03_13_05_53_11_750600.musashi': 'exp-logs/ss-hab-bc-probing/ppo_bc_seed_2__2024_02_14_23_16_39_041498.musashi', 'ppo_bc_seed_5__2024_03_11_09_00_37_506684.Loki': 'exp-logs/ss-hab-bc-probing/ppo_bc_seed_2__2024_02_14_23_16_39_041498.musashi', 'ppo_bc_seed_3__2024_03_16_01_28_14_973721.Loki': 'exp-logs/ss-hab-bc-probing/ppo_bc_seed_2__2024_02_14_23_16_39_041498.musashi', 'ppo_bc_seed_3__2024_03_13_02_17_37_317057.musashi': 'exp-logs/ss-hab-bc-probing/ppo_bc_seed_2__2024_02_14_23_16_39_041498.musashi'}\n"
     ]
    }
   ],
   "source": [
    "revised_probing_runs = wandb.Api().runs(\"dosssman/ss-hab-bc-revised-finals-probing\"); revised_probing_runs # (iterable) list\n",
    "final_to_probing_runs_dict = {}\n",
    "\n",
    "for idx, probing_run in enumerate(revised_probing_runs):\n",
    "  ## Recover some config attribute from the run, make a name for it\n",
    "  ## Shared with the orignal agent experiment\n",
    "  agent_type = probing_run.config[\"agent_type\"]\n",
    "  gw_size = probing_run.config[\"gw_size\"]\n",
    "  seed = probing_run.config[\"seed\"]\n",
    "  exp_name = probing_run.config[\"exp_name\"]\n",
    "\n",
    "  ## This refers to the run name of the revised experiment itself,\n",
    "  ## not the probing\n",
    "  run_name = f\"ppo_bc__{agent_type}_{gw_size}\"\n",
    "\n",
    "  pretrained_model_path = probing_run.config[\"pretrained_model_path\"]\n",
    "  original_exp_run = pretrained_model_path.split('/')[-3] # Get the folder of the revised run experiment\n",
    "  print(agent_type)\n",
    "  print(gw_size)\n",
    "  print(seed)\n",
    "  print(exp_name)\n",
    "  print(original_exp_run)\n",
    "  print(\"\")\n",
    "  # print(list(probing_run.files()))\n",
    "  # for bfp in list(probing_run.files()):\n",
    "  #   print(bfp)\n",
    "  # print(probing_run.files(\"output.log\")[0])\n",
    "\n",
    "  # Download the output log which should have the final experiment name\n",
    "  # output_save_folder = f\"{WANDB_DL_PREFIX}/probing/{run_name}\"\n",
    "  # list(probing_run.files(\"output.log\"))[0].download(output_save_folder, exist_ok=True)\n",
    "\n",
    "  # with open(f\"{output_save_folder}/output.log\", 'r') as f:\n",
    "  #   # Extract the folder where the experimetns results and weights\n",
    "  #   # were ultimately saved in\n",
    "  #   exp_logdir_path = f.readlines()[2].replace(\"# Logdir: \", \"\")\n",
    "  #   exp_logdir_path = exp_logdir_path.replace(\"\\n\", \"\") # Get rid of return to line char\n",
    "  #   updated_exp_name = exp_logdir_path.split('/')[-1]\n",
    "\n",
    "  final_to_probing_runs_dict[original_exp_run] = f\"exp-logs/ss-hab-bc-probing/{updated_exp_name}\"\n",
    "  if idx >= 5:\n",
    "    break\n",
    "\n",
    "print(final_to_probing_runs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.00025,\n",
       " 'cpu': False,\n",
       " 'eval': True,\n",
       " 'notb': False,\n",
       " 'seed': 42,\n",
       " 'gamma': 0.99,\n",
       " 'wandb': True,\n",
       " 'logdir': None,\n",
       " 'resume': '',\n",
       " 'gw_size': 64,\n",
       " 'vf_coef': 0.5,\n",
       " 'ent_coef': 0.2,\n",
       " 'exp_name': 'ppo_bc__gw_64__seed_1',\n",
       " 'gru_type': 'layernorm',\n",
       " 'hostname': 'conan',\n",
       " 'log_name': None,\n",
       " 'n_epochs': 10,\n",
       " 'norm_adv': True,\n",
       " 'num_envs': 10,\n",
       " 'optim_wd': 0,\n",
       " 'clip_coef': 0.1,\n",
       " 'num_steps': 150,\n",
       " 'target_kl': None,\n",
       " 'agent_type': 'gw',\n",
       " 'batch_size': 1500,\n",
       " 'ce_weights': None,\n",
       " 'clip_vloss': True,\n",
       " 'eval_every': 15000,\n",
       " 'gae_lambda': 0.95,\n",
       " 'gpu_device': '',\n",
       " 'probe_bias': False,\n",
       " 'save_model': True,\n",
       " 'config_path': 'env_configs/savi/savi_ss1_rgb_spectro.yaml',\n",
       " 'gw_use_null': True,\n",
       " 'hidden_size': 512,\n",
       " 'probe_depth': 2,\n",
       " 'save_videos': False,\n",
       " 'total_steps': 500000,\n",
       " 'dataset_path': 'SAVI_Oracle_Dataset_v0',\n",
       " 'gpu_auto_rev': False,\n",
       " 'wandb_entity': 'dosssman',\n",
       " 'logdir_prefix': '/home/rousslan/random/rl/exp-logs/ss-hab-bc-revised-finals-probing',\n",
       " 'max_grad_norm': 0.5,\n",
       " 'recenc_use_gw': True,\n",
       " 'update_epochs': 4,\n",
       " 'wandb_project': 'ss-hab-bc-revised-finals-probing',\n",
       " 'gw_cross_heads': 1,\n",
       " 'minibatch_size': 30,\n",
       " 'probe_hid_size': 512,\n",
       " 'probing_inputs': ['state_encoder',\n",
       "  'visual_encoder.rnn',\n",
       "  'audio_encoder.rnn'],\n",
       " 'cudnn_benchmark': False,\n",
       " 'eval_n_episodes': 5,\n",
       " 'num_minibatches': 50,\n",
       " 'probing_targets': ['category', 'scene'],\n",
       " 'recenc_gw_detach': True,\n",
       " 'save_model_every': 500000,\n",
       " 'batch_chunk_length': 10,\n",
       " 'dataset_ce_weights': False,\n",
       " 'torch_deterministic': True,\n",
       " 'gpu_auto_max_n_procs': 2,\n",
       " 'pretrained_model_name': 'ppo_bc__gw_64__seed_1',\n",
       " 'pretrained_model_path': '/home/rousslan/random/rl/exp-logs/ss-hab-bc-revised-final/ppo_bc_seed_1__2024_02_13_10_37_42_215535.Loki/models/ppo_agent.20001000.ckpt.pth',\n",
       " 'log_sampling_stats_every': 1500,\n",
       " 'log_training_stats_every': 10}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probing_run = list(revised_probing_runs)[-1]; probing_run.config\n",
    "probing_run.config\n",
    "# list(probing_run.files())\n",
    "# list(probing_run.files(\"output.log\"))[0].download(\"tmp_wandb\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<File artifact/725518757/wandb_manifest.json (application/json) 0.0B>,\n",
       " <File config.yaml () 3.1KiB>,\n",
       " <File events.out.tfevents.1707788262.Loki.3615968.0 () 8.6MiB>,\n",
       " <File output.log () 136.1KiB>,\n",
       " <File wandb-summary.json (application/json) 1.7KiB>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_run = list(revised_exp_runs)[-3]\n",
    "list(test_run.files())\n",
    "# list(test_run.files())[3].download(\"tmp_wandb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GRU Agent: 'ppo_bc__sweep_gru_512'\n",
      "  Feat size: 512\n",
      "  GW size: 512\n",
      "Loaded GW Agent: 'ppo_bc__sweep_gw_64'\n",
      "  Feat size: 512\n",
      "  GW size: 64\n"
     ]
    }
   ],
   "source": [
    "# Loading pretrained agent\n",
    "MODEL_VARIANTS_TO_STATEDICT_PATH = {\n",
    "    ## GRU\n",
    "    # region: SAVI BC GRUv3 variants: rec enc gw3 detach\n",
    "    \"ppo_bc__sweep_gru_512\": {\n",
    "        \"pretty_name\": \"GRU 1 (Sweep)\",\n",
    "        \"state_dict_path\": \"/home/rousslan/random/rl/exp-logs/ss-hab-bc-revised-sweep/\"\n",
    "            \"ppo_bc_seed_42__2024_02_05_18_30_00_569723.musashi\"\n",
    "            # \"/models/ppo_agent.19995001.ckpt.pth\",\n",
    "            \"/models/ppo_agent.10000500.ckpt.pth\",\n",
    "        # TODO: prending probes\n",
    "        \"probe_path\": \"/home/rousslan/random/rl/exp-logs/ss-hab-bc-probing/\"\n",
    "            \"ppo_bc__savi_ss1_rgb_spectro__gruv3__gw_detach__usenull__grulynrm__entcoef_0.2__no_cew__n_mb_50__prb_dpth_2_seed_111__2023_11_16_16_08_52_068321.conan\"\n",
    "    },\n",
    "    # endregion: SAVI BC GRUv3 variants: rec enc gw3 detach\n",
    "\n",
    "    ## GWTv3 H=512\n",
    "    # region: SAVI BC GWTv3 variants: rec enc gw3 detach; CA uses null\n",
    "    \"ppo_bc__sweep_gw_64\": {\n",
    "        \"pretty_name\": \"GW 1 (Sweep)\",\n",
    "        \"state_dict_path\": \"/home/rousslan/random/rl/exp-logs/ss-hab-bc-revised-sweep/\"\n",
    "            \"ppo_bc_seed_42__2024_01_23_15_44_57_777702.musashi\"\n",
    "            \"/models/ppo_agent.10000500.ckpt.pth\",\n",
    "        # TODO: prending probes\n",
    "        \"probe_path\": \"/home/rousslan/random/rl/exp-logs/ss-hab-bc-probing/\"\n",
    "            \"ppo_bc__savi_ss1_rgb_spectro__gwtv3__gw_detach__usenull__grulynrm__entcoef_0.2__no_cew__n_mb_50__prb_dpth_2_seed_111__2023_11_14_18_38_49_687853.musashi\"\n",
    "    },\n",
    "    # endregion: SAVI BC GWTv3 variants: rec enc gw3 detach; CA uses null\n",
    "}\n",
    "\n",
    "# dev = th.device(\"cpu\")\n",
    "dev = th.device(\"cuda\")\n",
    "\n",
    "# 'variant named' indexed 'torch agent'\n",
    "MODEL_VARIANTS_TO_AGENTMODEL = {}\n",
    "\n",
    "for k, v in MODEL_VARIANTS_TO_STATEDICT_PATH.items():\n",
    "    args_copy = copy.copy(args)\n",
    "    tmp_args = copy.copy(args)\n",
    "\n",
    "    # Detected the  gw_size\n",
    "    for gw_size in [32, 64, 128, 256, 512]:\n",
    "        if k.__contains__(f\"{gw_size}\"):\n",
    "            tmp_args.gw_size = gw_size\n",
    "            break\n",
    "\n",
    "    # Override args depending on the model in use\n",
    "    if k.__contains__(\"gru\"):\n",
    "        print(f\"Loaded GRU Agent: '{k}'\")\n",
    "        print(f\"  Feat size: {tmp_args.hidden_size}\")\n",
    "        print(f\"  GW size: {tmp_args.gw_size}\")\n",
    "\n",
    "        agent = GRU_Actor(single_observation_space, single_action_space, tmp_args,\n",
    "            analysis_layers=models.GWTAGENT_DEFAULT_ANALYSIS_LAYER_NAMES)\n",
    "        # print(agent)\n",
    "    elif k.__contains__(\"gw\"):\n",
    "        print(f\"Loaded GW Agent: '{k}'\")\n",
    "        print(f\"  Feat size: {tmp_args.hidden_size}\")\n",
    "        print(f\"  GW size: {tmp_args.gw_size}\")\n",
    "\n",
    "        agent = GW_Actor(single_observation_space, single_action_space, tmp_args,\n",
    "            analysis_layers=models.GWTAGENT_DEFAULT_ANALYSIS_LAYER_NAMES + [\"state_encoder.ca.mha\"])\n",
    "        # print(agent)\n",
    "\n",
    "    agent.eval()\n",
    "    # Load the model weights\n",
    "    # TODO: add map location device to use CPU only ?\n",
    "    if v[\"state_dict_path\"] != \"\":\n",
    "        agent_state_dict = th.load(v[\"state_dict_path\"], map_location=dev)\n",
    "        agent.load_state_dict(agent_state_dict)\n",
    "    agent = agent.to(dev)\n",
    "\n",
    "    MODEL_VARIANTS_TO_AGENTMODEL[k] = agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GW_Actor(\n",
      "  (visual_encoder): RecurrentVisualEncoder(\n",
      "    (cnn): Sequential(\n",
      "      (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Flatten()\n",
      "    )\n",
      "    (rnn): GRUCell(\n",
      "      (_layer): Linear(in_features=2880, out_features=1536, bias=True)\n",
      "      (_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (audio_encoder): RecurrentAudioEncoder(\n",
      "    (cnn): Sequential(\n",
      "      (0): Conv2d(2, 32, kernel_size=(5, 5), stride=(2, 2))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Flatten()\n",
      "    )\n",
      "    (rnn): GRUCell(\n",
      "      (_layer): Linear(in_features=3072, out_features=1536, bias=True)\n",
      "      (_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (state_encoder): GWStateEncoder(\n",
      "    (ca): CrossAttention(\n",
      "      (proj_vis): Linear(in_features=512, out_features=64, bias=False)\n",
      "      (proj_aud): Linear(in_features=512, out_features=64, bias=False)\n",
      "      (ln_q): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln_k): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln_v): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (mha): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (rnn): GRUCell(\n",
      "      (_layer): Linear(in_features=192, out_features=192, bias=True)\n",
      "      (_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (action_distribution): CategoricalNet(\n",
      "    (linear): Linear(in_features=64, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process agents features, retain the relevant ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the subset of cached features that will be analyzed\n",
    "# CACHE_DIRNAME = \"cats_scenes_trajs_C_6_M_5_N_5__2023_06_01_10_41__ablation_agents_features__cache\"\n",
    "# FEATURES_CACHE_DIRNAME = f\"cached_data/features/cats_scenes_trajs_C_6_M_5_N_5__2023_06_01_10_41\"\n",
    "\n",
    "CATEGORIES_OF_INTEREST = [\n",
    "    \"chair\",\n",
    "    # \"picture\",\n",
    "    # \"cabinet\",\n",
    "    # \"plant\",\n",
    "    # \"cushion\",\n",
    "    # \"table\"\n",
    "]\n",
    "SCENES_OF_INTEREST = [\n",
    "    \"gTV8FGcVJC9\",\n",
    "    # \"D7N2EKCX4Sj\",\n",
    "    # \"b8cTxDM8gDG\",\n",
    "    # \"Vvot9Ly1tCj\",\n",
    "    # \"vyrNrziPKCB\"\n",
    "] # ['gTV8FGcVJC9', 'b8cTxDM8gDG', 'D7N2EKCX4Sj', 'Vvot9Ly1tCj', 'vyrNrziPKCB']\n",
    "TRAJ_INDICES = [\n",
    "    0,\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    4\n",
    "] # Only select trajectories in indices of interest\n",
    "ABLATIONS_OF_INTEREST = [\"default\", \"vision\", \"audio\", \"zeros\"]\n",
    "LAYERS_OF_INTEREST = [\n",
    "    \"visual_encoder.rnn\", \"audio_encoder.rnn\",\n",
    "    \"state_encoder\",\n",
    "    \"state_encoder.ca.mha\", \"state_encoder.ca\"\n",
    "]\n",
    "AGENTS_OF_INTEREST = [\n",
    "    ## GRU H=512\n",
    "    \"ppo_bc__sweep_gru_512\",\n",
    "    \n",
    "    ## GWTv3 H=64\n",
    "    \"ppo_bc__sweep_gw_64\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect visual, audio, state features for all agent variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chair:\n",
      "  gTV8FGcVJC9: [28, 10, 46, 9, 6]\n",
      "    Traj 0: Length: 28\n",
      "        Model variant: ppo_bc__sweep_gru_512\n",
      "          Detected GW size: 512\n",
      "        Model variant: ppo_bc__sweep_gw_64\n",
      "          Detected GW size: 64\n",
      "    Traj 1: Length: 10\n",
      "        Model variant: ppo_bc__sweep_gru_512\n",
      "          Detected GW size: 512\n",
      "        Model variant: ppo_bc__sweep_gw_64\n",
      "          Detected GW size: 64\n",
      "    Traj 2: Length: 46\n",
      "        Model variant: ppo_bc__sweep_gru_512\n",
      "          Detected GW size: 512\n",
      "        Model variant: ppo_bc__sweep_gw_64\n",
      "          Detected GW size: 64\n",
      "    Traj 3: Length: 9\n",
      "        Model variant: ppo_bc__sweep_gru_512\n",
      "          Detected GW size: 512\n",
      "        Model variant: ppo_bc__sweep_gw_64\n",
      "          Detected GW size: 64\n",
      "    Traj 4: Length: 6\n",
      "        Model variant: ppo_bc__sweep_gru_512\n",
      "          Detected GW size: 512\n",
      "        Model variant: ppo_bc__sweep_gw_64\n",
      "          Detected GW size: 64\n"
     ]
    }
   ],
   "source": [
    "# Collect the relevant features from the PGWT variants\n",
    "CAT_SCENE_TRAJS_FEATURES = {}\n",
    "\n",
    "## Helper for cleaning up and preparing the recorded intermediate features\n",
    "def process_analysis_feats_raw__occ_variant(raw_dict):\n",
    "    result_dict = {}\n",
    "\n",
    "    for k, v in raw_dict.items():\n",
    "        if isinstance(v[0], th.Tensor):\n",
    "            new_v = th.stack(v, dim=0).cpu()\n",
    "        elif isinstance(v[0], tuple):\n",
    "            new_v = None # TODO\n",
    "            n_elements = len(v[0])\n",
    "            elements = [[] for _ in range(n_elements)]\n",
    "            for j in range(n_elements):\n",
    "                for i in range(len(v)):\n",
    "                    elements[j].append(v[i][j])\n",
    "            \n",
    "            new_v = [th.stack(vv, dim=0).cpu() for vv in elements]\n",
    "        else:\n",
    "            raise Exception(f\"Unhandled type: {v[0].__class__}\")\n",
    "\n",
    "        result_dict[k] = new_v\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "for catname, cat_scenes_trajs in cats_scenes_trajs_dict.items():\n",
    "    if catname not in CATEGORIES_OF_INTEREST:\n",
    "        continue\n",
    "\n",
    "    if catname not in CAT_SCENE_TRAJS_FEATURES.keys():\n",
    "        CAT_SCENE_TRAJS_FEATURES[catname] = {}\n",
    "    print(f\"{catname}:\")\n",
    "\n",
    "    for scene, scene_trajs in cat_scenes_trajs.items():\n",
    "        if scene not in SCENES_OF_INTEREST:\n",
    "            continue\n",
    "\n",
    "        traj_lengths = [len(traj_data[\"edd\"][\"done_list\"]) for traj_data in scene_trajs]\n",
    "        print(f\"  {scene}: {traj_lengths}\")\n",
    "\n",
    "        if scene not in CAT_SCENE_TRAJS_FEATURES[catname].keys():\n",
    "            CAT_SCENE_TRAJS_FEATURES[catname][scene] = {}\n",
    "        \n",
    "        for traj_idx, traj_data in enumerate(scene_trajs):\n",
    "            if traj_idx not in TRAJ_INDICES:\n",
    "                continue\n",
    "            \n",
    "            if traj_idx not in CAT_SCENE_TRAJS_FEATURES[catname][scene].keys():\n",
    "                CAT_SCENE_TRAJS_FEATURES[catname][scene][traj_idx] = {}\n",
    "\n",
    "            # Load the data, perform ablations if necessary\n",
    "            obs_dict_list, done_list, target_scene_idx_list, target_category_idx_list = \\\n",
    "                get_traj_data_by_category_scene_trajIdx(cats_scenes_trajs_dict, catname, scene, traj_idx, tensorize=True, device=dev)\n",
    "            \n",
    "            ep_length = len(obs_dict_list)\n",
    "            print(f\"    Traj {traj_idx}: Length: {ep_length}\")\n",
    "\n",
    "            # TODO: verify\n",
    "            CAT_SCENE_TRAJS_FEATURES[catname][scene][traj_idx][\"target_scene_idx_list\"] = target_scene_idx_list\n",
    "            CAT_SCENE_TRAJS_FEATURES[catname][scene][traj_idx][\"target_category_idx_list\"] = target_category_idx_list\n",
    "\n",
    "            for agent_variant, agent_model in MODEL_VARIANTS_TO_AGENTMODEL.items():\n",
    "                if agent_variant not in AGENTS_OF_INTEREST:\n",
    "                    continue\n",
    "                print(f\"        Model variant: {agent_variant}\")\n",
    "\n",
    "                agent_raw_features = {}\n",
    "                # Init the agent_rnn_state depending on the variant used\n",
    "                H = 512\n",
    "                for gw_size in [32, 64, 128, 256]:\n",
    "                    if agent_variant.__contains__(f\"{gw_size}\"):\n",
    "                        H = gw_size\n",
    "\n",
    "                print(f\"          Detected GW size: {H}\")\n",
    "\n",
    "                agent_rnn_state = th.zeros((1, H), device=dev)\n",
    "                modality_features = {\n",
    "                    \"audio\": agent_rnn_state.new_zeros([1, 512]),\n",
    "                    \"visual\": agent_rnn_state.new_zeros([1, 512])\n",
    "                }\n",
    "                \n",
    "                for t, (obs_th, done_th) in enumerate(zip(obs_dict_list, done_list)):\n",
    "                    \n",
    "                    masks = 1. - done_th[:, None]\n",
    "                    with th.no_grad():\n",
    "                        _, _, _, _, \\\n",
    "                        _, agent_rnn_state, modality_features = \\\n",
    "                            agent_model.act(obs_th, agent_rnn_state, masks=masks, \n",
    "                                modality_features=modality_features)\n",
    "\n",
    "                    # Collecting intermediate layers results\n",
    "                    for k, v in agent_model._features.items():\n",
    "                        if k not in LAYERS_OF_INTEREST:\n",
    "                            continue # Skip irrelevant layers\n",
    "                        if k not in list(agent_raw_features.keys()):\n",
    "                            agent_raw_features[k] = []\n",
    "                        agent_raw_features[k].append((v[0].cpu(), v[1].cpu()) if isinstance(v, tuple) else v.cpu())\n",
    "                \n",
    "                agent_layers_features = process_analysis_feats_raw__occ_variant(agent_raw_features)\n",
    "                del agent_raw_features\n",
    "\n",
    "                CAT_SCENE_TRAJS_FEATURES[catname][scene][traj_idx][agent_variant] = \\\n",
    "                    agent_layers_features\n",
    "                \n",
    "                # Caching features: TODO\n",
    "\n",
    "            del obs_dict_list, done_list, target_scene_idx_list, target_category_idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['state_encoder', 'visual_encoder.rnn', 'audio_encoder.rnn']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(CAT_SCENE_TRAJS_FEATURES.keys())\n",
    "list(CAT_SCENE_TRAJS_FEATURES[\"chair\"][\"gTV8FGcVJC9\"][0][\"ppo_bc__sweep_gru_512\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 1, 512])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CAT_SCENE_TRAJS_FEATURES[\"chair\"][\"gTV8FGcVJC9\"][0][\"ppo_bc__sweep_gru_512\"][\"state_encoder\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 1, 512])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CAT_SCENE_TRAJS_FEATURES[\"chair\"][\"gTV8FGcVJC9\"][0][\"ppo_bc__sweep_gru_512\"][\"visual_encoder.rnn\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 1, 512])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CAT_SCENE_TRAJS_FEATURES[\"chair\"][\"gTV8FGcVJC9\"][0][\"ppo_bc__sweep_gru_512\"][\"audio_encoder.rnn\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chair | gTV8FGcVJC9 | 0 | Length: 28\n",
      "chair | gTV8FGcVJC9 | 1 | Length: 10\n",
      "chair | gTV8FGcVJC9 | 2 | Length: 46\n",
      "chair | gTV8FGcVJC9 | 3 | Length: 9\n",
      "chair | gTV8FGcVJC9 | 4 | Length: 6\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.ticker import MaxNLocator, MultipleLocator\n",
    "\n",
    "colpal = sns.color_palette(\"tab10\")\n",
    "MOD_AXIS_TO_NAME = {0: \"Audio\", 1: \"Vision\", 2: r\"Prev. state $h_{t-1}$\", 3: \"Null\"}\n",
    "MOD_AXIS_TO_COLOR = { 0: colpal[2], 1: colpal[1], 2: colpal[0], 3: colpal[7]}\n",
    "\n",
    "# N_TRAJS = 4\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "# plt.style.use(\"ggplot\")\n",
    "\n",
    "TRAJS_OF_INTEREST_DICT = [\n",
    "  *[{\"category\": \"chair\", \"scene\": \"gTV8FGcVJC9\", \"traj_idx\": i} for i in range(5)]\n",
    "  # *[{\"category\": \"picture\", \"scene\": \"gTV8FGcVJC9\", \"traj_idx\": i} for i in range(5)] # No sound cutoffs \n",
    "  # *[{\"category\": \"cushion\", \"scene\": \"gTV8FGcVJC9\", \"traj_idx\": i} for i in range(5)]\n",
    "  # *[{\"category\": \"plant\", \"scene\": \"gTV8FGcVJC9\", \"traj_idx\": i} for i in range(5)]\n",
    "  # *[{\"category\": \"cabinet\", \"scene\": \"gTV8FGcVJC9\", \"traj_idx\": i} for i in range(5)]\n",
    "  # *[{\"category\": \"table\", \"scene\": \"gTV8FGcVJC9\", \"traj_idx\": i} for i in range(5)]\n",
    "]\n",
    "N_TRAJS = len(TRAJS_OF_INTEREST_DICT)\n",
    "fig, axes = plt.subplots(3, N_TRAJS, figsize=(N_TRAJS * 1.5, 3 * 1.25))\n",
    "\n",
    "\n",
    "AGENT_GROUPS_OF_INTEREST = {\n",
    "\n",
    "  \"GW H=64\": {\n",
    "    42: \"ppo_bc__sweep_gw_64\",\n",
    "  },\n",
    "  # },\n",
    "\n",
    "}\n",
    "\n",
    "# TODO: functionalize\n",
    "for ridx in range(3):\n",
    "  for cidx in range(N_TRAJS):\n",
    "    # Tweak the ylimit for all plots\n",
    "    axes[ridx, cidx].set_ylim(-0.05, 1.05)\n",
    "\n",
    "    if ridx == 0:\n",
    "      axes[ridx, cidx].xaxis.set_label_position(\"top\")\n",
    "      if cidx == 2:\n",
    "        axes[ridx, cidx].set_xlabel(f\"Trajectory\\n{cidx+1}\", fontsize=10)\n",
    "      else:\n",
    "        axes[ridx, cidx].set_xlabel(f\"{cidx+1}\", fontsize=10)\n",
    "    if cidx > 0:\n",
    "      axes[ridx, cidx].yaxis.set_major_locator(ticker.NullLocator())\n",
    "    if ridx < 2:\n",
    "      axes[ridx, cidx].xaxis.set_major_locator(ticker.NullLocator())\n",
    "    else:\n",
    "      axes[ridx, cidx].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "      if cidx == 2:\n",
    "        axes[ridx, cidx].set_xlabel(\"Time steps\", fontsize=9)\n",
    "\n",
    "# Plots labelling\n",
    "# ylabel_fontsize = 10\n",
    "axes[0, 0].set_ylabel(\"Audio\", fontsize=11)\n",
    "axes[1, 0].set_ylabel(\"Query\\n\\nVision\", fontsize=11)\n",
    "axes[2, 0].set_ylabel(\"GW\", fontsize=11)\n",
    "\n",
    "# Create custom legend handles and labels\n",
    "attn_weights_legend_handles = [\n",
    "    Line2D([0], [0], color=colpal[color], label=label)\n",
    "    for color, label in zip(\n",
    "      [0, 1, 2, 7],\n",
    "      [\"GW\", \"Vision\", \"Audio\", \"Null\"]\n",
    "    )\n",
    "]\n",
    "bottom_row_x_MultipleLocator_bases = []\n",
    "\n",
    "# Add legend\n",
    "# plt.legend(handles=probe_acc_legend_handles)\n",
    "\n",
    "# Iterate over traj data, plot if of interest\n",
    "trajint_idx = 0\n",
    "\n",
    "# TODO: rework the plotting to satisfy:\n",
    "# 1. Iterate over the trajectories of interest\n",
    "# 2. Group agent runs by seed, give them a name\n",
    "for trajint_idx, trajint_data in enumerate(TRAJS_OF_INTEREST_DICT):\n",
    "  cat = trajint_data[\"category\"]\n",
    "  scene = trajint_data[\"scene\"]\n",
    "  traj_idx = trajint_data[\"traj_idx\"]\n",
    "\n",
    "  # Load the current trajectory's data\n",
    "  # TODO: could count this during the processing phase somehow ?\n",
    "  obs_dict_list, _, _, _ = \\\n",
    "      get_traj_data_by_category_scene_trajIdx(cats_scenes_trajs_dict, cat, scene, traj_idx, tensorize=False)\n",
    "  \n",
    "  T = len(CAT_SCENE_TRAJS_FEATURES[cat][scene][traj_idx][\"target_category_idx_list\"])\n",
    "\n",
    "  if 0 < T <= 15:\n",
    "    bottom_row_x_MultipleLocator_bases.append(5)\n",
    "  elif T <= 50:\n",
    "    bottom_row_x_MultipleLocator_bases.append(10)\n",
    "  \n",
    "  mute_step = 0\n",
    "  spectrogram_obs_list = np.array([d[\"spectrogram\"] for d in obs_dict_list])\n",
    "  for t in range(T):\n",
    "    if spectrogram_obs_list[t].sum() >= 1e-6:\n",
    "      mute_step += 1\n",
    "    else:\n",
    "      break\n",
    "  mute_step = min(mute_step, T-1)\n",
    "\n",
    "  print(f\"{cat} | {scene} | {traj_idx} | Length: {T}\")\n",
    "\n",
    "  # Plot the probe accuracies\n",
    "  xs = np.arange(T)\n",
    "\n",
    "  ## Shading the non silent region in gray\n",
    "  [axes[i, trajint_idx].fill_between([0, mute_step+1], 0, [1.1, 1.1], color=\"gray\", alpha=0.125) for i in [0, 1, 2]]\n",
    "  \n",
    "  for agent_group, agent_group_data in AGENT_GROUPS_OF_INTEREST.items():\n",
    "    for exp_seed, exp_name in agent_group_data.items():\n",
    "\n",
    "      ## Fix the length of the x axis\n",
    "      [axes[i, trajint_idx].set_xlim([0, T-1]) for i in range(3)]\n",
    "\n",
    "      if exp_name.__contains__(\"gwtv3\"):\n",
    "        # Plot the attention weights for the GWTv3 variant\n",
    "        att_weights = CAT_SCENE_TRAJS_FEATURES[cat][scene][traj_idx][exp_name][\"state_encoder.ca.mha\"][1][:, 0, :, :]\n",
    "\n",
    "        for mod_idx in range(3):\n",
    "          for mod_axis in range(4):\n",
    "            mod_idx_offset = mod_idx-2\n",
    "            axes[mod_idx, trajint_idx].plot(xs, att_weights[:, mod_idx_offset, mod_axis], \n",
    "              linewidth=1.25,\n",
    "              label=MOD_AXIS_TO_NAME[mod_axis],\n",
    "              color=MOD_AXIS_TO_COLOR[mod_axis],\n",
    "              alpha=0.7)\n",
    "\n",
    "# Set legend using dashed lines before doing the dots / scater\n",
    "# axes[0, 0].legend(handles=probe_acc_legend_handles)\n",
    "# axes[2, N_TRAJS-1].legend(handles=attn_weights_legend_handles)\n",
    "# axes[2, 3].legend(handles=attn_weights_legend_handles, ncol=len(attn_weights_legend_handles), bbox_to_anchor=(0,0))\n",
    "for cidx in range(len(TRAJS_OF_INTEREST_DICT)):\n",
    "  axes[2, cidx].xaxis.set_major_locator(MultipleLocator(base=bottom_row_x_MultipleLocator_bases[cidx]))\n",
    "  if cidx == 2:\n",
    "      axes[1, cidx].set_xlabel(\"Time steps\")\n",
    "\n",
    "fig.subplots_adjust(wspace=0.08, hspace=0.08)\n",
    "fig.legend(handles=attn_weights_legend_handles, ncol=len(attn_weights_legend_handles), bbox_to_anchor=(0.782, 0.01))\n",
    "# fig.supxlabel(\"Trajectory\", va=\"top\")\n",
    "# fig.supylabel(\"Query\", ha=)\n",
    "# fig.tight_layout()\n",
    "fig.show()\n",
    "\n",
    "# fig.savefig(\"GWAgent_H_64_Seed_111_AttentionWeights.pdf\", bbox_inches=\"tight\")\n",
    "# fig.savefig(\"GWAgent_H_64_Seed_222_AttentionWeights.pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "# fig.savefig(\"GWAgent_H_512_Seed_111_AttentionWeights.pdf\", bbox_inches=\"tight\")\n",
    "# fig.savefig(\"GWAgent_H_512_Seed_222_AttentionWeights.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ss-hab-headless-py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
