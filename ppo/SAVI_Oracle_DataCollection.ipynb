{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import uuid\n",
    "import datetime\n",
    "import numpy as np\n",
    "import compress_pickle as cpkl\n",
    "\n",
    "from ss_baselines.av_nav.config import get_config\n",
    "from ss_baselines.savi.config.default import get_config as get_savi_config\n",
    "from ss_baselines.common.env_utils import construct_envs\n",
    "from ss_baselines.common.environments import get_env_class\n",
    "from ss_baselines.common.utils import plot_top_down_map\n",
    "\n",
    "# Helper / tools\n",
    "from soundspaces.mp3d_utils import CATEGORY_INDEX_MAPPING\n",
    "def get_category_name(idx):\n",
    "    assert idx >= 0 and idx <=20, f\"Invalid category index number: {idx}\"\n",
    "\n",
    "    for k, v in CATEGORY_INDEX_MAPPING.items():\n",
    "        if v == idx:\n",
    "            return k\n",
    "\n",
    "def get_env_scene_id(envs, env_idx):\n",
    "    # NOTE: might be different if using other wrapper like SYNC_ENV or VecEnv\n",
    "    return envs.workers[env_idx]._env._env.current_episode.scene_id.split(\"/\")[3]\n",
    "    # return envs.workers[env_idx]._env._env._task._sim._current_scene.strip(\"data/scene_datasets/mp3d\").split(\"/\")[0]\n",
    "\n",
    "def get_current_ep_category_label(obs_dict):\n",
    "    return get_category_name(obs_dict[\"category\"].argmax())\n",
    "\n",
    "def save_episode_to_dataset(ep_data_dict, dataset_path):\n",
    "    if not os.path.exists(dataset_path):\n",
    "        os.mkdir(dataset_path)\n",
    "    \n",
    "    timestamp = datetime.datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "    epid = str(uuid.uuid4().hex)\n",
    "    ep_length = ep_data_dict[\"ep_length\"]\n",
    "\n",
    "    # TODO: consider the downside of compression if this has to be used for \n",
    "    ep_scene_id = ep_data_dict[\"scene_id\"]\n",
    "    ep_category_name = ep_data_dict[\"category_name\"]\n",
    "\n",
    "    ep_data_filename = f\"{ep_scene_id}-{ep_category_name}-{ep_length}-{timestamp}-{epid}.bz2\"\n",
    "    ep_data_fullpath = os.path.join(dataset_path, ep_data_filename)\n",
    "    with open(ep_data_fullpath, \"wb\") as f:\n",
    "        cpkl.dump(ep_data_dict, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the environments for data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_savi_config(\n",
    "    # config_paths=\"ss_baselines/av_nav/config/audionav/mp3d/env_test_0.yaml\", # RGB + AudiogoalSensor\n",
    "    config_paths=\"env_configs/savi/savi_ss1.yaml\")\n",
    "config.defrost()\n",
    "## Seed override\n",
    "config.SEED = config.TASK_CONFIG.SEED = config.TASK_CONFIG.SIMULATOR.SEED = 101\n",
    "config.NUM_PROCESSES = 1\n",
    "config.USE_SYNC_VECENV = True\n",
    "config.USE_VECENV = False\n",
    "\n",
    "## Override semantic object sensor sizes: does RGB / Depth sensor's shape increase ?\n",
    "# config.DISPLAY_RESOLUTION = 512\n",
    "# config.TASK_CONFIG.TASK.SEMANTIC_OBJECT_SENSOR.HEIGHT = 512\n",
    "# config.TASK_CONFIG.TASK.SEMANTIC_OBJECT_SENSOR.WIDTH = 512\n",
    "\n",
    "# For custom resolution, disable the use of pre-rendered observations\n",
    "config.TASK_CONFIG.SIMULATOR.USE_RENDERED_OBSERVATIONS = False\n",
    "# For smoother video, set CONTINUOUS_VIEW_CHANGE to True, and get the additional frames in obs_dict[\"intermediate\"]\n",
    "config.TASK_CONFIG.SIMULATOR.CONTINUOUS_VIEW_CHANGE = False\n",
    "\n",
    "config.TASK_CONFIG.SIMULATOR.RGB_SENSOR.WIDTH = 512\n",
    "config.TASK_CONFIG.SIMULATOR.RGB_SENSOR.HEIGHT = 512\n",
    "config.TASK_CONFIG.SIMULATOR.DEPTH_SENSOR.WIDTH = 512\n",
    "config.TASK_CONFIG.SIMULATOR.DEPTH_SENSOR.HEIGHT = 512\n",
    "\n",
    "# Add support for TOP_DOWN_MAP\n",
    "config.TASK_CONFIG.TASK.MEASUREMENTS.append(\"TOP_DOWN_MAP\")\n",
    "config.freeze()\n",
    "# print(config)\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envs = construct_envs(config, get_env_class(config.ENV_NAME))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset parameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_TOTAL_STEPS = 50\n",
    "DATASET_DIR_PATH = f\"SAVI_Oracle_Dataset_2023_05_17__{DATASET_TOTAL_STEPS}__STEPS\"\n",
    "\n",
    "NUM_ENVS = config.NUM_PROCESSES"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholders for episode data\n",
    "obs_list, \\\n",
    "reward_list, \\\n",
    "done_list, \\\n",
    "info_list, \\\n",
    "action_list = \\\n",
    "    [[] for _ in range(NUM_ENVS)], \\\n",
    "    [[] for _ in range(NUM_ENVS)], \\\n",
    "    [[] for _ in range(NUM_ENVS)], \\\n",
    "    [[] for _ in range(NUM_ENVS)], \\\n",
    "    [[] for _ in range(NUM_ENVS)]\n",
    "# Plaecholders for various statistics about the training data\n",
    "dataset_statistics = {\n",
    "    \"action_counts\": {i: 0 for i in range(4)},\n",
    "    \"total_steps\": 0,\n",
    "    \"total_episodes\": 0,\n",
    "    \"scene_counts\": {},\n",
    "    \"category_counts\": {get_category_name(i): 0 for i in range(21)} # 21 categories in SAVi.\n",
    "}\n",
    "\n",
    "obs, done = envs.reset(), [False for _ in range(NUM_ENVS)]\n",
    "\n",
    "step = 0\n",
    "ep_returns = []\n",
    "envs_current_step = [0 for _ in range(NUM_ENVS)]\n",
    "\n",
    "while step < DATASET_TOTAL_STEPS:\n",
    "    # Recover the optimal action for each parallel env\n",
    "    actions = [envs.workers[i]._env._env._sim._oracle_actions[envs_current_step[i]] for i in range(NUM_ENVS)]\n",
    "\n",
    "    # Step the environment\n",
    "    outputs = envs.step(actions)\n",
    "    next_obs, reward, next_done, info = [list(x) for x in zip(*outputs)]\n",
    "\n",
    "    # Recorder episode trajectoreis\n",
    "    for i in range(NUM_ENVS):\n",
    "        obs_list[i].append(obs[i])\n",
    "        done_list[i].append(done[i])\n",
    "        action_list[i].append(actions[i])\n",
    "        reward_list[i].append(reward[i])\n",
    "        info_list[i].append(info[i])\n",
    "\n",
    "    # When one or more episode end is detected, write to disk,\n",
    "    # then reset the placeholders for the finished env. idx\n",
    "    if np.sum(next_done) >= 1.:\n",
    "        finished_envs_idxs = np.where(next_done)[0]\n",
    "    \n",
    "        for i in finished_envs_idxs:\n",
    "            if not info_list[i][-1][\"success\"] == 1:\n",
    "                continue\n",
    "        \n",
    "            ep_length = len(obs_list[i])\n",
    "            ep_returns = []\n",
    "            ep_success = []\n",
    "            ep_norm_dist_to_goal = []\n",
    "\n",
    "            # Pre-process the obs_dict to have lists of \"rgb\", \"depth\", etc..\n",
    "            obs_dict = {k: [] for k in obs_list[i][0].keys()} # TODO: to also store intermediate, maaybe use obs_list[i][1].keys() instead\n",
    "\n",
    "            # Stores the high resolution rgb and depth data\n",
    "            highres_obs_list = {k: [] for k in [\"rgb\", \"depth\"]}\n",
    "\n",
    "            for t in range(ep_length):\n",
    "                for k, v in obs_list[i][t].items():\n",
    "                    if k in [\"rgb\", \"depth\"]:\n",
    "                        highres_obs_list[k].append(v.copy()) # TODO: make sure the high res stuff is not resized later\n",
    "                        obs_dict[k].append(cv2.resize(v, dsize=(128, 128)))\n",
    "                    else:\n",
    "                        obs_dict[k].append(v)\n",
    "                \n",
    "                # Count actions for overall dataset statistics\n",
    "                dataset_statistics[\"action_counts\"][action_list[i][t]] += 1\n",
    "            \n",
    "            # Additional episode metadata\n",
    "            # TODO: episode's scene SPLIT\n",
    "            ep_scene_id = get_env_scene_id(envs, i)\n",
    "            ep_category_idx = obs_dict[\"category\"][0].argmax()\n",
    "            ep_category_name = get_category_name(ep_category_idx)\n",
    "\n",
    "            ep_data_dict = {\n",
    "                \"obs_list\": obs_dict, # RGB and DEPTH shape (128, 128, 3)\n",
    "                \"highres_obs_list\": highres_obs_list, # RGB and DEPTH shape (512, 512, 3)\n",
    "                \"action_list\": action_list[i],\n",
    "                \"done_list\": done_list[i],\n",
    "                \"reward_list\": reward_list[i],\n",
    "                \"info_list\": info_list[i], # This can arguably be skipped ?,\n",
    "                \"ep_length\": ep_length,\n",
    "                # Other metadata\n",
    "                \"scene_id\": ep_scene_id,\n",
    "                \"category_idx\": ep_category_idx,\n",
    "                \"category_name\": ep_category_name\n",
    "            }\n",
    "\n",
    "            ep_returns.append(np.sum(reward_list[i]))\n",
    "            # TODO: double check why the last info list is not the final one\n",
    "            ep_success.append(info_list[i][-1][\"success\"])\n",
    "            ep_norm_dist_to_goal.append(info_list[i][-1][\"normalized_distance_to_goal\"])\n",
    "\n",
    "            # Saves to disk\n",
    "            save_episode_to_dataset(ep_data_dict, DATASET_DIR_PATH)\n",
    "\n",
    "            step += ep_length\n",
    "\n",
    "            # Track overall statistics of the dataset\n",
    "            dataset_statistics[\"total_episodes\"] += 1\n",
    "            dataset_statistics[\"total_steps\"] += ep_length\n",
    "            dataset_statistics[\"category_counts\"][ep_category_name] += 1\n",
    "            if ep_scene_id not in dataset_statistics[\"scene_counts\"].keys():\n",
    "                dataset_statistics[\"scene_counts\"][ep_scene_id] = 1\n",
    "            else:\n",
    "                dataset_statistics[\"scene_counts\"][ep_scene_id] += 1\n",
    "\n",
    "            # Reset the data placeholders\n",
    "            obs_list[i], action_list[i], done_list[i], reward_list[i], info_list[i] = \\\n",
    "                [], [], [], [], []\n",
    "        \n",
    "            # Save the dataset statistics to file\n",
    "            ## Compute action probs\n",
    "            dataset_statistics[\"action_probs\"] = {\n",
    "                a: dataset_statistics[\"action_counts\"][a] / dataset_statistics[\"total_steps\"] for a in range(4)\n",
    "            }\n",
    "            dataset_statistics[\"action_cel_coefs\"] = {\n",
    "                k: (0.25 / v) if v > 0 else 0. for k, v in dataset_statistics[\"action_probs\"].items()\n",
    "            }\n",
    "            ## Compute action coefficient for CEL of BC\n",
    "            dataset_stats_filename = \"dataset_statistics.bz2\"\n",
    "            dataset_stats_filepath = f\"{DATASET_DIR_PATH}/{dataset_stats_filename}\"\n",
    "            with open(dataset_stats_filepath, \"wb\") as f:\n",
    "                cpkl.dump(dataset_statistics, f)\n",
    "\n",
    "            for k, v in dataset_statistics.items():\n",
    "                print(f\"{k}: {v}\")\n",
    "\n",
    "            print(\"\")\n",
    "            print(\"#####################################################################################\")\n",
    "            print(\"#####################################################################################\")\n",
    "            print(f\"Collected {step} / {DATASET_TOTAL_STEPS}; Avg return: {np.mean(ep_returns):0.2f}; Avg Suc.: {np.mean(ep_success)}; Avg: Norm Dist Goal: {np.mean(ep_norm_dist_to_goal)}\")\n",
    "            print(\"#####################################################################################\")\n",
    "            print(\"#####################################################################################\")\n",
    "            print(\"\")\n",
    "\n",
    "            \n",
    "    # Prepare for the next step\n",
    "    obs = next_obs\n",
    "    done = next_done\n",
    "\n",
    "    for i in range(NUM_ENVS):\n",
    "        envs_current_step[i] = int((1 - next_done[i]) * (envs_current_step[i] + 1))\n",
    "\n",
    "    # Stop collection ASAP\n",
    "    if step >= DATASET_TOTAL_STEPS:\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking dataset statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_stats_filepath, \"rb\") as f:\n",
    "    r__dataset_stats = cpkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r__dataset_stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking collected trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ep_filepath = \"./SAVI_Oracle_Dataset_2023_05_17__200__STEPS/VzqfbhrpDEA-cushion-23-20230517T142613-02f36c1bee3d4baaadc10c1bca0bd7e3.bz2\"\n",
    "\n",
    "# with open(ep_filepath, \"rb\") as f:\n",
    "#     edd = cpkl.load(f)\n",
    "\n",
    "# print(f\"edd content: {list(edd.keys())}\")\n",
    "# edd[\"obs_list\"].keys() # dict_keys(['depth', 'rgb', 'audiogoal', 'spectrogram', 'category', 'pointgoal_with_gps_compass', 'pose'])\n",
    "# type(edd[\"obs_list\"][\"rgb\"]), len(edd[\"obs_list\"][\"rgb\"]), edd[\"obs_list\"][\"rgb\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH=\"SAVI_Oracle_Dataset_2023_05_17__50__STEPS\"\n",
    "for ep_filename in os.listdir(DATASET_PATH)[:5]:\n",
    "    if ep_filename == \"dataset_statistics.bz2\":\n",
    "        continue\n",
    "    \n",
    "    # relative file path\n",
    "    ep_filepath = f\"{DATASET_PATH}/{ep_filename}\"\n",
    "    \n",
    "    # Load the episode data\n",
    "    with open(ep_filepath, \"rb\") as f:\n",
    "        edd = cpkl.load(f)\n",
    "\n",
    "    ## Plot the collected trajectory's RGB observations\n",
    "    ep_length = len(edd[\"obs_list\"][\"rgb\"])\n",
    "    ep_category_name = edd[\"category_name\"]\n",
    "    ep_scene_id = edd[\"scene_id\"]\n",
    "\n",
    "    print(f\"Ep. scene: {ep_scene_id} | Cat. : {ep_category_name} | Len. : {ep_length}\")\n",
    "\n",
    "    N = 5\n",
    "    truncated_obs_list = edd[\"obs_list\"][\"rgb\"][:N] + edd[\"obs_list\"][\"rgb\"][-N:]\n",
    "\n",
    "    fig, axes = plt.subplots(1, N * 2 + 1, figsize=(4 * N * 2 + 4, 4), dpi=300)\n",
    "    fig.set_facecolor(\"white\")\n",
    "\n",
    "    for t, rgb_obs in enumerate(truncated_obs_list):\n",
    "        axes[t].tick_params(axis=\"both\", which=\"both\", bottom=False, top=False, left=False, labelleft=False, labelbottom=False)\n",
    "        axes[t].imshow(rgb_obs)\n",
    "    top_down_map_img = plot_top_down_map(edd[\"info_list\"][-1])\n",
    "    axes[-1].imshow(top_down_map_img)\n",
    "    axes[-1].tick_params(axis=\"both\", which=\"both\", bottom=False, top=False, left=False, labelleft=False, labelbottom=False)\n",
    "\n",
    "    fig.suptitle(f\"Scene: {ep_scene_id} | Target: {ep_category_name} | Ep. Len.: {ep_length}\", fontsize=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ss-hab-display-py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
