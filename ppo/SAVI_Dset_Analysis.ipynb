{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import uuid\n",
    "import datetime\n",
    "import numpy as np\n",
    "import compress_pickle as cpkl\n",
    "\n",
    "from ss_baselines.av_nav.config import get_config\n",
    "from ss_baselines.savi.config.default import get_config as get_savi_config\n",
    "from ss_baselines.common.env_utils import construct_envs\n",
    "from ss_baselines.common.environments import get_env_class\n",
    "from ss_baselines.common.utils import plot_top_down_map\n",
    "\n",
    "# Helper / tools\n",
    "from soundspaces.mp3d_utils import CATEGORY_INDEX_MAPPING\n",
    "def get_category_name(idx):\n",
    "    assert idx >= 0 and idx <=20, f\"Invalid category index number: {idx}\"\n",
    "\n",
    "    for k, v in CATEGORY_INDEX_MAPPING.items():\n",
    "        if v == idx:\n",
    "            return k\n",
    "\n",
    "def get_current_ep_category_label(obs_dict):\n",
    "    return get_category_name(obs_dict[\"category\"].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR_PATH = f\"SAVI_Oracle_Dataset_v0\"\n",
    "# DATASET_DIR_PATH = f\"SAVI_Oracle_Dataset_v0_10K\" # Smaller scale dataset for tests\n",
    "\n",
    "# Read the dataset statistics file.\n",
    "dataset_stats_filepath = f\"{DATASET_DIR_PATH}/dataset_statistics.bz2\"\n",
    "with open(dataset_stats_filepath, \"rb\") as f:\n",
    "    r__dataset_stats = cpkl.load(f)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(r__dataset_stats)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting some stats about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency of category counts\n",
    "total_episodes = np.sum([v for k, v in r__dataset_stats[\"category_counts\"].items()])\n",
    "assert total_episodes == r__dataset_stats[\"total_episodes\"], \\\n",
    "    \"Category counts not matching episode counts.\"\n",
    "\n",
    "category_probs = {k: v / total_episodes for k, v in r__dataset_stats[\"category_counts\"].items()}\n",
    "# pprint(category_probs)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(6,3), dpi=200)\n",
    "x=[i for i in range(21)]\n",
    "x_labels, x_heights = [], []\n",
    "for k, v in category_probs.items():\n",
    "    x_labels.append(k)\n",
    "    x_heights.append(v)\n",
    "ax.bar(x=x, height=x_heights, tick_label=x_labels)\n",
    "ax.set_xticklabels(x_labels, rotation=45, ha=\"right\")\n",
    "fig.suptitle(f\"Dset: {DATASET_DIR_PATH} | # steps: {r__dataset_stats['total_steps']} | # eps: {r__dataset_stats['total_episodes']}\", fontsize=7)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency of scenes in the dataset\n",
    "total_episodes = np.sum([v for k, v in r__dataset_stats[\"scene_counts\"].items()])\n",
    "assert total_episodes == r__dataset_stats[\"total_episodes\"], \\\n",
    "    \"Scene counts not matching episode counts.\"\n",
    "scene_probs = {k: v / total_episodes for k, v in r__dataset_stats[\"scene_counts\"].items()}\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(6 * 3, 6), dpi=200)\n",
    "x_labels, x_heights = [], []\n",
    "for k, v in scene_probs.items():\n",
    "    x_labels.append(k)\n",
    "    x_heights.append(v)\n",
    "n_scenes = len(x_labels)\n",
    "x = [i for i in range(n_scenes)]\n",
    "\n",
    "ax.bar(x=x, height=x_heights, tick_label=x_labels)\n",
    "ax.set_xticklabels(x_labels, rotation=45, ha=\"right\")\n",
    "fig.suptitle(f\"Dset: {DATASET_DIR_PATH} | # steps: {r__dataset_stats['total_steps']} | # eps: {r__dataset_stats['total_episodes']}\", fontsize=18)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Frequency of the episode lengths\n",
    "# all_ep_lengths = []\n",
    "# ep_lengths_dict = {}\n",
    "# for ep_filename in os.listdir(DATASET_DIR_PATH):\n",
    "#     if ep_filename == \"dataset_statistics.bz2\":\n",
    "#         continue\n",
    "#     ep_filepath = f\"{DATASET_DIR_PATH}/{ep_filename}\"\n",
    "#     with open(ep_filepath, \"rb\") as f:\n",
    "#         edd = cpkl.load(f)\n",
    "    \n",
    "#     ep_length = edd[\"ep_length\"]\n",
    "#     if ep_length not in list(ep_lengths_dict.keys()):\n",
    "#         ep_lengths_dict[ep_length] = 1\n",
    "#     else:\n",
    "#         ep_lengths_dict[ep_length] += 1\n",
    "#     all_ep_lengths.append(ep_length)\n",
    "\n",
    "# # Histogram of the episodes lengths, note that it is very time costly, since this was not logged during data collection.\n",
    "# fig, ax = plt.subplots(1,1, figsize=(6 * 3, 6), dpi=200)\n",
    "# ax.hist(all_ep_lengths, bins=60)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting trajectories for RSA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. C categories, for a given category: N trajs for M rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import clear_output\n",
    "\n",
    "# # Start byreading all the episodes in \n",
    "# M = 3 # number fo scenes / rooms, for one category\n",
    "# N = 4 # number of trajs. per scenes / rooms, for one category\n",
    "# CATEGORIES_OF_INTEREST = [\n",
    "#     \"chair\",\n",
    "#     \"picture\",\n",
    "#     # \"table\",\n",
    "#     # \"cushion\",\n",
    "#     # \"cabinet\",\n",
    "#     # \"plant\"\n",
    "# ]\n",
    "# C = len(CATEGORIES_OF_INTEREST)\n",
    "\n",
    "# trajs_scenes_cat = {\n",
    "#     k: {} for k in CATEGORIES_OF_INTEREST\n",
    "# }\n",
    "\n",
    "# n_selected_trajs = 0\n",
    "\n",
    "# ep_filenames = os.listdir(DATASET_DIR_PATH)\n",
    "# if \"dataset_statistics.bz2\" in ep_filenames:\n",
    "#     ep_filenames.remove(\"dataset_statistics.bz2\")\n",
    "# ep_filenames_iterator = iter(ep_filenames)\n",
    "\n",
    "# while n_selected_trajs < C * N * M:\n",
    "#     ep_filename = next(ep_filenames_iterator)\n",
    "\n",
    "#     ep_filepath = f\"{DATASET_DIR_PATH}/{ep_filename}\"\n",
    "#     with open(ep_filepath, \"rb\") as f:\n",
    "#         edd = cpkl.load(f)\n",
    "\n",
    "#     ep_length = edd[\"ep_length\"]\n",
    "#     ep_category = edd[\"category_name\"]\n",
    "#     ep_scene = edd[\"scene_id\"]\n",
    "\n",
    "#     # Skip if the category does not match\n",
    "#     if ep_category not in CATEGORIES_OF_INTEREST:\n",
    "#         continue\n",
    "\n",
    "#     if ep_scene not in trajs_scenes_cat[ep_category].keys():\n",
    "#         # First time seeing the scene: add it to the dict, along with the new traj.\n",
    "#         if len(trajs_scenes_cat[ep_category]) < M:\n",
    "#             # Only add it if we don't have enough scenes yet.\n",
    "#             trajs_scenes_cat[ep_category][ep_scene] = [\n",
    "#                 {\n",
    "#                     \"ep_filename\": ep_filename,\n",
    "#                     \"edd\": edd\n",
    "#                 }\n",
    "#             ]\n",
    "#             n_selected_trajs += 1\n",
    "#     else:\n",
    "#         # The scene was already seen once; check if we need more, and append accordingly\n",
    "#         if len(trajs_scenes_cat[ep_category][ep_scene]) < N:\n",
    "#             trajs_scenes_cat[ep_category][ep_scene].append({\n",
    "#                 \"ep_filename\": ep_filename,\n",
    "#                 \"edd\": edd\n",
    "#             })\n",
    "#             n_selected_trajs += 1\n",
    "\n",
    "#     if n_selected_trajs < N * M:\n",
    "#         clear_output(wait=True)\n",
    "    \n",
    "#     print(\"### --------------------------------------------------- ###\")\n",
    "#     print(f\"### # selected traj: {n_selected_trajs} for \\\"{ep_category}\\\"\")\n",
    "#     for k, v in trajs_scenes_cat[ep_category].items():\n",
    "#         print(f\"\\t{k}: {len(v)}\")\n",
    "#     print(\"### --------------------------------------------------- ###\")\n",
    "#     print(\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Similar to A, but make sure we use the same rooms for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import clear_output\n",
    "\n",
    "# # Start byreading all the episodes in \n",
    "# M = 3 # number fo scenes / rooms, for one category\n",
    "# N = 2 # number of trajs. per scenes / rooms, for one category\n",
    "# CATEGORIES_OF_INTEREST = [\n",
    "#     \"chair\",\n",
    "#     \"picture\",\n",
    "#     # \"table\",\n",
    "#     # \"cushion\",\n",
    "#     # \"cabinet\",\n",
    "#     # \"plant\"\n",
    "# ]\n",
    "# C = len(CATEGORIES_OF_INTEREST)\n",
    "\n",
    "# trajs_scenes_cat = {\n",
    "#     k: {} for k in CATEGORIES_OF_INTEREST\n",
    "# }\n",
    "\n",
    "# n_selected_trajs = 0\n",
    "\n",
    "# ep_filenames = os.listdir(DATASET_DIR_PATH)\n",
    "# if \"dataset_statistics.bz2\" in ep_filenames:\n",
    "#     ep_filenames.remove(\"dataset_statistics.bz2\")\n",
    "# ep_filenames_iterator = iter(ep_filenames)\n",
    "\n",
    "# scenes_of_interest = [] # To make sure we have the same scenes for each category\n",
    "\n",
    "# while n_selected_trajs < C * N * M:\n",
    "#     ep_filename = next(ep_filenames_iterator)\n",
    "\n",
    "#     ep_filepath = f\"{DATASET_DIR_PATH}/{ep_filename}\"\n",
    "#     with open(ep_filepath, \"rb\") as f:\n",
    "#         edd = cpkl.load(f)\n",
    "\n",
    "#     ep_length = edd[\"ep_length\"]\n",
    "#     ep_category = edd[\"category_name\"]\n",
    "#     ep_scene = edd[\"scene_id\"]\n",
    "\n",
    "#     # Skip if the category does not match\n",
    "#     if ep_category not in CATEGORIES_OF_INTEREST:\n",
    "#         continue\n",
    "\n",
    "#     # Track which scenes' trajectories will be saved.\n",
    "#     # We want the same scenes for each category\n",
    "#     if len(scenes_of_interest) < M and (ep_scene not in scenes_of_interest):\n",
    "#         scenes_of_interest.append(ep_scene)\n",
    "    \n",
    "#     if ep_scene not in scenes_of_interest:\n",
    "#         continue\n",
    "    \n",
    "#     # Make sure the scene is part of the\n",
    "#     if ep_scene not in trajs_scenes_cat[ep_category].keys():\n",
    "#         # First time seeing the scene: add it to the dict, along with the new traj.\n",
    "#         if len(trajs_scenes_cat[ep_category]) < M:\n",
    "#             # Only add it if we don't have enough scenes yet.\n",
    "#             trajs_scenes_cat[ep_category][ep_scene] = [\n",
    "#                 {\n",
    "#                     \"ep_filename\": ep_filename,\n",
    "#                     \"edd\": edd\n",
    "#                 }\n",
    "#             ]\n",
    "#             n_selected_trajs += 1\n",
    "#     else:\n",
    "#         # The scene was already seen once; check if we need more, and append accordingly\n",
    "#         if len(trajs_scenes_cat[ep_category][ep_scene]) < N:\n",
    "#             trajs_scenes_cat[ep_category][ep_scene].append({\n",
    "#                 \"ep_filename\": ep_filename,\n",
    "#                 \"edd\": edd\n",
    "#             })\n",
    "#             n_selected_trajs += 1\n",
    "\n",
    "#     if n_selected_trajs < N * M:\n",
    "#         clear_output(wait=True)\n",
    "    \n",
    "#     print(\"### --------------------------------------------------- ###\")\n",
    "#     print(f\"### # selected traj: {n_selected_trajs} for \\\"{ep_category}\\\"\")\n",
    "#     for k, v in trajs_scenes_cat[ep_category].items():\n",
    "#         print(f\"\\t{k}: {len(v)}\")\n",
    "#     print(\"### --------------------------------------------------- ###\")\n",
    "#     print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving the filtered trajectories data\n",
    "# # trajs_scenes_cat[\"chair\"] # Check the content\n",
    "# C = len(CATEGORIES_OF_INTEREST)\n",
    "# analysis_trajs_filename = f\"analysis_trajs_C_{C}_M_{M}_N_{N}.bz2\"; print(analysis_trajs_filename)\n",
    "# # Uncomment for actual saving\n",
    "# with open(analysis_trajs_filename, \"wb\") as f:\n",
    "#     cpkl.dump(trajs_scenes_cat, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating filter scenes from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_trajs_filename = \"analysis_trajs_C_6_M_5_N_5.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the filtred trajectories data\n",
    "with open(analysis_trajs_filename, \"rb\") as f:\n",
    "    analysis_trajs_dict = cpkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structured as follows:\n",
    "# - category_name\n",
    "#   - scene_id\n",
    "#       [{}, {}, {} ...] with N items (episode data)b\n",
    "\n",
    "analysis_trajs_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inspecting the analysis data trajectories\n",
    "n_plotted_trajs = 0\n",
    "for i, (cat_name, cat_scenes_trajs) in enumerate(analysis_trajs_dict.items()):\n",
    "    for scene_id, scene_trajs in cat_scenes_trajs.items():\n",
    "        for traj_dict in scene_trajs:\n",
    "            NN = 4\n",
    "            fig, axes = plt.subplots(1, NN * 2 + 1, figsize=((NN * 2 + 1) *  6, 6), dpi=200)\n",
    "            fig.set_facecolor(\"white\")\n",
    "\n",
    "            ep_filename = traj_dict[\"ep_filename\"]\n",
    "            edd = traj_dict[\"edd\"]\n",
    "\n",
    "            truncated_obs_list = edd[\"obs_list\"][\"rgb\"][:NN] + edd[\"obs_list\"][\"rgb\"][-NN:]\n",
    "            truncated_top_down_map_list = edd[\"info_list\"][:NN] + edd[\"info_list\"][-NN:]\n",
    "            # Plot NN * 2 steps + top down map\n",
    "            # for t, rgb_obs in enumerate(truncated_obs_list):\n",
    "            #     axes[t].imshow(rgb_obs)\n",
    "            #     axes[t].tick_params(axis=\"both\", which=\"both\", bottom=False, top=False, left=False, labelleft=False, labelbottom=False)\n",
    "            # top_down_map_img = plot_top_down_map(edd[\"info_list\"][1])\n",
    "            # axes[-1].imshow(top_down_map_img)\n",
    "            # axes[-1].tick_params(axis=\"both\", which=\"both\", bottom=False, top=False, left=False, labelleft=False, labelbottom=False)\n",
    "\n",
    "            # Plot NN * 2 top_down_map + one rgb_obs\n",
    "            for t, info_dict in enumerate(truncated_top_down_map_list):\n",
    "                top_down_map_img = plot_top_down_map(info_dict)\n",
    "                axes[t].imshow(top_down_map_img)\n",
    "                axes[t].tick_params(axis=\"both\", which=\"both\", bottom=False, top=False, left=False, labelleft=False, labelbottom=False)\n",
    "            axes[-1].tick_params(axis=\"both\", which=\"both\", bottom=False, top=False, left=False, labelleft=False, labelbottom=False)\n",
    "            axes[-1].imshow(truncated_obs_list[-1])\n",
    "\n",
    "            fig.suptitle(f\"Scene: {scene_id} | Target: {cat_name} | Ep. Len.: {edd['ep_length']}\", fontsize=32)\n",
    "\n",
    "            n_plotted_trajs += 1\n",
    "\n",
    "            if n_plotted_trajs >= 10:\n",
    "                break\n",
    "        \n",
    "        if n_plotted_trajs >= 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ss-hab-headless-py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
